@misc{1986accessorientedPdf,
  title = {1986-Access-Oriented.Pdf},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\Z3QZB88Q\\1986-access-oriented.pdf}
}

@misc{3600TechnicalSummary1983,
  title = {3600 Technical Summary - Feb83},
  year = {1983},
  publisher = {Symbolics Corporaiton},
  langid = {english}
}

@article{adeliComputeraidedAnalysisStructures1986,
  title = {Computer-Aided Analysis of Structures in INTERLISP Environment},
  author = {Adeli, H. and Paek, Y. J.},
  year = {1986},
  journal = {Computers \& structures},
  volume = {23},
  number = {3},
  pages = {393--407},
  doi = {10.1016/0045-7949(86)90231-2},
  url = {https://www.sciencedirect.com/science/article/abs/pii/0045794986902312},
  abstract = {LISP appears to be the language of choice among the developers of knowledge-based expert systems. Analysis of structures in INTERLISP environment is discussed in this paper. An interactive INTERLISP program is presented for analysis of frames which can be used as part of an expert system for computer-aided design of structures. Some of the concepts and characteristics of INTERLISP language are explained by referring to the INTERLISP program.},
  keywords = {sz}
}

@incollection{affenzellerCASTFSMComputation2001,
  title = {On CAST.FSM Computation of Hierarchical Multi-Layer Networks of Automata},
  booktitle = {Computer Aided Systems Theory — EUROCAST 2001},
  author = {Affenzeller, Michael and Pichler, Franz and Mittelmann, Rudolf},
  editor = {Goos, Gerhard and Hartmanis, Juris and {\noopsort{leeuwen}}{van Leeuwen}, Jan and {Moreno-Díaz}, Roberto and Buchberger, Bruno and Luis Freire, José},
  year = {2001},
  volume = {2178},
  pages = {36--44},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin},
  doi = {10.1007/3-540-45654-6_3},
  url = {http://link.springer.com/10.1007/3-540-45654-6_3},
  urldate = {2021-04-15},
  abstract = {CAST.FSM denotes a CAST tool which has been developed at the Institute of Systems Science at the University of Linz during the years 1986–1993. The first version of CAST.FSM was implemented in INTERLISP-D and LOOPS for the Siemens-Xerox workstation 5815 (“Dandelion”). CAST.FSM supports the application of the theory of finite state machines for hardware design tasks between the architecture level and the level of gate circuits. The application domain, to get practical experience for CAST.FSM, was the field of VLSI design of ASICS’s where the theory of finite state machines can be applied to improve the testability of such circuits (“design for testability”) and to optimise the required silicon area of the circuit (“floor planning”). An overview of CAST as a whole and of CAST.FSM as a CAST tool is given in [11]. In our presentation we want to report on the re-engineering of CAST.FSM and on new types of applications of CAST.FSM which are currently under investigation. In this context we will distinguish between three different problems: 1. the implementation of CAST.FSM in ANSI Common Lisp and the design of a new user interface by Rudolf Mittelmann [5].   2. the search for systemstheoretical concepts in modelling intelligent hierarchical systems based on the past work of Arthur Koestler [3] following the concepts presented by Franz Pichler in [10].   3. the construction of hierarchical formal models (of multi-layer type) to study attributes which are assumed for SOHO-structures (SOHO = Self Organizing Hierarchical Order) of A. Koestler.   The latter problem will deserve the main attention in our presentation. In the present paper we will build such a hierarchical model following the concepts of parallel decomposition of finite state machines (FSMs) and interpret it as a multi-layer type of model.},
  isbn = {978-3-540-42959-3 978-3-540-45654-4},
  langid = {english},
  keywords = {sz}
}

@inproceedings{albergaProgramDevelopmentTool1981,
  title = {A Program Development Tool},
  booktitle = {Proceedings of the 8th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages  - POPL '81},
  author = {Alberga, C. N. and Brown, A. L. and Leeman, G. B. and Mikelsons, M. and Wegman, M. N.},
  year = {1981},
  pages = {92--104},
  publisher = {ACM Press},
  address = {Williamsburg, Virginia},
  doi = {10.1145/567532.567543},
  url = {http://portal.acm.org/citation.cfm?doid=567532.567543},
  urldate = {2021-04-15},
  abstract = {In this paper we describe how we have combined a number of tools (most of which understand a particular programming language) into a single system to aid in the reading, writing, and running of programs. We discuss the efficacy and the structure of our system. For the last two years the system has been used to build itself; it currently consists of 500 kilobytes of machine code (25,000 lines of LISP/370 code) and approximately one hundred commands with large numbers of options. We will describe some of the experience we have gained in evolving this system. We first indicate the system components which users have found most important; some of the tools described here are new in the literature. Second, we emphasize how these tools form a synergistic union, and we illustrate this point with a number of examples. Third, we illustrate the use of various system commands in the development of a simple program. Fourth, we discuss the implementation of the system components and indicate how some of them have been generalized.},
  isbn = {978-0-89791-029-X},
  langid = {english},
  keywords = {sz}
}

@article{albizuri-romeroRetrospectiveViewCASE2000,
  title = {A Retrospective View of CASE Tools Adoption},
  author = {{Albizuri-Romero}, Miren Begoña},
  year = {2000},
  month = mar,
  journal = {ACM SIGSOFT Software Engineering Notes},
  volume = {25},
  number = {2},
  pages = {46--50},
  issn = {0163-5948},
  doi = {10.1145/346057.346071},
  url = {https://doi.org/10.1145/346057.346071},
  urldate = {2021-04-15},
  abstract = {This paper provides a retrospective view of the adoption of CASE tools in organizations using some empirical data from various research studies in this field. First, relevant factors that influence the decision to adopt such a tool are discussed. Such factors include elements related to the organization adopting such a technology, as well as other characteristics associated with the application environment and the alternative development methods being used. Then, the advantages and disadvantages of using CASE tools are discussed and some critical success factors are identified. Finally, a taxonomy of CASE tools in the 90's is presented. The paper provides some explanations of why some organizations are successful in adopting CASE tools and gives recommendations for making a better use of such a technology.},
  keywords = {applications development,CASE,sz,workbench}
}

@article{allardRealtimeProgrammingCommon1991,
  title = {Real-Time Programming in Common Lisp},
  author = {Allard, James R. and Hawkinson, Lowell B.},
  year = {1991},
  month = sep,
  journal = {Communications of the ACM},
  volume = {34},
  number = {9},
  pages = {64--69},
  issn = {0001-0782},
  doi = {10.1145/114669.114679},
  url = {https://doi.org/10.1145/114669.114679},
  urldate = {2021-04-25},
  keywords = {garbage collection,Lisp,macros,real-time programming,sz,type declaration}
}

@inproceedings{allchinFLASHLanguageindependentPortable1980,
  title = {FLASH: A Language-Independent, Portable File Access System},
  shorttitle = {FLASH},
  booktitle = {Proceedings of the 1980 ACM SIGMOD International Conference on Management of Data},
  author = {Allchin, James E. and Keller, Arthur M. and Wiederhold, Gio},
  year = {1980},
  month = may,
  series = {SIGMOD '80},
  pages = {151--156},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/582250.582274},
  url = {https://doi.org/10.1145/582250.582274},
  urldate = {2021-04-15},
  abstract = {A file access system, flash, for use in building database systems is described. It supports access from several languages, including pascal, fortran, and interlisp. Flash provides record level access to a file with multiple indexes using symbolic keys. It is portable and written in Pascal with support routines in dec System 20 macro. The file access system is designed to run on computers of various sizes and capabilities, including micros. Concurrent and simultaneous access by several users is supported given that the operating systems provides multiprogramming. Flash is designed to be highly reliable. It assumes the existence of underlying operating system file services that read or write named files directly. Transfer to files occurs in units which are efficient, typically a block.},
  isbn = {978-0-89791-018-4},
  keywords = {concurrent update,databases,files,Indexed sequential,ISAM,microprocessors,multiple indexes,multiple language,portable,sz,VSAM}
}

@article{allenDrJavaLightweightPedagogic2002,
  title = {DrJava: A Lightweight Pedagogic Environment for Java},
  shorttitle = {DrJava},
  author = {Allen, Eric and Cartwright, Robert and Stoler, Brian},
  year = {2002},
  month = feb,
  journal = {ACM SIGCSE Bulletin},
  volume = {34},
  number = {1},
  pages = {137--141},
  issn = {0097-8418},
  doi = {10.1145/563517.563395},
  url = {https://doi.org/10.1145/563517.563395},
  urldate = {2021-06-03},
  abstract = {DrJava is a pedagogic programming environment for Java that enables students to focus on designing programs, rather than learning how to use the environment. The environment provides a simple interface based on a "read-eval-print loop" that enables a programmer to develop, test, and debug Java programs in an interactive, incremental fashion. This paper gives an overview of DrJava including its pedagogic rationale, functionality, and implementation.},
  keywords = {sz}
}

@misc{allenXeroxAltoRebuilt2016,
  title = {Xerox Alto Is Rebuilt and Reconnected by the Living Computer Museum},
  author = {Allen, Paul G.},
  year = {2016},
  month = sep,
  journal = {Vulcan Inc.},
  url = {https://medium.com/vulcan-inc/xerox-alto-is-rebuilt-and-reconnected-by-the-living-computer-museum-e56a7e86be91},
  urldate = {2023-05-22},
  abstract = {It’s one thing to read about a true breakthrough, something else to see it in action},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\YK7A6WP5\\xerox-alto-is-rebuilt-and-reconnected-by-the-living-computer-museum-e56a7e86be91.html}
}

@misc{amorosoMyEncounterMedley2023,
  title = {My Encounter with Medley Interlisp},
  author = {Amoroso, Paolo},
  year = {2023},
  month = jan,
  journal = {Paolo Amoroso's Journal},
  url = {https://journal.paoloamoroso.com/my-encounter-with-medley-interlisp},
  urldate = {2023-02-25},
  abstract = {Imagine someone let you into an alien spaceship they landed in your backyard, sat you at the controls, and encouraged you to fly the ship...},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\2P8FTV57\\my-encounter-with-medley-interlisp.html}
}

@article{andersharaidsonLISPdetailsINTERLlSP3601975,
  title = {LISP-Details INTERLlSP / 360 - 370},
  author = {{Anders Haraidson}},
  year = {1975},
  journal = {Oatalogi1aboratoriet, Sturegatan 1. S-752 23 Uppsala, -Sweden},
  pages = {217},
  issn = {9150600346},
  url = {http://www.softwarepreservation.org/projects/LISP/uppsala/Haraldson-LISP_details.pdf},
  abstract = {This paper gives a tutorial introduction to INTERLISP/360-370, a subset of INTERLISP, which can be implemented on IBM/360 and similar systems. oe·scriptions of a large number of functions in INTERLISP with numerous examples, exercises and solutions are contained. The use of edit, break, advice, file handling and compiler are given and both interactive and batch use of the system is taken care of.},
  langid = {english},
  keywords = {INTERLISP/360-370,s2z}
}

@article{andersonFreeingEssenceComputation1995,
  title = {Freeing the Essence of a Computation},
  author = {Anderson, Kenneth R.},
  year = {1995},
  month = may,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {VIII},
  number = {2},
  pages = {25--36},
  issn = {1045-3563},
  doi = {10.1145/224133.224136},
  url = {https://dl.acm.org/doi/10.1145/224133.224136},
  urldate = {2021-04-25},
  abstract = {In theory, abstraction is important, but in practice, so is performance. Thus, there is a struggle between an abstract description of an algorithm and its efficient implementation. This struggle can be mediated by using an interpreter or a compiler. An interpreter takes a program that is a high level abstract description of an algorithm and applies it to some data. Don't think of an interpreter as slow. An interpreter is important enough to software that it is often implemented in hardware. A compiler takes the program and produces another program, perhaps in another language. The resulting program is applied to some data by another interpreter.},
  langid = {english},
  keywords = {sz}
}

@misc{anonymousKotoINTERLISPDRELEASE1985,
  title = {Koto INTERLISP-D RELEASE NOTES},
  author = {{Anonymous}},
  year = {1985},
  month = dec,
  publisher = {Xerox Corporation},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198706_Lyric/3102464_Lyric_Common_Lisp_Implementation_Notes_Jun87.pdf},
  abstract = {The Koto release of Interlisp-D provides a wide range of added functionality, increased performance and improved reliability Central among these is that Koto is the first release of Interlisp that supports the new Xerox 1185i1186 artificial intelligence work stations, including the new features of these work stations such as the expanded 19" display and the PC emulation option. Of course, like previous releases of Interlisp, Koto also supports the other current members of the 1100 series of machines, specifically the 1132 and various models of the 1108.},
  langid = {english},
  keywords = {s2z}
}

@misc{anonymousXEROXCOMMONLISP1987,
  title = {XEROX COMMON LISP IMPLEMENTATION NOTES},
  shorttitle = {IMPLEMENTATION NOTES},
  author = {{Anonymous}},
  year = {1987},
  month = jun,
  publisher = {XEROX},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198706_Lyric/3102464_Lyric_Common_Lisp_Implementation_Notes_Jun87.pdf},
  abstract = {The Xerox Common Lisp Implementation Notes cover several aspects of the Lyric release. In these notes you will find: • An explanation of how Xerox Common Lisp extends the Common Lisp standard. For example, in Xerox Common Lisp the Common Lisp array-constructing function make-array has additional keyword arguments that enhance its functionality. • An explanation of how several ambiguities in Steele's Common Lisp: the Language were resolved. • A description of additional features that provide far more than extensions to Common Lisp.},
  langid = {english},
  keywords = {Interlisp-D,s2z}
}

@techreport{ANSICommonLisp1994,
  type = {Draft Standard},
  title = {ANSI Common Lisp},
  year = {1994},
  month = aug,
  number = {X3J13/94-101R},
  institution = {ANSI},
  url = {https://franz.com/support/documentation/cl-ansi-standard-draft-w-sidebar.pdf},
  urldate = {2021-06-29},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\58FMWQLB\\cl-ansi-standard-draft-w-sidebar.pdf}
}

@misc{ArchivesEmailCommon,
  title = {(Archives of Email about the Common Lisp Standard and Related)},
  url = {https://ml.cddddr.org/},
  urldate = {2021-09-16},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\KI3TPE48\\ml.cddddr.org.html}
}

@misc{AttendeesLarryMasinter2020,
  title = {Attendees | Larry Masinter, The Medley Interlisp Project: Status and Plans | Meetup},
  year = {2020},
  month = dec,
  url = {https://www.meetup.com/LispNYC/events/vqhmbpybcqblb/attendees/},
  urldate = {2021-06-22},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\2QRA49FT\\attendees.html}
}

@patent{balbanMethodApparatusComposing1991,
  title = {Method of and Apparatus for Composing a Press Imposition},
  author = {Balban, Morton S. and Lan, Ming-Shong and Panos, Rodney M.},
  year = {1991},
  month = jan,
  number = {US4984773A},
  url = {https://patents.google.com/patent/US4984773A/en},
  urldate = {2021-06-01},
  abstract = {An apparatus and a method are disclosed for composing an imposition in terms of an arrangement of printing plates on selected of the image positions on selected units of a printing press to print a given edition, by first assigning each section of this edition to one of the press areas. Thereafter, each printing unit is examined to determine an utilization value thereof in terms of the placement of the printing plates on the image positions and the relative number of image positions to which printing plates are assigned with respect to the total number of image positions. Thereafter, a list of the image positions for each of the sections and its area, is constructed by examining one printing unit at a time in an order according to the placement of that printing unit in the array and examining its utilization value to determine whether or not to include a particular image position of that printing unit in the list. As a result, a list of the image positions is constructed in a sequence corresponding to numerical order of the pages in the section under consideration. Finally, that list of the image positions and the corresponding section and page numbers is displayed in a suitable fashion to inform a user of how to place the printing plates in the desired arrangement onto the printing units of the press to print this given edition.},
  assignee = {Rockwell International Corp},
  nationality = {US},
  keywords = {color,composing,imposition,press,printing},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\GHKH394E\\Balban et al. - 1991 - Method of and apparatus for composing a press impo.pdf}
}

@inproceedings{balzerLanguageindependentProgrammerInterface1974,
  title = {A Language-Independent Programmer's Interface},
  booktitle = {Proceedings of the May 6-10, 1974, National Computer Conference and Exposition},
  author = {Balzer, Robert M.},
  year = {1974},
  month = may,
  series = {AFIPS '74},
  pages = {365--370},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1500175.1500251},
  url = {https://doi.org/10.1145/1500175.1500251},
  urldate = {2021-06-03},
  abstract = {This paper addresses the general problem of creating a suitable on-line environment for programming. The amount of software, and the effort required to produce it, to support such an on-line environment is very large relative to that needed to produce a programming language, and is largely responsible for the scarcity of such programming environments. The size of this effort was largely responsible for the scrapping of a major language (QA4) as a separate entity and its inclusion instead as a set of extensions in a LISP environment. The few systems which do exist (e.g., LISP, APL, BASIC, and PL/I) have greatly benefited their users and have strongly contributed to the widespread acceptance of the associated language.},
  isbn = {978-1-4503-7920-5},
  langid = {english}
}

@article{balzerResearchProgressInformation2017,
  title = {Research in Progress at the Information Sciences Institute, University of Southern California},
  author = {Balzer, Robert and Erman, Lee and Feather, Martin and Goldman, Neil and London, Philip and Wile, David and Wilczynski, David and Lingard, Robert and Mark, William and Mann, William and Moore, James and Pirtle, Mel and Dyer, David and Rizzi, William and Cohen, Danny and Barnett, Jeff and Kameny, Iris and Yemini, Yechiam},
  year = {2017},
  month = jul,
  journal = {AI Magazine},
  volume = {1},
  number = {1},
  pages = {22},
  issn = {2371-9621, 0738-4602},
  doi = {10.1609/aimag.v1i1.88},
  url = {https://ojs.aaai.org/index.php/aimagazine/article/view/88},
  urldate = {2021-04-15},
  abstract = {ISI is an off-campus research center in the University of Southern California's School of Engineering. The Institute engages in a broad set of research and application oriented projects in the computer sciences, ranging from advanced research efforts aimed at producing new concepts to operation of a major Arpanet computer facility.},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\7G69ID36\\Balzer et al. - 2017 - Research in Progress at the Information Sciences I.pdf}
}

@misc{barelaIntroducingDarkstarXerox2019,
  type = {Blog},
  title = {Introducing Darkstar: A Xerox Star Emulator},
  shorttitle = {Introducing Darkstar},
  author = {Barela, Anne},
  year = {2019},
  month = jan,
  journal = {Adafruit Industries - Makers, hackers, artists, designers and engineers!},
  url = {https://blog.adafruit.com/2019/01/23/introducing-darkstar-a-xerox-star-emulator-vintagecomputing-xerox-emulation/},
  urldate = {2021-04-21},
  abstract = {Via libingcomputers.org: Josh Dersch writes about research into the Xerox 8010 Information System (codenamed “Dandelion” during development) and commonly referred to as the Star. The Star was envisioned as center point of the office of the future, combining high-resolution graphics with the now-familiar mouse, Ethernet networking for sharing and collaborating, and Xerox’s Laser Printer technology for faithful “WYSIWYG” document reproduction. A revolutionary system when most everyone else was using text based systems.},
  langid = {american},
  keywords = {Dandelion,Emulation,Interlisp-D,Reviewed by SHFT - CSUCI (Ron Vincent A.),Star,sz}
}

@incollection{barronLinkersLoaders2003,
  title = {Linkers and Loaders},
  booktitle = {Encyclopedia of Computer Science},
  author = {Barron, David W.},
  year = {2003},
  month = jan,
  pages = {988--991},
  publisher = {John Wiley and Sons Ltd.},
  url = {https://dl.acm.org/doi/10.5555/1074100.1074541},
  urldate = {2021-04-15},
  abstract = {Terminology concerning linkers and loaders is confusing, having changed over the years as technology has changed. In older mainframe operating systems, processing of a program between compiling and execution took place in two distinct stages. The function of the linker (or linkage editor) was to combine a number of independently compiled or assembled object files into a single load module, resolving cross-references and incorporating routines from libraries as required. The loader then prepared this module for execution, physically loaded it into memeory, and started execution. Early versions of Unix (q.v.) blurred this distinction: the functions of the linker were incorporated into the C (q.v.) compiler in what was confusingly called the "load phase," and the actual loading was done as part of the "exec," operation that installed a new process image for execution.},
  isbn = {0-470-86412-5},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\24H74EXY\\Barron - 2003 - Linkers and loaders.pdf}
}

@inproceedings{barstowOverviewDisplayorientedEditor1981,
  title = {Overview of a Display-Oriented Editor for INTERLISP},
  booktitle = {Proceedings of the 7th International Joint Conference on Artificial Intelligence - Volume 2},
  author = {Barstow, David R.},
  year = {1981},
  month = aug,
  series = {IJCAI'81},
  pages = {927--929},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  url = {https://dl.acm.org/doi/abs/10.5555/1623264.1623329},
  urldate = {2021-05-04},
  abstract = {DED is a display-oriented editor that was designed to add the power and convenience of display terminals to INTERLISPs teletype-oriented structure editor. DED divides the display screen into a Prettypnnt Region and an Interaction Region. The Prettypnnt Region gives a prettyprinted view of the structure being edited; the Interaction Region contains the interaction between the user and INTERLISPs standard editor. DEDs prettyprinter allows ellision, and the user may zoom in or out to see the expression being edited with more or less detail. There are several arrow keys which allow the user to change quite easily the locus of attention in certain structural ways, as well as a menu-like facility for common command sequences. Together, these features provide a display-facility that considerably augments INTERLISPs otherwise quite sophisticated user interface.}
}

@inproceedings{batesImplementationInterlispVAX1982,
  title = {Implementation of Interlisp on the VAX},
  booktitle = {Proceedings of the 1982 ACM Symposium on LISP and Functional Programming  - LFP '82},
  author = {Bates, Raymond L. and Dyer, David and Koomen, Johannes A. G. M.},
  year = {1982},
  month = aug,
  pages = {81--87},
  publisher = {ACM Press},
  address = {Pittsburgh, Pennsylvania, United States},
  doi = {10.1145/800068.802138},
  url = {http://portal.acm.org/citation.cfm?doid=800068.802138},
  urldate = {2021-04-16},
  abstract = {This paper presents some of the issues involved in implementing Interlisp [19] on a VAX computer [24] with the goal of producing a version that runs under UNIX[17], specifically Berkeley VM/UNIX. This implementation has the following goals: • To be compatible with and functionally equivalent to Interlisp-10. • To serve as a basis for future Interlisp implementations on other mainframe computers. This goal requires that the implementation to be portable. • To support a large virtual address space. • To achieve a reasonable speed. The implementation draws directly from three sources, Interlisp-10 [19], Interlisp-D [5], and Multilisp [12]. Interlisp-10, the progenitor of all Interlisps, runs on the PDP-10 under the TENEX [2] and TOPS-20 operating systems. Interlisp-D, developed at Xerox Palo Alto Research Center, runs on personal computers also developed at PARC. Multilisp, developed at the University of British Columbia, is a portable interpreter containing a kernel of Interlisp, written in Pascal [9] and running on the IBM Series/370 and the VAX. The Interlisp-VAX implementation relies heavily on these implementations. In turn, Interlisp-D and Multilisp were developed from The Interlisp Virtual Machine Specification [15] by J Moore (subsequently referred to as the VM specification), which discusses what is needed to implement an Interlisp by describing an Interlisp Virtual Machine from the implementors' point of view. Approximately six man-years of effort have been spent exclusively in developing Interlisp-VAX, plus the benefit of many years of development for the previous Interlisp implementations.},
  isbn = {978-0-89791-082-6},
  langid = {english},
  keywords = {INTERLISP-VAX,s2z}
}

@book{batesInterlispVAXUsersManual1982,
  title = {Interlisp-VAX Users Manual},
  author = {Bates, Raymond and David, Dayer and Koomen, Johannes and Saunders, Steven and Voreck, Donald},
  year = {1982},
  month = dec,
  edition = {First},
  publisher = {Xerox Corporation},
  address = {300 N. Halstead St. Pasadena CA 91107 USA},
  url = {http://www.softwarepreservation.org/projects/LISP/interlisp/Interlisp-VAX-Users_Manual.pdf/view},
  urldate = {2021-04-23},
  langid = {english},
  keywords = {INTERLISP-VAX,s2z}
}

@inproceedings{batesRecentDevelopmentsISIinterlisp1984,
  title = {Recent Developments in ISI-Interlisp},
  booktitle = {Proceedings of the 1984 ACM Symposium on LISP and Functional Programming},
  author = {Bates, Raymond L. and Dyer, David and Feber, Mark},
  year = {1984},
  month = aug,
  series = {LFP '84},
  pages = {129--139},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800055.802029},
  url = {https://doi.org/10.1145/800055.802029},
  urldate = {2021-06-02},
  abstract = {This paper reports on recent developments of the ISI- Interlisp implementation of Interlisp on a VAX computer. ISI-Interlisp currently runs under UNIX, specifically the Berkeley VM/UNIX and VMS operating systems. Particular attention is paid to the current status of the implementation and the growing pains experienced in the last few years. Included is a discussion of the conversion from UNIX to VAX/VMS, recent modifications and improvements, current limitations, and projected goals. Since much of the recent effort has concerned performance tuning, our observations on this activity are included. ISI-Interlisp, formerly known as Interlisp-VAX, was reported in 1982 ACM Symposium on LISP and Functional Programming, August 1982 [1]. Experiences and recommendations since the 1982 LISP conference are presented.},
  isbn = {978-0-89791-142-3},
  keywords = {sz}
}

@techreport{beckerAQINTERLISPINTERLISPProgram1983,
  title = {AQINTERLISP: An INTERLISP Program for Inductive Generalization of VL1 Event Sets},
  shorttitle = {AQINTERLISP},
  author = {Becker, Jeffrey M.},
  year = {1983},
  month = sep,
  number = {ISG 83-28},
  institution = {University of Illinois Urbana-Champaign},
  url = {https://www.mli.gmu.edu/papers/81-85/83-28.pdf},
  keywords = {sz}
}

@inproceedings{beckerCompilerErrorMessages2019,
  title = {Compiler Error Messages Considered Unhelpful: The Landscape of Text-Based Programming Error Message Research},
  shorttitle = {Compiler Error Messages Considered Unhelpful},
  booktitle = {Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education},
  author = {Becker, Brett A. and Denny, Paul and Pettit, Raymond and Bouchard, Durell and Bouvier, Dennis J. and Harrington, Brian and Kamil, Amir and Karkare, Amey and McDonald, Chris and Osera, Peter-Michael and Pearce, Janice L. and Prather, James},
  year = {2019},
  month = dec,
  series = {ITiCSE-WGR '19},
  pages = {177--210},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3344429.3372508},
  url = {https://dl.acm.org/doi/10.1145/3344429.3372508},
  urldate = {2021-04-15},
  abstract = {Diagnostic messages generated by compilers and interpreters such as syntax error messages have been researched for over half of a century. Unfortunately, these messages which include error, warning, and run-time messages, present substantial difficulty and could be more effective, particularly for novices. Recent years have seen an increased number of papers in the area including studies on the effectiveness of these messages, improving or enhancing them, and their usefulness as a part of programming process data that can be used to predict student performance, track student progress, and tailor learning plans. Despite this increased interest, the long history of literature is quite scattered and has not been brought together in any digestible form. In order to help the computing education community (and related communities) to further advance work on programming error messages, we present a comprehensive, historical and state-of-the-art report on research in the area. In addition, we synthesise and present the existing evidence for these messages including the difficulties they present and their effectiveness. We finally present a set of guidelines, curated from the literature, classified on the type of evidence supporting each one (historical, anecdotal, and empirical). This work can serve as a starting point for those who wish to conduct research on compiler error messages, runtime errors, and warnings. We also make the bibtex file of our 300+ reference corpus publicly available. Collectively this report and the bibliography will be useful to those who wish to design better messages or those that aim to measure their effectiveness, more effectively.},
  isbn = {978-1-4503-7567-2},
  keywords = {compiler error messages,considered harmful,cs-1,cs1,design guidelines,diagnostic error messages,error messages,hci,human computer interaction,introduction to programming,novice programmers,programming error messages,programming errors,review,run-time errors,survey,syntax errors,sz,warnings}
}

@article{beckerleExtensionsCommonLISP1989,
  title = {Extensions to Common LISP to Support International Character Sets},
  author = {Beckerle, Michael and Beiser, Paul and Duggan, Jerry and Kerns, Robert and Layer, Kevin and Linden, Thom and Masinter, Larry and Unietis, David},
  year = {1989},
  pages = {24},
  url = {https://www.researchgate.net/profile/Larry-Masinter/publication/237527690_Extensions_to_Common_LISP_to_Support_International_Character_Sets/links/0c960535d33199f90d000000/Extensions-to-Common-LISP-to-Support-International-Character-Sets.pdf},
  abstract = {This is a proposal to the X3 J13 committee for both extending and modifying the Common LISP language definition to provide a standard basis for Common LISP support of the variety of characters used to represent the languages of the international community. This proposal was created by the Character Subcommittee of X3 J13. We would like to acknowledge discussions with T. Yuasa and other members of the JIS Technical Working Group, comments from members of X3 J13, and the proposals [Ida87], [Linden87], [Kerns87], and [Kurokawa88] for providing the motivation and direction for these extensions. As all these documents and discussions were created expressly for LISP standardization usage, we have borrowed freely from their ideas as well as the texts themselves.},
  keywords = {sz}
}

@inproceedings{beesleyArabicMorphologyUsing1998,
  title = {Arabic Morphology Using Only Finite-State Operations},
  booktitle = {Proceedings of the Workshop on Computational Approaches to Semitic Languages},
  author = {Beesley, Kenneth R.},
  year = {1998},
  month = aug,
  series = {Semitic '98},
  pages = {50--57},
  publisher = {Association for Computational Linguistics},
  address = {USA},
  url = {https://dl.acm.org/doi/10.5555/1621753.1621763},
  urldate = {2021-04-15},
  abstract = {Finite-state morphology has been successful in the description and computational implementation of a wide variety of natural languages. However, the particular challenges of Arabic, and the limitations of some implementations of finite-state morphology, have led many researchers to believe that finite-state power was not sufficient to handle Arabic and other Semitic morphology. This paper illustrates how the morphotactics and the variation rules of Arabic have been described using only finite-state operations and how this approach has been implemented in a significant morphological analyzer/generator.},
  keywords = {sz}
}

@misc{benchoffThatLispMachine2018,
  type = {Blog},
  title = {That’s A Lisp Machine In Your Pocket},
  author = {Benchoff, Brian},
  year = {2018},
  month = dec,
  journal = {Hackaday},
  url = {https://hackaday.com/2018/12/19/thats-a-lisp-machine-in-your-pocket/},
  urldate = {2023-02-19},
  abstract = {Computer languages have always advanced faster than computer hardware. Case in point: we’re~just now getting CPU instructions for JavaScript floating point numbers. The 1970s and 80s wasn\&\#82…},
  langid = {american},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\HBEHEVRF\\thats-a-lisp-machine-in-your-pocket.html}
}

@book{berkeleyProgrammingLanguageLISP1966,
  title = {The Programming Language LISP: Its Operation and Applications},
  shorttitle = {The Programming Language LISP},
  author = {Berkeley, Edmund Callis and Bobrow, Daniel Gureasko},
  year = {1966},
  publisher = {The M.I.T. Press},
  url = {http://www.softwarepreservation.org/projects/LISP/book/III_LispBook_Apr66.pdf},
  isbn = {0-262-59004-2},
  keywords = {sz}
}

@article{berlageSelectiveUndoMechanism1994,
  title = {A Selective Undo Mechanism for Graphical User Interfaces Based on Command Objects},
  author = {Berlage, Thomas},
  year = {1994},
  month = sep,
  journal = {ACM Transactions on Computer-Human Interaction},
  volume = {1},
  number = {3},
  pages = {269--294},
  issn = {1073-0516},
  doi = {10.1145/196699.196721},
  url = {https://doi.org/10.1145/196699.196721},
  urldate = {2021-04-15},
  abstract = {It is important to provide a recovery operation for applications with a graphical user interface. A restricted linear undo mechanism can conveniently be implemented using object-oriented techniques. Although linear undo provides an arbitrarily long history, it is not possible to undo isolated commands from the history without undoing all following commands. Various undo models have been proposed to overcome this limitation, but they all ignore the problem that in graphical user interfaces a previous user action might not have a sensible interpretation in another state. Selective undo introduced here can undo isolated commands by copying them into the current state “if that is meaningful.” Furthermore, the semantics of selective undo are argued to be more natural for the user, because the mechanism only looks at the command to undo and the current state and does not depend on the history in between. The user interface for selective undo can also be implemented generically. Such a generic implementation is able to provide a consistent recovery mechanism in arbitrary applications.},
  keywords = {command objects,groupware,sz,undo}
}

@patent{bierCustomizableUserInterfaces1999,
  title = {Customizable User Interfaces for Programmed Computer Systems},
  author = {Bier, Eric A.},
  year = {1999},
  month = jan,
  number = {US5862395A},
  url = {https://patents.google.com/patent/US5862395A},
  urldate = {2021-04-16},
  abstract = {A software architecture is provided for allowing users to impart various types of button behavior to ordinary human interpretable elements of electronic documents by associating hidden persistent character string button attributes to such elements. This architecture permits such buttons to be edited and searched through the use of the edit and search routines that are ordinarily provided by standard document editors.},
  assignee = {Xerox Corporation},
  nationality = {United States},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\QP53NEMG\\Bier - 1999 - Customizable user interfaces for programmed comput.pdf}
}

@techreport{bobrowBBN940LISP1967,
  title = {THE BBN 940 LISP SYSTEM},
  author = {Bobrow, Daniel G. and Darley, D. Lucille and Deutsch, L. Peter and Murphy, Daniel L. and Teitelman, Warren},
  year = {1967},
  month = jul,
  institution = {BOLT BERANEK AND NEWMAN INC CAMBRIDGE MA},
  url = {https://apps.dtic.mil/sti/citations/AD0656771},
  urldate = {2021-06-01},
  abstract = {The report describes the LISP system implemented at BBN on the SDS 940 Computer. This LISP is an upward compatible extension of LISP 1.5 for the IBM 7090, with a number of new features which make it work well as an on-line language. These new features include tracing, and conditional breakpoints in functions for debugging and a sophisticated LISP oriented editor. The BBN 940 LISP SYSTEM has a large memory store approximately 50,000 free words utilizing special paging techniques for a drum to provide reasonable computation times. The system includes both an interpreter, a fully compatible compiler, and an assembly language facility for inserting machine code subroutines.},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {BBN-LISP,s2z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\DZP5FG6K\\Bobrow et al. - 1967 - THE BBN 940 LISP SYSTEM.pdf}
}

@book{bobrowBBNLISPSystemReference1969,
  title = {The BBN-LISP System: Reference Manual},
  shorttitle = {The BBN-LISP System},
  editor = {Bobrow, Daniel G. and Murphy, D. L. and Teitelman, Warren},
  year = {1969},
  month = apr,
  publisher = {Bolt, Beranek and Newman Inc},
  address = {Cambridge},
  url = {http://www.bitsavers.org/pdf/bbn/The_BBN-LISP_System_Apr69.pdf},
  abstract = {This document describes the BEN-LISP system currently implemented on the SDS 940. It is a dialect of LISP 1.5 and the differences between IBM 7090 version and this system are described in Appendix 1 and 2. Principally, this system has been expanded from the LISP 1.5 on the 7090 in a number of different ways. BBN-LISP is designed to utilize a drum for storage and to provide the user a large virtual memory, with a relatively small penalty in speed (using special paging techniques described in Bobrow and Murphy 1967).},
  lccn = {Z699.5.L28 B62 1969},
  keywords = {BBN-LISP,Information storage and retrieval systems,LISP (Computer program language),s2z}
}

@article{bobrowCommonLispObject1988,
  title = {Common Lisp Object System Specification},
  author = {Bobrow, Daniel G. and DeMichiel, Linda G. and Gabriel, Richard P. and Keene, Sonya E. and Kiczales, Gregor and Moon, David A.},
  year = {1988},
  month = sep,
  journal = {ACM SIGPLAN Notices},
  volume = {23},
  number = {SI},
  pages = {1--142},
  issn = {0362-1340},
  doi = {10.1145/885631.885632},
  url = {https://doi.org/10.1145/885631.885632},
  urldate = {2021-06-02},
  abstract = {Introduction The Common Lisp Object System is an object-oriented extension to Common Lisp as defined in Common Lisp: The Language, by Guy L. Steele Jr. It is based on generic functions, multiple inheritance, declarative method combination, and a meta-object protocol. The first two chapters of this specification present a description of the standard Programmer Interface for the Common Lisp Object System. The first chapter contains a description of the concepts of the Common Lisp Object System, and the second contains a description of the functions and macros in the Common Lisp Object System Programmer Interface. The chapter "The Common Lisp Object System Meta-Object Protocol" describes how the Common Lisp Object System can be customized. The fundamental objects of the Common Lisp Object System are classes, instances, generic functions, and methods. A class object determines the structure and behavior of a set of other objects, which are called its instances. Every Common Lisp object is an instance of a class. The class of an object determines the set of operations that can be performed on the object. A generic function is a function whose behavior depends on the classes or identities of the arguments supplied to it. A generic function object contains a set of methods, a lambda-list, a method combination type, and other information. The methods define the class-specific behavior and operations of the generic function; a method is said to specialize a generic function. When invoked, a generic function executes a subset of its methods based on the classes of its arguments. A generic function can be used in the same ways that an ordinary function can be used in Common Lisp; in particular, a generic function can be used as an argument to funcall and apply and can be given a global or a local name. A method is an object that contains a method function, a sequence of parameter speclalizers that specify when the given method is applicable, and a sequence of qualifiers that is used by the method combination facility to distinguish among methods. Each required formal parameter of each method has an associated parameter specializer, and the method will be invoked only on arguments that satisfy its parameter specializers. The method combination facility controls the selection of methods, the order in which they are run, and the values that are returned by the generic function. The Common Lisp Object System offers a default method combination type and provides a facility for declaring new types of method combination.},
  keywords = {sz}
}

@inproceedings{bobrowCommonLoopsMergingLisp1986,
  title = {CommonLoops: Merging Lisp and Object-Oriented Programming},
  shorttitle = {CommonLoops},
  booktitle = {Conference Proceedings on Object-Oriented Programming Systems, Languages and Applications},
  author = {Bobrow, Daniel G. and Kahn, Kenneth and Kiczales, Gregor and Masinter, Larry and Stefik, Mark and Zdybel, Frank},
  year = {1986},
  month = jun,
  series = {OOPSLA '86},
  pages = {17--29},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/28697.28700},
  url = {https://doi.org/10.1145/28697.28700},
  urldate = {2021-04-25},
  abstract = {CommonLoops blends object-oriented programming smoothly and tightly with the procedure-oriented design of Lisp. Functions and methods are combined in a more general abstraction. Message passing is invoked via normal Lisp function call. Methods are viewed as partial descriptions of procedures. Lisp data types are integrated with object classes. With these integrations, it is easy to incrementally move a program between the procedure and object-oriented styles. One of the most important properties of CommonLoops is its extensive use of meta-objects. We discuss three kinds of meta-objects: objects for classes, objects for methods, and objects for discriminators. We argue that these meta-objects make practical both efficient implementation and experimentation with new ideas for object-oriented programming. CommonLoops' small kernel is powerful enough to implement the major object-oriented systems in use today.},
  isbn = {978-0-89791-204-7},
  keywords = {sz}
}

@article{bobrowCommonLoopsMergingLisp1986a,
  title = {CommonLoops: Merging Lisp and Object-Oriented Programming},
  shorttitle = {CommonLoops},
  author = {Bobrow, Daniel G. and Kahn, Kenneth and Kiczales, Gregor and Masinter, Larry and Stefik, Mark and Zdybel, Frank},
  year = {1986},
  month = jun,
  journal = {ACM SIGPLAN Notices},
  volume = {21},
  number = {11},
  pages = {17--29},
  issn = {0362-1340},
  doi = {10.1145/960112.28700},
  url = {https://doi.org/10.1145/960112.28700},
  urldate = {2021-06-03},
  abstract = {CommonLoops blends object-oriented programming smoothly and tightly with the procedure-oriented design of Lisp. Functions and methods are combined in a more general abstraction. Message passing is invoked via normal Lisp function call. Methods are viewed as partial descriptions of procedures. Lisp data types are integrated with object classes. With these integrations, it is easy to incrementally move a program between the procedure and object-oriented styles. One of the most important properties of CommonLoops is its extensive use of meta-objects. We discuss three kinds of meta-objects: objects for classes, objects for methods, and objects for discriminators. We argue that these meta-objects make practical both efficient implementation and experimentation with new ideas for object-oriented programming. CommonLoops' small kernel is powerful enough to implement the major object-oriented systems in use today.},
  keywords = {sz}
}

@article{bobrowCompactEncodingsList1979,
  title = {Compact Encodings of List Structure},
  author = {Bobrow, Daniel G. and Clark, Douglas W.},
  year = {1979},
  month = oct,
  journal = {ACM Transactions on Programming Languages and Systems},
  volume = {1},
  number = {2},
  pages = {266--286},
  issn = {0164-0925, 1558-4593},
  doi = {10.1145/357073.357081},
  url = {https://dl.acm.org/doi/10.1145/357073.357081},
  urldate = {2021-04-21},
  abstract = {List structures provide a general mechanism for representing easily changed structured data, but can introduce inefficiencies in the use of space when fields of uniform size are used to contain pointers to data and to link the structure. Empirically determined regularity can be exploited to provide more space-efficient encodings without losing the flexibility inherent in list structures. The basic scheme is to provide compact pointer fields big enough to accommodate most values that occur in them and to provide “escape” mechanisms for exceptional cases. Several examples of encoding designs are presented and evaluated, including two designs currently used in Lisp machines. Alternative escape mechanisms are described, and various questions of cost and implementation are discussed. In order to extrapolate our results to larger systems than those measured, we propose a model for the generation of list pointers and we test the model against data from two programs. We show that according to our model, list structures with compact cdr fields will, as address space grows, continue to be compacted well with a fixed-width small field. Our conclusion is that with a microcodable processor, about a factor of two gain in space efficiency for list structure can be had for little or no cost in processing time.},
  langid = {english},
  keywords = {Interlisp-D,s2z}
}

@inproceedings{bobrowExtendingInterlispModularization1979,
  title = {Extending Interlisp for Modularization and Efficiency},
  booktitle = {Proceedings of the International Symposiumon on Symbolic and Algebraic Computation},
  author = {Bobrow, Daniel G. and Deutsch, L. Peter},
  year = {1979},
  month = jun,
  series = {EUROSAM '79},
  pages = {481--489},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  url = {https://dl.acm.org/doi/10.5555/646670.699000},
  urldate = {2021-06-03},
  isbn = {978-3-540-09519-5},
  keywords = {sz}
}

@inproceedings{bobrowFormatdirectedListProcessing1966,
  title = {Format-Directed List Processing in LISP},
  booktitle = {Proceedings of the First ACM Symposium on Symbolic and Algebraic Manipulation},
  author = {Bobrow, Daniel G. and Teitelman, Warren},
  year = {1966},
  month = jan,
  series = {SYMSAC '66},
  pages = {0301--0329},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800005.807968},
  url = {https://doi.org/10.1145/800005.807968},
  urldate = {2021-05-31},
  abstract = {This article describes a notation and a programming language for expressing, from within a LISP system, string transformations such as those performed in COMIT or SNOBOL. A simple transformation (or transformation rule) is specified by providing a pattern which must match the structure to be transformed and a format which specifies how to construct a new structure according to the segmentation specified by the pattern. The patterns and formats are greatly generalized versions of the left-half and right-half rules of COMIT and SNOBOL. For example, elementary patterns and formats can be variable names, results of computations, disjunctive sets, or repeating subpatterns; predicates can be associated with elementary patterns which check relationships among separated elements of the match; it is no longer necessary to restrict the operations to linear strings since elementary patterns can themselves match structures. The FLIP language has been implemented in LISP 1.5, and has been successfully used in such disparate tasks as editing LISP functions and parsing Kleene regular expressions.},
  isbn = {978-1-4503-7371-5},
  keywords = {BBN-LISP,s2z}
}

@misc{bobrowGeneralStructureLISP1967,
  title = {General Structure of LISP 1.69},
  author = {Bobrow, D. G. and Deutsch, L. P. and Murphy, D. L.},
  year = {1967},
  month = mar,
  url = {http://www.bitsavers.org/pdf/sds/9xx/940/ucbProjectGenie/940_LISP_Memo_1_Mar67.pdf},
  abstract = {This is a preliminary memo describing the BBN LISP 1.69 system for the 50S 940 computer. It is a description of how the system is working now, except for those places clearly noted in the text below. Any difference between the descriptions given and actual operation found should be reported, in writing, to the authors. At the end of this memo there is a copy of the index to function descriptions in the document, "The BBN LISP SYSTEM (revised October 1966).},
  keywords = {BBN-LISP,s2z}
}

@techreport{bobrowInterlispPerformanceMeasurements1976,
  title = {Interlisp Performance Measurements},
  author = {Bobrow, Robert and Grignetti, Mario},
  year = {1976},
  month = jun,
  number = {DTIC\_ADA1045834},
  pages = {61},
  institution = {BOLT BERANEK AND NEWMAN INC CAMBRIDGE MA},
  url = {https://archive.org/details/DTIC_ADA1045834},
  abstract = {This report describes measurements performed for the purpose of determining areas of potential improvement to the efficiency of INTERLISP running under TENEX.},
  langid = {english},
  keywords = {sz}
}

@article{bobrowLISPBulletin1969,
  title = {LISP Bulletin},
  author = {Bobrow, D. G.},
  year = {1969},
  month = sep,
  journal = {ACM SIGPLAN Notices},
  volume = {4},
  number = {9},
  pages = {17--57},
  issn = {0362-1340},
  doi = {10.1145/1132291.1132032},
  url = {https://doi.org/10.1145/1132291.1132032},
  urldate = {2021-04-25},
  abstract = {This first (long delayed) LISP Bulletin contains samples of most of those types of items which the editor feels are relevant to this publication. These include announcements of new (i.e. not previously announced here) implementations of LISP (or closely related) systems; quick tricks in LISP; abstracts of LISP related papers; short writeups and listings of useful programs; and longer articles on problems of general interest to the entire LISP community. Printing of these last articles in the Bulletin does not interfere with later publications in formal journals or books. Short write-ups of new features added to LISP are of interest, preferably upward compatible with LISP 1.5, especially if they are illustrated by programming examples.},
  keywords = {sz}
}

@article{bobrowModelStackImplementation1973,
  title = {A Model and Stack Implementation of Multiple Environments},
  author = {Bobrow, Daniel G. and Wegbreit, Ben},
  year = {1973},
  month = oct,
  journal = {Communications of the ACM},
  volume = {16},
  number = {10},
  pages = {591--603},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/362375.362379},
  url = {https://dl.acm.org/doi/10.1145/362375.362379},
  urldate = {2021-04-16},
  abstract = {Many control and access environment structures require that storage for a procedure activation exist at times when control is not nested within the procedure activated. This is straightforward to implement by dynamic storage allocation with linked blocks for each activation, but rather expensive in both time and space. This paper presents an implementation technique using a single stack to hold procedure activation storage which allows retention of that storage for durations not necessarily tied to control flow. The technique has the property that, in the simple case, it runs identically to the usual automatic stack allocation and deallocation procedure. Applications of this technique to multitasking, coroutines, backtracking, label-valued variables, and functional arguments are discussed. In the initial model, a single real processor is assumed, and the implementation assumes multiple-processes coordinate by passing control explicitly to one another. A multiprocessor implementation requires only a few changes to the basic technique, as described.},
  langid = {english},
  keywords = {interlisp,s2z}
}

@article{bobrowNewProgrammingLanguages1974,
  title = {New Programming Languages for Artificial Intelligence Research},
  author = {Bobrow, Daniel G. and Raphael, Bertram},
  year = {1974},
  month = sep,
  journal = {ACM Computing Surveys},
  volume = {6},
  number = {3},
  pages = {153--174},
  issn = {0360-0300},
  doi = {10.1145/356631.356632},
  url = {https://doi.org/10.1145/356631.356632},
  urldate = {2021-06-02},
  abstract = {New directions in Artifical Intelligence research have led to the need for certain novel features to be embedded in programming languages. This paper gives an overview of the nature of these features, and their implementation in four principal families of AI languages: SAIL; PLANNER/CONNIVER;QLIPS/INTERLISP; and POPLER/POP-2. The programming feature described include: new data types and accessing mechanisms for stored expressions; matching to allow caomparison of data item with a template, and extraction of labeled subexpressions; and deductive mechanisms which allow the programming system to carry out certain activities including modifying the data base and deciding which subroutines to run next using only constraints and guidelines set up by the programmer.},
  keywords = {sz}
}

@article{bobrowNoteEfficiencyLISP1968,
  title = {A Note on the Efficiency of a LISP Computation in a Paged Machine},
  author = {Bobrow, Daniel G. and Murphy, Daniel L.},
  year = {1968},
  month = aug,
  journal = {Communications of the ACM},
  volume = {11},
  number = {8},
  pages = {558},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/363567.363581},
  url = {https://dl.acm.org/doi/10.1145/363567.363581},
  urldate = {2021-04-21},
  abstract = {The problem of the use of two levels of storage for programs is explored in the context of a LISP system which uses core memory as a buffer for a large virtual memory stored on a drum. Details of timing are given for one particular problem.},
  langid = {english},
  keywords = {BBN-LISP,s2z}
}

@article{bobrowNoteHashLinking1975,
  title = {A Note on Hash Linking},
  author = {Bobrow, Daniel G.},
  year = {1975},
  month = jul,
  journal = {Communications of the ACM},
  volume = {18},
  number = {7},
  pages = {413--415},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/360881.360920},
  url = {https://dl.acm.org/doi/10.1145/360881.360920},
  urldate = {2021-04-16},
  abstract = {In current machine designs, a machine address gives the user direct access to a single piece of information, namely the contents of that machine word. This note is based on the observation that it is often useful to associate additional information, with some (relatively few) address locations determined at run time, without the necessity of preallocating the storage at all possible such addresses. That is, it can be useful to have an effective extra bit, field, or address in some words without every word having to contain a bit (or bits) to mark this as a special case. The key idea is that this extra associated information can be found by a table search. Although it could be found by any search technique (e.g. linear, binary sorted, etc.), we suggest that an appropriate low overhead mechanism is to use hash search on a table in which the key is the address of the cell to be augmented.},
  langid = {english},
  keywords = {interlisp,s2z}
}

@article{bobrowPerspectivesArtificialIntelligence,
  title = {Perspectives on Artificial Intelligence Programming},
  author = {Bobrow, G and Stefik, J},
  volume = {231},
  pages = {8},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\8FM22D24\\Bobrow and Stefik - Perspectives on Artificial Intelligence Programmin.pdf}
}

@article{bobrowPerspectivesArtificialIntelligencea,
  title = {Perspectives on Artificial Intelligence Programming},
  author = {Bobrow, G and Stefik, J},
  volume = {231},
  pages = {8},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\4RC42LTY\\Bobrow and Stefik - Perspectives on Artificial Intelligence Programmin.pdf}
}

@techreport{bobrowProgrammingLanguagesLOOPS2003,
  title = {Programming Languages -- The LOOPS Project (1982-1986)},
  author = {Bobrow, Daniel and Mittal, Sanjay and Lanning, Stanley and Stefik, Mark},
  year = {2003},
  institution = {Xerox Parc},
  url = {https://larrymasinter.net/stefik-loops.pdf},
  abstract = {The LOOPS (Lisp Object-Oriented Language) project was started to support development of expert systems project at PARC. We wanted a language that had many of the features of frame languages, such as objects, annotated values, inheritance, and attached procedures. We drew heavily on Smalltalk-80, which was being developed next door.},
  langid = {english},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\TW3RNT8E\\Bobrow - Programming Languges.pdf}
}

@techreport{bobrowStorageManagementLISP1966,
  title = {Storage Management in LISP},
  author = {Bobrow, Daniel G.},
  year = {1966},
  month = jun,
  address = {Cambridge, MA},
  institution = {BOLT BERANEK AND NEWMAN INC},
  url = {https://apps.dtic.mil/sti/citations/AD0636049},
  urldate = {2021-06-02},
  abstract = {Storage allocation, maintenance, and reclamation are handled automatically in LISP systems.  Storage is allocated as needed, and a garbage collection process periodically reclaims storage no longer in use.  A number of different garbage collection algorithms are described.  A common property of most of these algorithms is that during garbage collection all other computation ceases.  This is an untenable situation for programs which must respond to real time interrupts.  The paper concludes with a proposal for an incremental garbage collection scheme which allows simultaneous computation and storage reclamation.  Author},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\7VRSJF9S\\AD0636049.html}
}

@techreport{bobrowSTRUCTURELISPSYSTEM1966,
  title = {THE STRUCTURE OF A LISP SYSTEM USING TWO-LEVEL STORAGE, SCIENTIFIC REPROT},
  author = {Bobrow, Daniel G. and Murphy, Daniel L.},
  year = {1966},
  month = nov,
  address = {Cambridge, MA},
  institution = {BOLT BERANEK AND NEWMAN INC},
  url = {https://apps.dtic.mil/sti/citations/AD0647601},
  urldate = {2021-06-01},
  abstract = {In an ideal list-processing system there would be enough core memory to contain all the data and programs. The paper describes a number of techniques used to build a LISP system which utilizes a drum for its principal storage medium, with a surprisingly low time-penalty for use of this slow storage device. The techniques include careful segmentation of system programs, allocation of virtual memory to allow address arithmetic for type determination, and a special algorithm for building reasonably linearized lists. A scheme is described for binding variables which is good in this environment and allows for complete compatibility between compiled and interpreted programs with no special declarations.},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {BBN-LISP,s2z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\PYHK3Y5D\\Bobrow and Murphy - 1966 - THE STRUCTURE OF A LISP SYSTEM USING TWO-LEVEL STO.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\MTAZCZ2U\\AD0647601.html}
}

@article{bobrowStructureLISPSystem1967,
  title = {Structure of a LISP System Using Two-Level Storage: Communications of the ACM},
  author = {Bobrow, Daniel G. and Murphy, Daniel L.},
  year = {1967},
  month = mar,
  journal = {Communications of the ACM},
  volume = {10},
  number = {3},
  pages = {155--159},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/363162.363185},
  url = {https://dl.acm.org/doi/10.1145/363162.363185},
  urldate = {2021-04-16},
  abstract = {In an ideal list-processing system there would be enough core memory to contain all the data and programs. Described in this paper are a number of techniques that have been used to build a LISP system utilizing a drum for its principal storage medium, with a surprisingly low time penalty for use of this slow storage device. The techniques include careful segmentation of system programs, allocation of virtual memory to allow address arithmetic for type determination, and a special algorithm for building reasonably linearized lists. A scheme for binding variables is described which is good in this environment and allows for complete compatibility between compiled and interpreted programs with no special declarations.},
  langid = {english},
  keywords = {BBN-LISP,s2z}
}

@incollection{boeckerIXOPTIMISTSystem2019,
  title = {IX. OPTIMIST. Ein System zur Beurteilung und Verbesserung von Lisp-Code},
  booktitle = {Prototypen benutzergerechter Computersysteme},
  author = {Böcker, Heinz-Dieter},
  year = {2019},
  month = jul,
  pages = {151--168},
  publisher = {De Gruyter},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110861907-010/html},
  isbn = {978-3-11-086190-7},
  langid = {ngerman},
  keywords = {sz}
}

@article{bohnkeArbeitsweiseHypermedialerLernsysteme2001,
  title = {Die Arbeitsweise Hypermedialer Lernsysteme Am Beispiel Der Systeme Lisp-Tutor Und ELM-ART},
  author = {Böhnke, Dorothea and Eggerth, Claudia},
  year = {2001},
  month = jan,
  url = {http://informatikdidaktik.de/Lehre/HypermediaLernsysteme/Vortraege/BoehnkeEggerth.pdf},
  keywords = {sz}
}

@inproceedings{bouvinClassicalHypermediaVirtues2016,
  title = {Classical Hypermedia Virtues on the Web with Webstrates},
  booktitle = {Proceedings of the 27th ACM Conference on Hypertext and Social Media},
  author = {Bouvin, Niels Olof and Klokmose, Clemens Nylandsted},
  year = {2016},
  month = jul,
  series = {HT '16},
  pages = {207--212},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2914586.2914622},
  url = {https://doi.org/10.1145/2914586.2914622},
  urldate = {2021-04-15},
  abstract = {We show and analyze herein how Webstrates can augment the Web from a classical hypermedia perspective. Webstrates turns the DOM of Web pages into persistent and collaborative objects. We demonstrate how this can be applied to realize bidirectional links, shared collaborative annotations, and in-browser authorship and development.},
  isbn = {978-1-4503-4247-6},
  keywords = {collaboration,dynamic documents,hypermedia,sz,web}
}

@inproceedings{bouvinNoteCardsNotebooksThere2019,
  title = {From NoteCards to Notebooks: There and Back Again},
  shorttitle = {From NoteCards to Notebooks},
  booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
  author = {Bouvin, Niels Olof},
  year = {2019},
  month = sep,
  series = {HT '19},
  pages = {19--28},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3342220.3343666},
  url = {https://doi.org/10.1145/3342220.3343666},
  urldate = {2021-04-15},
  abstract = {Fifty years since the beginning of the Internet, and three decades of the Dexter Hypertext Reference Model and the World Wide Web mark an opportune time to take stock and consider how hypermedia has developed, and in which direction it might be headed. The modern Web has on one hand turned into a place where very few, very large companies control all major platforms with some highly unfortunately consequences. On the other hand, it has also led to the creation of a highly flexible and nigh ubiquitous set of technologies and practices, which can be used as the basis for future hypermedia research with the rise of computational notebooks as a prime example of a new kind of collaborative and highly malleable applications.},
  isbn = {978-1-4503-6885-8},
  keywords = {computational literacy,computational notebooks,end user programming,hypermedia,open hypermedia,sz,world wide web}
}

@article{boydIsolationAnalysisOptimization1993,
  title = {Isolation and Analysis of Optimization Errors},
  author = {Boyd, Mickey R. and Whalley, David B.},
  year = {1993},
  month = jun,
  journal = {ACM SIGPLAN Notices},
  volume = {28},
  number = {6},
  pages = {26--35},
  issn = {0362-1340},
  doi = {10.1145/173262.155093},
  url = {https://doi.org/10.1145/173262.155093},
  urldate = {2021-06-03},
  abstract = {This paper describes two related tools developed to support the isolation and analysts of optimization errors in the vpo optimizer. Both tools rely on vpo identifying sequences of changes, referred to as transformations. that result in semantically equivalent (and usually improved) code. One tool determines the first transfer. motion that causes incorrect output of the execution of the compiled program. This tool not only automatically isolates the illegal transformation, but also identifies the location and instant the transformation is performed in vpo. To assist in the analysis of an optimization error, a graphical optimization viewer was also implemented that can display the state of the generated instructions before and after each transformation performed by vpo. Unique features of the optimization viewer include reverse viewing (or undoing) of transformations and the ability to stop at breakpoints associated with the generated instructions. Both tools are useful independently. Together these tools form a powerful environment for facilitating the retargeting of vpo to a new machine and supporting experimentation with new optimizations. In addition, the optimization viewercan be used as a teaching aid in compiler classes.},
  keywords = {sz}
}

@techreport{brachmanKLONEReferenceManual1978,
  title = {KLONE Reference Manual:},
  shorttitle = {KLONE Reference Manual},
  author = {Brachman, Ronald and Ciccarelli, Eugene and Greenfeld, Norton and Yonke, Martin},
  year = {1978},
  month = jul,
  address = {Fort Belvoir, VA},
  institution = {Defense Technical Information Center},
  doi = {10.21236/ADA122437},
  url = {http://www.dtic.mil/docs/citations/ADA122437},
  urldate = {2021-07-13},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\9ISLG7U8\\Brachman et al. - 1978 - KLONE Reference Manual.pdf}
}

@article{brachmanSpecialIssueKnowledge1980,
  title = {Special Issue on Knowledge Representation},
  author = {Brachman, Ronald J. and Smith, Brian C.},
  year = {1980},
  month = feb,
  journal = {ACM SIGART Bulletin},
  number = {70},
  pages = {1--138},
  issn = {0163-5719},
  doi = {10.1145/1056751.1056752},
  url = {https://doi.org/10.1145/1056751.1056752},
  urldate = {2021-04-25},
  abstract = {In the fall of 1978 we decided to produce a special issue of the SIGART Newsletter devoted to a survey of current knowledge representation research. We felt that there were twe useful functions such an issue could serve. First, we hoped to elicit a clear picture of how people working in this subdiscipline understand knowledge representation research, to illuminate the issues on which current research is focused, and to catalogue what approaches and techniques are currently being developed. Second -- and this is why we envisaged the issue as a survey of many different groups and projects -- we wanted to provide a document that would enable the reader to acquire at least an approximate sense of how each of the many different research endesvours around the world fit into the field as a whole.It would of course be impossible to produce a final or definitive document accomplishing these goals: rather, we hoped that this survey could initiate a continuing dialogue on issues in representation, a project for which this newsletter seems the ideal forum. It has been many months since our original decision was made, but we are finally able to present the results of that survey. Perhaps more than anything else, it has emerged as a testament to an astounding range and variety of opinions held by many different people in many different places.The following few pages are intended as an introduction to the survey as a whole, and to this issue of the newsletter. We will briefly summarize the form that the survey took, discuss the strategies we followed in analyzing and tabulating responses, briefly review the overall sense we received from the answers that were submitted, and discuss various criticisms which were submitted along with the responses. The remainder of the volume has been designed to be roughly self-explanatory at each point, so that one may dip into it at different places at will. Certain conventions, however, particularly regarding indexing and tabulating, will also be explained in the remainder of this introduction.As editors, we are enormously grateful to the many people who devoted substantial effort to responding to our survey. It is our hope that the material presented here will be interesting and helpful to our readers, and that fruitful discussion of these and other issues will continue energetically and enthusiastically into the future.},
  keywords = {sz}
}

@misc{bradmyersAllWidgetsMenus2021,
  title = {All the Widgets 2: Menus},
  shorttitle = {All the Widgets 2},
  author = {{Brad Myers}},
  year = {2021},
  month = feb,
  url = {https://www.youtube.com/watch?v=phr1UcEa_B8},
  urldate = {2021-05-02},
  abstract = {All the Widgets 2: Menus Brad Myers, Carnegie Mellon University CHI '90 Special Issue: All The Widgets WEB:: http://www.cs.umd.edu/hcil/chivideosl...\hspace{0pt} Editor: Brad Myers (Carnegie Mellon University) Location: Austin, USA},
  keywords = {sz}
}

@misc{BuildingHolisticDevelopment2017,
  title = {Building towards a Holistic Development Service — Amjad Masad},
  year = {2017},
  month = may,
  url = {https://www.youtube.com/watch?v=w8Pv29pkAvU},
  urldate = {2021-05-02},
  abstract = {We as developers tend to separate our development tools by the stage of the development lifecycle: authoring, executing, building, or deployment. But this limits how much information each tool has at it’s disposal and therefore how much utility it can provide. For example, your IDE can show you the callers of a particular function but because it it’s not involved in running your code it can’t tell you how many times that function failed at runtime. Even worse, we end up with a lot of redundant implementations of the same functions – for example parsers – because it’s easier than sharing the work. At Replit we’re growing a holistic development service from the ground up. At first our service just executed user code. Then it gained code intelligence capabilities like Lint. Then it understood the project structure and dependencies. Then it knew how to test code. And now it’s growing to understand deployment. All this within a single service. We envision this to become a long-lived always-on service that understands your code in all it’s stages and can be at your disposal anywhere you are regardless of the device, platform or the programming language you’re using.},
  keywords = {sz}
}

@incollection{bundyInterlispD1984,
  title = {Interlisp-D},
  booktitle = {Catalogue of Artificial Intelligence Tools},
  author = {Bundy, Alan and Wallen, Lincoln},
  editor = {Bundy, Alan and Wallen, Lincoln},
  year = {1984},
  series = {Symbolic Computation},
  pages = {52--52},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-96868-6_103},
  url = {https://doi.org/10.1007/978-3-642-96868-6_103},
  urldate = {2021-06-03},
  abstract = {Major dialect of LISP {$<$}34{$>$}, designed for high-resolution, bit-mapped display, distinguished by (a) use of in-core editor for structures, and thus code, (b) programming environment of tools for automatic error-correction, syntax (sic) extension and structure declaration/access, (c) implementation of almost-compatible dialects (Interlisp {$<$}X{$>$}) on several machines, (d) extensive usage of display orientated tools and facilities. Emphasis: Personal Lisp workstation, user interface tools.},
  isbn = {978-3-642-96868-6},
  langid = {english}
}

@inproceedings{burtonOverviewStatusDoradoLisp1980,
  title = {Overview and Status of DoradoLisp},
  booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
  author = {Burton, Richard R. and Masinter, L. M. and Bobrow, Daniel G. and Haugeland, Willie Sue and Kaplan, Ronald M. and Sheil, B. A.},
  year = {1980},
  month = aug,
  series = {LFP '80},
  pages = {243--247},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800087.802812},
  url = {https://doi.org/10.1145/800087.802812},
  urldate = {2021-04-25},
  abstract = {DoradoLisp is an implementation of the Interlisp programming system on a large personal computer. It has evolved from AltoLisp, an implementation on a less powerful machine. The major goal of the Dorado implementation was to eliminate the performance deficiencies of the previous system. This paper describes the current status of the system and discusses some of the issues that arose during its implementation. Among the techniques that helped us meet our performance goal were transferring much of the kernel software into Lisp, intensive use of performance measurement tools to determine the areas of worst performance, and use of the Interlisp programming environment to allow rapid and widespread improvements to the system code. The paper lists some areas in which performance was critical and offers some observations on how our experience might be useful to other implementations of Interlisp.},
  isbn = {978-1-4503-7396-8},
  keywords = {Interlisp-D,s2z}
}

@techreport{burtonPapersInterlispD1980,
  title = {Papers on Interlisp-D},
  author = {Burton, Richard R. and Kaplan, Ronald M. and Masinter, B. and Sheil, B. A. and Bell, A. and Bobrow, D. G. and Deutsch, L. P. and Haugeland, W. S.},
  year = {1980},
  month = sep,
  pages = {52},
  url = {http://www.softwarepreservation.net/projects/LISP/interlisp-d/Papers_On_Interlisp-D.pdf},
  abstract = {This report consists of five papers on Interlisp-0, a refinement and implementation of the I[ tnterlisp virtual machine [Moore, 761 which supports the interlisp programming system [Teitelman et at., 781 on the Dolphin and Dorado personal computers},
  keywords = {Interlisp-D,s2z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\AQNUKIZM\\Burton - Papers on Interlisp-D.pdf}
}

@article{burtonSemanticGrammarEngineering1977,
  title = {Semantic Grammar: An Engineering Technique for Constructing Natural Language Understanding Systems},
  shorttitle = {Semantic Grammar},
  author = {Burton, Richard R.},
  year = {1977},
  month = feb,
  journal = {ACM SIGART Bulletin},
  number = {61},
  pages = {26},
  issn = {0163-5719},
  doi = {10.1145/1045283.1045290},
  url = {https://doi.org/10.1145/1045283.1045290},
  urldate = {2021-06-02},
  abstract = {One of the major stumbling blocks to more effective used computers by naive users is the lack of natural means of communication between the user and the computer system. This report discusses a paradigm for constructing efficient and friendly man-machine interface systems involving subsets of natural language for limited domains of discourse. As such this work falls somewhere between highly constrained formal language query systems and unrestricted natural language under-standing systems. The primary purpose of this research is not to advance our theoretical under-standing of natural language but rather to put forth a set of techniques for embedding both semantic/conceptual and pragmatic information into a useful natural language interface module. Our intent has been to produce a front end system which enables the user to concentrate on his problem or task rather than making him worry about how to communicate his ideas or questions to the machine.},
  langid = {english},
  keywords = {sz}
}

@article{burwellComputerManipulationGeological1985,
  title = {Computer Manipulation of Geological Exploration Data},
  author = {Burwell, A. D. M.},
  year = {1985},
  month = sep,
  journal = {Journal of the Geological Society of London},
  volume = {142},
  number = {5},
  pages = {925--926},
  issn = {0016-7649, 2041-479X},
  doi = {10.1144/gsjgs.142.5.0925},
  url = {http://jgs.lyellcollection.org/lookup/doi/10.1144/gsjgs.142.5.0925},
  urldate = {2021-04-15},
  abstract = {Report of a meeting held by the Geological Information Group at the British Petroleum Research Centre, Sunbury, 24 January 1985 This meeting, concerned mainly with computer manipulation of petroleum exploration data, attracted c. 95 participants. In addition to eight papers presented, there were two computer demonstrations of log analysis systems and a number of poster displays. The morning session, concerned with large-scale, integrated hardware and software systems, was chaired by R. Howarth. R. Till of British Petroleum gave the opening paper concerning BP Exploration’s integrated database system. BP Exploration databases fall into three main groups: those containing largely numerical data; databases specifically concerned with text handling; and well-based databases. The ‘numerical’ databases, implemented under the ULTRA database management system (dbms), include a seismic data system, a generalized cartographic database and an earth constants database. Textual databases include a library information system and a Petroconsultants scout data database, both implemented under the BASIS dbms. The well-based systems include a generalized well-data database, a wireline log archive, storage and retrieval system, and a master well index; all three are implemented under the INGRES dbms. Two related BASIS databases contain geochemical and biostratigraphical data. G. Baxter (co-author M. Hemingway) described the development of Britoil’s well log database which was prompted by the need to have rapid access to digitized wireline log data for c. 1500 wells on the UKCS. Early work involved both locating log information and digitizing those logs held in sepia form only. Each digitized log occupies approximately 1 Mbyte.},
  langid = {english},
  keywords = {sz}
}

@article{cardOralHistoryInterview2020,
  title = {Oral History Interview with Stuart Card},
  author = {Card, Stuart},
  year = {2020},
  month = feb,
  journal = {Charles Babbage Institute},
  pages = {50},
  publisher = {Charles Babbage Institute},
  url = {http://conservancy.umn.edu/handle/11299/218989},
  urldate = {2021-09-04},
  abstract = {This interview is part of a series on Human Computer Interaction (HCI) conducted by the Charles Babbage Institute for ACM SIGCHI (Association for Computing Machinery Special Interest Group for Computer Human Interaction).  HCI Pioneer Stuart Card discusses early education, attending Oberlin College, and helping lead its computer center, before the bulk of the interview focuses on his graduate education at Carnegie Mellon University working under Allen Newell, and his long and influential tenure at Xerox PARC.  This includes his long and impactful collaboration with Newell and fellow Newell doctoral student Tom Moran. Newell, Card, and Moran were fundamentally important to theorizing early Human Computer Interaction, and the three co-wrote the widely used and deeply insightful textbook, The Psychology of Human Computer Interaction.  Card provides an overview of his decades of work of Xerox PARC and various aspects of his research contributions to HCI models, information visualization, and information access (especially foraging theory). He moved into managing research and also relates a portion of his leadership roles at PARC and outside on important committees such as for the National Academy of Science.  He briefly expresses his ideas on the early institutional history of SIGCHI and its evolution.  Regarding his work at PARC, Card discusses his influential work on computer mice research at greater length.  Card became an adjunct professor at Stanford University. He is an ACM Fellow and was awarded SIGCHI’s Lifetime Research Achievement Award.},
  langid = {english},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  annotation = {Accepted: 2021-03-04T21:17:00Z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\GMV3PQ6M\\Card - 2020 - Oral history interview with Stuart Card.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\Q5R7GUJV\\218989.html}
}

@article{cardoso-llachArchiveInterfacesExploring2021,
  title = {An Archive of Interfaces: Exploring the Potential of Emulation for Software Research, Pedagogy, and Design},
  shorttitle = {An Archive of Interfaces},
  author = {{Cardoso-Llach}, Daniel and Kaltman, Eric and Erdolu, Emek and Furste, Zachary},
  year = {2021},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW2},
  pages = {294:1--294:22},
  doi = {10.1145/3476035},
  url = {https://doi.org/10.1145/3476035},
  urldate = {2021-10-21},
  abstract = {This paper explores the potential of distributed emulation networks to support research and pedagogy into historical and sociotechnical aspects of software. Emulation is a type of virtualization that re-creates the conditions for a piece of legacy software to operate on a modern system. The paper first offers a review of Computer-Supported Cooperative Work (CSCW), Human-Computer Interaction (HCI), and Science and Technology Studies (STS) literature engaging with software as historical and sociotechnical artifacts, and with emulation as a vehicle of scholarly inquiry. It then documents the novel use of software emulations as a pedagogical resource and research tool for legacy software systems analysis. This is accomplished through the integration of the Emulation as a Service Infrastructure (EaaSI) distributed emulation network into a university-level course focusing on computer-aided design (CAD). The paper offers a detailed case study of a pedagogical experience oriented to incorporate emulations into software research and learning. It shows how emulations allow for close, user-centered analyses of software systems that highlight both their historical evolution and core interaction concepts, and how they shape the work practices of their users.},
  keywords = {architecture,autocad,computer-aided design,emulation,pedagogy,software history},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\K6KSSU4I\\Cardoso-Llach et al. - 2021 - An Archive of Interfaces Exploring the Potential .pdf}
}

@article{chaillouxTechnicalNotesVLISP1978,
  title = {Technical Notes: A VLISP Interpreter on the VCMC1 Machine},
  shorttitle = {Technical Notes},
  author = {Chailloux, Jerome},
  year = {1978},
  month = jul,
  journal = {ACM Lisp Bulletin},
  number = {2},
  pages = {19--26},
  doi = {10.1145/1411798.1411807},
  url = {https://doi.org/10.1145/1411798.1411807},
  urldate = {2021-04-25},
  abstract = {VCMC1 is a virtual machine designed to observe "in vitro" the behaviour of VLISP interpreters. VCMC1 is actually entirely simulated in VLISP 10. We present a short description of the VCMC1 machine followed by the complete listing of the code of a VLISP interpreter, This interpreter incorporates the special feature for tail-recursion function calls.},
  keywords = {sz}
}

@article{chaillouxUseLISPComputer1978,
  title = {The Use of LISP at Computer Centers in Western Germany},
  author = {Chailloux, Jerome},
  year = {1978},
  month = jul,
  journal = {ACM Lisp Bulletin},
  number = {2},
  pages = {10--13},
  issn = {2372-8760},
  doi = {10.1145/1411798.1411804},
  url = {https://dl.acm.org/doi/10.1145/1411798.1411804},
  urldate = {2021-04-23},
  abstract = {A summary of G. GÖRZ "Die Verwendung von LISP an wissenschaft-lichen Rechenzentren in der BRD", IAB Nr 63, Universität Erlangen-nürnberg, Rechenzentrum, Dez. 76.},
  langid = {english},
  keywords = {sz}
}

@article{chaillouxVLISPKITDescription1979,
  title = {The VLISP KIT: Description Implementation and Evaluation},
  shorttitle = {The VLISP KIT},
  author = {Chailloux, Jérôme},
  year = {1979},
  month = dec,
  journal = {ACM Lisp Bulletin},
  number = {3},
  pages = {5},
  doi = {10.1145/1411829.1411832},
  url = {https://doi.org/10.1145/1411829.1411832},
  urldate = {2021-04-25},
  abstract = {This study presents the realization of three systems VLISP (a dialect of LISP) developped at the University of Paris 8 - Vincennes, on the following machines: - a 8 bit words micro-processor (Intel8080/Zilog80) - a 16 bit words PDP-11 - a 36 bit words PDP-10 From these realizations is extracted an implementation model. Our study proposes a solution to the problems of construction and evaluation of such a system. These problems are : 1) The exhaustive description of the implementation. We propose a description based on the virtual, referential and prototype machine VCMC2. 2) The adequate representations of the VLISP objects and functions. We have associated some natural properties and we have established a functionnal typology. 3) The efficiency of the interpreter (in words of core, execution time and power). Our iterpreter does, for his own need, a optimal core allocation (in term of CONS module calls). The direct acces (which needs only one memory access) to the values of objects variable and function, and a type classification of functions allow a direct invocation of all typed functions. 4) The power of control structures. Our implementation's KIT generalizes the VLISP control structures SELF an ESCAPE, extends them with the new constructions EXIT, WHERE and LETF and unifies completly their description and implementation. An incarnation of our model is given by the realization of a complete VLISP system in the referential machine VCMC2. The full code is given in appendix.},
  keywords = {sz}
}

@misc{CHAOSNetFileProtocol1981,
  title = {CHAOSNet File Protocol},
  year = {1981},
  month = sep,
  publisher = {Symbolics Corporaiton}
}

@inproceedings{chapuisMetisseNot3D2005,
  title = {Metisse Is Not a 3D Desktop!},
  booktitle = {Proceedings of the 18th Annual ACM Symposium on User Interface Software and Technology},
  author = {Chapuis, Olivier and Roussel, Nicolas},
  year = {2005},
  month = oct,
  series = {UIST '05},
  pages = {13--22},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1095034.1095038},
  url = {https://doi.org/10.1145/1095034.1095038},
  urldate = {2021-04-15},
  abstract = {Twenty years after the general adoption of overlapping windows and the desktop metaphor, modern window systems differ mainly in minor details such as window decorations or mouse and keyboard bindings. While a number of innovative window management techniques have been proposed, few of them have been evaluated and fewer have made their way into real systems. We believe that one reason for this is that most of the proposed techniques have been designed using a low fidelity approach and were never made properly available. In this paper, we present Metisse, a fully functional window system specifically created to facilitate the design, the implementation and the evaluation of innovative window management techniques. We describe the architecture of the system, some of its implementation details and present several examples that illustrate its potential.},
  isbn = {978-1-59593-271-2},
  keywords = {sz,window management,window system},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\HG5KXZU3\\Chapuis and Roussel - 2005 - Metisse is not a 3D desktop!.pdf}
}

@article{chenProfileguidedProactiveGarbage2006,
  title = {Profile-Guided Proactive Garbage Collection for Locality Optimization},
  author = {Chen, Wen-ke and Bhansali, Sanjay and Chilimbi, Trishul and Gao, Xiaofeng and Chuang, Weihaw},
  year = {2006},
  month = jun,
  journal = {ACM SIGPLAN Notices},
  volume = {41},
  number = {6},
  pages = {332--340},
  issn = {0362-1340},
  doi = {10.1145/1133255.1134021},
  url = {https://doi.org/10.1145/1133255.1134021},
  urldate = {2021-06-02},
  abstract = {Many applications written in garbage collected languages have large dynamic working sets and poor data locality. We present a new system for continuously improving program data locality at run time with low overhead. Our system proactively reorganizes the heap by leveraging the garbage collector and uses profile information collected through a low-overhead mechanism to guide the reorganization at run time. The key contributions include making a case that garbage collection should be viewed as a proactive technique for improving data locality by triggering garbage collection for locality optimization independently of normal garbage collection for space, combining page and cache locality optimization in the same system, and demonstrating that sampling provides sufficiently detailed data access information to guide both page and cache locality optimization with low runtime overhead. We present experimental results obtained by modifying a commercial, state-of-the-art garbage collector to support our claims. Independently triggering garbage collection for locality optimization significantly improved optimizations benefits. Combining page and cache locality optimizations in the same system provided larger average execution time improvements (17\%) than either alone (page 8\%, cache 7\%). Finally, using sampling limited profiling overhead to less than 3\%, on average.},
  keywords = {cache optimization,data locality,garbage collectors,memory optimization,page optimization,sz}
}

@phdthesis{clarkListStructureMeasurements1976,
  title = {List Structure: Measurements, Algorithms, and Encodings},
  author = {Clark, Douglas W.},
  year = {1976},
  abstract = {This thesis is about list structures: how they are used in practice, how they can be moved and copied efficiently, and how they can be represented by space-saving encodings. The approach taken to these subjects is mainly empirical. Measurement results are based on five large programs written in Interlisp, a sophisticated Lisp system that runs on the PDP-10.},
  school = {CMU},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\QWA5JU6L\\CMU-CS-76-clark.pdf}
}

@article{clingerHygienicMacroTechnology2020,
  title = {Hygienic Macro Technology},
  author = {Clinger, William D. and Wand, Mitchell},
  year = {2020},
  month = jun,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {4},
  number = {HOPL},
  pages = {80:1--80:110},
  issn = {2475-1421},
  doi = {10.1145/3386330},
  url = {https://doi.org/10.1145/3386330},
  urldate = {2021-04-15},
  abstract = {The fully parenthesized Cambridge Polish syntax of Lisp, originally regarded as a temporary expedient to be replaced by more conventional syntax, possesses a peculiar virtue: A read procedure can parse it without knowing the syntax of any expressions, statements, definitions, or declarations it may represent. The result of that parsing is a list structure that establishes a standard representation for uninterpreted abstract syntax trees. This representation provides a convenient basis for macro processing, which allows the programmer to specify that some simple piece of abstract syntax should be replaced by some other, more complex piece of abstract syntax. As is well-known, this yields an abstraction mechanism that does things that procedural abstraction cannot, such as introducing new binding structures. The existence of that standard representation for uninterpreted abstract syntax trees soon led Lisp to a greater reliance upon macros than was common in other high-level languages. The importance of those features is suggested by the ten pages devoted to macros in an earlier ACM HOPL paper, “The Evolution of Lisp.” However, na'ive macro expansion was a leaky abstraction, because the movement of a piece of syntax from one place to another might lead to the accidental rebinding of a program’s identifiers. Although this problem was recognized in the 1960s, it was 20 years before a reliable solution was discovered, and another 10 before a solution was discovered that was reliable, flexible, and efficient. In this paper, we summarize that early history with greater focus on hygienic macros, and continue the story by describing the further development, adoption, and influence of hygienic and partially hygienic macro technology in Scheme. The interplay between the desire for standardization and the development of new algorithms is a major theme of that story. We then survey the ways in which hygienic macro technology has been adapted into recent non-parenthetical languages. Finally, we provide a short history of attempts to provide a formal account of macro processing.},
  keywords = {hygiene,Lisp,macro,Scheme,sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\W9IWTQ5Z\\Clinger and Wand - 2020 - Hygienic macro technology.pdf}
}

@misc{CodeBestPractices2021,
  title = {Code of Best Practices in Fair Use for Software Preservation},
  year = {2021},
  month = feb,
  journal = {Association of Research Libraries},
  url = {https://www.arl.org/resources/code-of-best-practices-in-fair-use-for-software-preservation/},
  urldate = {2021-09-04},
  abstract = {The Code of Best Practices in Fair Use for Software Preservation provides clear guidance on the legality of archiving legacy software to ensure continued access to digital files of all...},
  langid = {american},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\X7FZ5L5R\\code-of-best-practices-in-fair-use-for-software-preservation.html}
}

@article{cohenATABLEDatatypeLISP1979,
  title = {The A-TABLE Data-Type for LISP Systems},
  author = {Cohen, Shimon},
  year = {1979},
  month = oct,
  journal = {ACM SIGPLAN Notices},
  volume = {14},
  number = {10},
  pages = {36--47},
  issn = {0362-1340},
  doi = {10.1145/953997.953998},
  url = {https://doi.org/10.1145/953997.953998},
  urldate = {2021-04-15},
  abstract = {This paper describes the A-TABLE Data-Type for LISP-based languages. The A-TABLE is introduced in an attempt to unify different structures such as the PASCAL-Record, SNOBOL-Table AND INTERLISP Funarg-Block.A set of functions is defined to apply A-TABLES to: (1) Creating, accessing and updating Records; (2) Managing associatively indexed tables; (3) Providing context-dependent computations in processes and coroutines; (4) Defining multivalued functions.We show how and why these functions can be efficiently implemented with respect to access, space, garbage-collection and page-faults. We compare the A-TABLE with other facilities - LIST, ARRAY, etc.It is suggested that the A-TABLE should be one of the data-types in LISP-based systems where it can fill the gap between types "LIST" and "ARRAY".},
  keywords = {sz}
}

@patent{cunninghamInteractiveMethodDeveloping1991,
  title = {Interactive Method of Developing Software Interfaces},
  author = {Cunningham, Robert E. and Bonar, Jeffery G. and Corbett, John D.},
  year = {1991},
  month = aug,
  number = {US5041992A},
  url = {https://patents.google.com/patent/US5041992A/en},
  urldate = {2021-06-01},
  abstract = {A system and method for interactive design of user manipulable graphic elements. A computer has display and stored tasks wherein the appearance of graphic elements and methods for their manipulation are defined. Each graphic element is defined by at least one figure specification, one mask specification and one map specification. An interactive display editor program defines specifications of said graphic elements. An interactive program editor program defines programming data and methods associated with said graphic elements. A display program uses the figure, map and mask specifications for assembling graphic elements upon the display and enabling user manipulation of said graphic elements.},
  assignee = {University of Pittsburgh},
  nationality = {US},
  keywords = {bit mapped,display,graphic,objects,program,sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\36L59DHR\\Cunningham et al. - 1991 - Interactive method of developing software interfac.pdf}
}

@techreport{cunninghamroberte.ChipsToolDeveloping1987,
  title = {Chips: A Tool for Developing Software Interfaces Interactively.},
  shorttitle = {Chips},
  author = {{Cunningham, Robert E.} and {Corbett, John D.} and {Bonar, Jeffrey G.}},
  year = {1987},
  month = oct,
  pages = {71.0},
  url = {https://apps.dtic.mil/sti/citations/ADA187499},
  urldate = {2023-04-12},
  abstract = {Chips is an interactive tool for developing software employing graphical humancomputer interfaces on Xerox Lisp machines. For the programmer, It provides a rich graphical interface for the creation of rich graphical interfaces. In the service of an end user, It provides classes for modeling the graphical relationships of objects on the screen and maintaining constraints between them. Several large applications have been developed with Chips including intelligent tutors for programming and electricity. Chips is implemented as a collection of customizable classes in the LOOPS object-oriented extensions to Interlisp-D. The three fundamental classes are 1 DomainObject which defines objects of the application domain - the domain for which the interface is being built - and ties together the various functionalities provided by the Chips system 2 DisplayObject which defines mouse-sensitive graphical objects and 3 Substrate which defines specialized windows for displaying and storing collections of instances of DisplayObject. A programmer creates an interface by specializing existing DomainObjects and drawing new Displayobjects with a graphics editor. Instances of DispalyObject and Substrate are assembled on screen to form the interface. Once the interface has been sketched in this manner, the programmer can build inward, creating all other parts of the application through the objects on the screen.},
  chapter = {Technical Reports},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\U9Y4ENJL\\ADA187499.html}
}

@techreport{danielg.bobrowBBNLISPSystem1967,
  title = {The BBN-LISP System},
  author = {{Daniel G. Bobrow} and {D. Lucille Darley} and {L. Peter Deutsch} and {Daniel L. Murphy} and {Warren Teitelman}},
  year = {1967},
  month = jul,
  number = {9},
  pages = {138},
  url = {http://www.softwarepreservation.org/projects/LISP/bbnlisp/BBN940Lisp_Jul67.pdf/view},
  urldate = {2021-04-23},
  abstract = {This report describes the LISP system implemented at BBN on the  SDS 940 Computer. This LISP is an upward compatible extension of  LISP 1.5 for the IBM 7090, with a number of new features which  make it work well as an on-line language. These new features  include tracing, and conditional breakpoints in functions for  debugging and a sophisticated LISP oriented editor. The BBN 940  LISP SYSTEM has a large memory store (approximately 50,000 free  words) utilizing special paging techniques for a drum to provide  reasonable computation times. The system includes both an  interpreter, a fully compatible compiler, and an assembly language  facility for inserting machine code subroutines.},
  langid = {english},
  keywords = {BBN-LISP,s2z}
}

@misc{danielg.bobrowPreliminarySpecificationBBN1966,
  title = {Preliminary Specification for BBN 940 LISP},
  author = {{Daniel G. Bobrow} and {Daniel L. Murphy}},
  year = {1966},
  month = oct,
  url = {http://www.softwarepreservation.org/projects/LISP/bbnlisp/BBN940LispPrelimSpec_Oct1966.pdf},
  langid = {english},
  keywords = {BBN-LISP,s2z}
}

@inproceedings{daqinghouEmpiricalAnalysisEvolution2009,
  title = {An Empirical Analysis of the Evolution of User-Visible Features in an Integrated Development Environment},
  booktitle = {Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research},
  author = {{Daqing Hou} and Wang, Yuejiao},
  year = {2009},
  month = nov,
  series = {CASCON '09},
  pages = {122--135},
  publisher = {IBM Corp.},
  address = {USA},
  doi = {10.1145/1723028.1723044},
  url = {https://doi.org/10.1145/1723028.1723044},
  urldate = {2021-04-15},
  abstract = {Programmers spend much of their time interacting with Integrated Development Environments (IDEs), which help increase productivity by automating much of the clerical and administrative work. Like any useful software, IDEs are becoming more powerful and usable as new functionality is added and usability concerns addressed. In particular, the last decade has witnessed the rapid and steady growth of features and enhancements (changes) in major Java IDEs. It is of research interest to learn about the characteristics of these changes as well as salient patterns in their evolution trajectories as these can be useful to understand and guide both the design and evolution of similar systems. To this end, a total of 645 "What's New" entries in seven releases of the Eclipse IDE were analyzed both quantitatively and qualitatively under two models. Using the first, an activity-based, functional model, it is found that the vast majority of the changes are refinements or incremental additions to the feature architecture set up in early releases (1.0 and 2.0). Using the second, a usability-based model, a detailed usability analysis was performed to further characterize these changes in terms of their potential impact on how effectively programmers use the IDE. Findings and implications as well as results of selective comparison with two other popular IDEs are reported.},
  keywords = {sz}
}

@inproceedings{davisDIPMETERADVISORInterpretation1981,
  title = {The DIPMETER ADVISOR: Interpretation of Geologic Signals.},
  shorttitle = {The DIPMETER ADVISOR},
  booktitle = {[No Source Information Available]},
  author = {Davis, Randall and Austin, Howard and Carlbom, Ingrid and Frawley, Bud and Pruchnik, Paul and Sneiderman, Rich and Gilreath, J.},
  year = {1981},
  month = jan,
  pages = {846--849},
  abstract = {The DIPMETER ADVISOR program is an application of Al and Expert System techniques to the problem of inferring subsurface geologic structure. It synthesizes techniques developed in two previous lines of work, rulte-based systems and signal understanding programs. This report on the prototype system has four main concerns. First, we describe the task and characterize the various bodies of knowledge required. Second, we describe the design of the system we have built and the level of performance it has currently reached. Third, we use this task as a case study and examine it in the light of other, related efforts, showing how particular characteristics of this problem have dictated a number of design decisions. We consider the character of the interpretation hypotheses generated and the sources of the expertise involved. Finally, we discuss future directions of this early effort. We describe the problem of "shallow knowledge" in expert systems and explain why this task appears to provide an attractive setting for exploring the use of deeper models.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\AQABFKFG\\Davis et al. - 1981 - The DIPMETER ADVISOR Interpretation of Geologic S.pdf}
}

@inproceedings{dawsonImprovedEffectivenessReal1982,
  title = {Improved Effectiveness from a Real Time LISP Garbage Collector},
  booktitle = {Proceedings of the 1982 ACM Symposium on LISP and Functional Programming},
  author = {Dawson, Jeffrey L.},
  year = {1982},
  month = aug,
  series = {LFP '82},
  pages = {159--167},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800068.802146},
  url = {https://doi.org/10.1145/800068.802146},
  urldate = {2021-04-25},
  abstract = {This paper describes a real-time garbage collection algorithm for list processing systems. We identify two efficiency problems inherent to real-time garbage collectors, and give some evidence that the proposed algorithm tends to reduce these problems. In a virtual memory implementation, the algorithm restructures the cell storage area more compactly, thus reducing working sets. The algorithm also may provide a more garbage-free storage area at the end of the collection cycle, although this claim really must await empirical verification.},
  isbn = {978-0-89791-082-6},
  keywords = {sz}
}

@article{dekleerDanielBobrowMemoriam2017,
  title = {Daniel G. Bobrow: In Memoriam},
  shorttitle = {Daniel G. Bobrow},
  author = {DeKleer, Johann},
  year = {2017},
  month = dec,
  journal = {The AI Magazine},
  volume = {38},
  number = {38},
  pages = {78},
  publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
  issn = {0738-4602},
  doi = {10.1609/aimag.v38i4.2767},
  url = {https://web.archive.org/web/201904301959/https://aaai.org/ojs/index.php/aimagazine/article/download/2767/2664},
  urldate = {2021-07-18},
  abstract = {It is with deep sorrow that we report the passing of former AAAI President Danny Bobrow on March 20, 2017. His family, friends, and colleagues from the Palo Alto Research Center and around the world recently gathered at PARC to commemorate his life and work.},
  langid = {english},
  annotation = {Fatcat ID: release\_wg4g7ikocbagxinabbk2eni52q},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\I6ZDPTW7\\DeKleer - 2017 - Daniel G. Bobrow In Memoriam.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\RU9MJYSL\\wg4g7ikocbagxinabbk2eni52q.html}
}

@inproceedings{demichielCommonLispObject1987,
  title = {The Common Lisp Object System: An Overview},
  shorttitle = {The Common Lisp Object System},
  booktitle = {ECOOP’ 87 European Conference on Object-Oriented Programming},
  author = {DeMichiel, Linda G. and Gabriel, Richard P.},
  editor = {Bézivin, Jean and Hullot, Jean-Marie and Cointe, Pierre and Lieberman, Henry},
  year = {1987},
  series = {Lecture Notes in Computer Science},
  pages = {151--170},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-47891-4_15},
  abstract = {The Common Lisp Object System is an object-oriented system that is based on the concepts of generic functions, multiple inheritance, and method combination. All objects in the Object System are instances of classes that form an extension to the Common Lisp type system. The Common Lisp Object System is based on a meta-object protocol that renders it possible to alter the fundamental structure of the Object System itself. The Common Lisp Object System has been proposed as a standard for ANSI Common Lisp and has been tentatively endorsed by X3J13.},
  isbn = {978-3-540-47891-1},
  langid = {english},
  keywords = {Additional Language,Class Graph,Method Combination,Object System,Ordinary Function,sz}
}

@patent{denberGraphicsDisplaySystem1992,
  title = {Graphics Display System with Improved Dynamic Menu Selection},
  author = {Denber, Michel J.},
  year = {1992},
  month = jan,
  number = {EP0464742A2},
  url = {https://patents.google.com/patent/EP0464742A2/en},
  urldate = {2021-06-01},
  abstract = {In a graphic display system, display control software is modified to impart motion to a pop-up menu to attract the attention of the user. The menu becomes animated when a control and comparison circuit confirms that a mouse driven cursor on the screen is moving away from the pop-up menu indicating that the operator is unaware of the menu's presence. The menu moves or "tags-along" after the cursor until the user takes notice and makes the appropriate selection.},
  assignee = {Xerox Corp},
  langid = {english},
  nationality = {EP},
  keywords = {cursor,menu,mouse,pop,screen},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\C7GBE3A9\\Denber - 1992 - Graphics display system with improved dynamic menu.pdf}
}

@patent{denberMethodApparatusThinning1993,
  title = {Method and Apparatus for Thinning Printed Images},
  author = {Denber, Michel J. and Jankowski, Henry P.},
  year = {1993},
  month = oct,
  number = {US5250934A},
  url = {https://patents.google.com/patent/US5250934A/en},
  urldate = {2021-06-01},
  abstract = {A method and apparatus are shown for improving bit-image quality in video display terminals and xerographic processors. In one embodiment, each scan line of a source image is ANDed with the scan line above to remove half-bits and thin halftones. In other embodiments, entire blocks of data are processed by bit-block transfer operations, such as ANDing a copy of the source image with a copy of itself shifted by one bit. Also, a source image can be compared to a shifted copy of itself to locate diagonal lines in order to place gray pixels bordering these lines.},
  assignee = {Xerox Corp},
  nationality = {US},
  keywords = {bit,image,memory buffer,output,shift register},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\S27UVYSS\\Denber and Jankowski - 1993 - Method and apparatus for thinning printed images.pdf}
}

@article{denningDisciplineSoftwareArchitecture1994,
  title = {A Discipline of Software Architecture},
  author = {Denning, Peter J. and Dargan, Pamela A.},
  year = {1994},
  month = jan,
  journal = {Interactions},
  volume = {1},
  number = {1},
  pages = {55--65},
  issn = {1072-5520},
  doi = {10.1145/174800.174807},
  url = {https://doi.org/10.1145/174800.174807},
  urldate = {2021-04-15},
  keywords = {sz}
}

@misc{deutsch930LISPReference1965,
  title = {930 LISP Reference Manual},
  author = {Deutsch, L. Peter and Lampson, Butler W.},
  year = {1965},
  month = jun,
  url = {http://bitsavers.org/pdf/sds/9xx/940/ucbProjectGenie/30.50.40_930_LISP_Reference_Feb66.pdf},
  langid = {english},
  keywords = {s2z,SDS 930 LISP}
}

@article{deutschACMFellowProfile1999,
  title = {ACM Fellow Profile},
  author = {Deutsch, L. Peter and Finkbine, Ronald B.},
  year = {1999},
  month = jan,
  journal = {ACM SIGSOFT Software Engineering Notes},
  volume = {24},
  number = {1},
  pages = {68},
  issn = {0163-5948},
  doi = {10.1145/308769.308771},
  url = {https://doi.org/10.1145/308769.308771},
  urldate = {2021-04-15},
  keywords = {sz}
}

@inproceedings{deutschByteLispItsAlto1980,
  title = {ByteLisp and Its Alto Implementation},
  booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
  author = {Deutsch, L. Peter},
  year = {1980},
  month = aug,
  series = {LFP '80},
  pages = {231--242},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800087.802811},
  url = {https://doi.org/10.1145/800087.802811},
  urldate = {2021-05-31},
  abstract = {This paper describes in detail the most interesting aspects of ByteLisp, a transportable Lisp system architecture which implements the Interlisp dialect of Lisp, and its first implementation, on a microprogrammed minicomputer called the Alto. Two forthcoming related papers will deal with general questions of Lisp machine and system architecture, and detailed measurements of the Alto ByteLisp system described here. A highly condensed summary of the series was published at MICRO-11 in November 197815.},
  isbn = {978-1-4503-7396-8},
  keywords = {Interlisp-D,s2z}
}

@misc{deutschDisplayPrimitivesLisp1974,
  title = {Display Primitives in Lisp},
  author = {Deutsch, P.},
  year = {1974},
  month = nov,
  publisher = {Palo Alto Research Center, Xerox Corporation},
  url = {http://www.bitsavers.org/pdf/xerox/alto/memos_1974/Display_Primitives_in_Lisp_Nov74.pdf},
  abstract = {Several conflicting goal must be resolved in deciding on a set of display facilities for Lisp: ease of lisp, efficient access to hardware facilities, and device and system independence. Thiss memo suggests a set of facilities constructed in two layers: a lower layer that gives direct access to the Alto bitmap capability, while retaining Lisp's tradition of freeing the programmer from  storage allocation worries and an upper Iayer that uses the lower (on the Alto) or a character-stream protocol (for VTS t on MAXC) to provide for writing strings, scrolling, edting, etc. on the screen,},
  keywords = {interlisp,s2z}
}

@article{deutschEfficientIncrementalAutomatic1976,
  title = {An Efficient, Incremental, Automatic Garbage Collector},
  author = {Deutsch, L. Peter and Bobrow, Daniel G.},
  year = {1976},
  month = sep,
  journal = {Communications of the ACM},
  volume = {19},
  number = {9},
  pages = {522--526},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/360336.360345},
  url = {https://dl.acm.org/doi/10.1145/360336.360345},
  urldate = {2021-04-16},
  abstract = {This paper describes a new way of solving the storage reclamation problem for a system such as Lisp that allocates storage automatically from a heap, and does not require the programmer to give any indication that particular items are no longer useful or accessible. A reference count scheme for reclaiming non-self-referential structures, and a linearizing, compacting, copying scheme to reorganize all storage at the users discretion are proposed. The algorithms are designed to work well in systems which use multiple levels of storage, and large virtual address space. They depend on the fact that most cells are referenced exactly once, and that reference counts need only be accurate when storage is about to be reclaimed. A transaction file stores changes to reference counts, and a multiple reference table stores the count for items which are referenced more than once.},
  langid = {english},
  keywords = {Interlisp-D,s2z}
}

@article{deutschExperienceMicroprogrammedInterlisp1978,
  title = {Experience with a Microprogrammed Interlisp System},
  author = {Deutsch, L. Peter},
  year = {1978},
  month = nov,
  journal = {ACM SIGMICRO Newsletter},
  volume = {9},
  number = {4},
  pages = {128--129},
  issn = {1050-916X},
  doi = {10.1145/1014198.804321},
  url = {https://doi.org/10.1145/1014198.804321},
  urldate = {2021-05-31},
  abstract = {This paper presents the design of an Interlisp system running on a microprogrammed minicomputer. We discuss the constraints imposed by compatibility requirements and by the hardware, the important design decisions, and the most prominent successes and failures of our design, and offer some suggestions for future designers of small Lisp systems. This extended abstract contains only qualitative results. Supporting measurement data will be presented at MICRO-11.},
  keywords = {Interlisp-D,s2z}
}

@techreport{deutschInteractiveProgramVerifier1973,
  title = {An Interactive Program Verifier},
  author = {Deutsch, L. Peter},
  year = {1973},
  month = may,
  address = {California},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.696.5498},
  abstract = {Program verification refers to the idea that the intent or effect of a program can be stated in a precise way that is not a simple "rewording " of the program itself, and that one can prove (in the mathematical sense) that a program actually conforms to a given statement of intent. This thesis describes a software system which can verify (prove) some non-trivial programs automatically. The system described here is organized in a novel manner compared to most other theorem-proving systems. IL has a great deal of specific knowledge about integers and arrays of integers, yet it is not "special-purpose", since this knowledge is represented in procedures which are separate from the underlying structure of the system. It also incorporates some knowledge, gained by the author from both experiment and introspection, about how programs are often constructed, and uses this knowledge to guide the proof process. It uses its knowledge, plus contextual information from the program being verified, to simplify the theorems dramatically as they are being constructed, rather than relying on a super-powerful proof procedure. The system also provides for interactive editing of programs and assertions, and for detailed human control of the proof process when the system cannot produce a proof (or counter-example) on its own.},
  keywords = {BBN-LISP,s2z}
}

@misc{deutschINTERLISPTWOIMPLEMENTATIONS1978,
  title = {INSIDE INTERLISP: TWO IMPLEMENTATIONS},
  author = {Deutsch, L. Peter},
  year = {1978},
  month = nov,
  publisher = {Xerox Palo Alto Research Center},
  url = {http://www.softwarepreservation.org/projects/LISP/interlisp/Deutsch-Inside_Interlisp-1978.pdf},
  langid = {english},
  keywords = {s2z}
}

@inproceedings{deutschLISPMachineVery1973,
  title = {A LISP Machine with Very Compact Programs},
  booktitle = {Proceedings of the 3rd International Joint Conference on Artificial Intelligence},
  author = {Deutsch, L. Peter},
  year = {1973},
  month = aug,
  series = {IJCAI'73},
  pages = {697--703},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  url = {https://dl.acm.org/doi/abs/10.5555/1624775.1624860},
  urldate = {2021-05-31},
  abstract = {This paper presents a machine designed for compact representation and rapid execution of LISP programs. The machine language is a factor of 2 to 5 more compact than S-expressions or conventional compiled code, and the compiler is extremely simple. The encoding scheme is potentially applicable to data as well as program. The machine also provides for user-defined data structures.},
  keywords = {Interlisp-D,s2z}
}

@misc{deutschPDP1Lisp1960,
  title = {PDP-1 Lisp},
  author = {Deutsch, L. Peter},
  year = {1960},
  url = {http://www.bitsavers.org/pdf/mit/rle_pdp1/memos/Deutsch_PDP-1_LISP.pdf},
  abstract = {A program has been written for the PDP-1 providing a subset of the features of the LISP interpreter for the IBM 709/7090. This program, which contains no known bugs, will run on any PDP-1 with automatic divide. On machines with more than 4K of memory, it must be run in memory field 0. It is assumed that the reader is familiar with 709 LISP in general and with the LISP 1.5 Programmer's Manual in particular.},
  keywords = {sz}
}

@techreport{deutschPIVOTSourceListing1975,
  title = {PIVOT Source Listing},
  author = {Deutsch, L. Peter},
  year = {1975},
  month = mar,
  address = {California},
  url = {http://www.softwarepreservation.org/projects/verification/pivot/Deutsch-Pivot.pdf},
  abstract = {Program verification refers to the idea that the intent or effect of a program can be stated in a precise way that is not a simple "rewording " of the program itself, and that one can prove (in the mathematical sense) that a program actually conforms to a given statement of intent. This thesis describes a software system which can verify (prove) some non-trivial programs automatically. The system described here is organized in a novel manner compared to most other theorem-proving systems. IL has a great deal of specific knowledge about integers and arrays of integers, yet it is not "special-purpose", since this knowledge is represented in procedures which are separate from the underlying structure of the system. It also incorporates some knowledge, gained by the author from both experiment and introspection, about how programs are often constructed, and uses this knowledge to guide the proof process. It uses its knowledge, plus contextual information from the program being verified, to simplify the theorems dramatically as they are being constructed, rather than relying on a super-powerful proof procedure. The system also provides for interactive editing of programs and assertions, and for detailed human control of the proof process when the system cannot produce a proof (or counter-example) on its own.},
  keywords = {BBN-LISP,s2z}
}

@misc{deutschPreliminaryGuideLISP1967,
  title = {Preliminary Guide to the LISP Editor},
  author = {Deutsch, P.},
  year = {1967},
  month = apr,
  url = {http://www.softwarepreservation.org/projects/LISP/bbnlisp/W-21_LISP_Editor_Apr67.pdf/view},
  abstract = {The editor described here is implemented within the PDP-l and SDS 940 time-sharing LISP systems, but can be used with minor changes within any LISP system which includes the capabilities of LISP 1.5. It was begun by the author in 1965 and later extended by Bobrow and Teitelman at BBN.},
  keywords = {Basic PDP-1 LISP,s2z}
}

@techreport{deutschStatusReportAlto1975,
  title = {Status Report on Alto Lisp},
  shorttitle = {Xerox},
  author = {Deutsch, P.},
  year = {1975},
  month = may,
  pages = {2},
  address = {Palo Alto},
  institution = {PARC/CSL},
  url = {http://www.bitsavers.org/pdf/xerox/alto/memos_1975/Status_Report_on_Alto_Lisp_May75.pdf},
  urldate = {2021-05-31},
  langid = {english},
  keywords = {Interlisp-D,lisp,s2z}
}

@article{DipmeterAdvisor2021,
  title = {Dipmeter Advisor},
  year = {2021},
  month = dec,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Dipmeter_Advisor&oldid=1060421060},
  urldate = {2022-06-27},
  abstract = {The Dipmeter Advisor was an early expert system developed in the 1980s by Schlumberger  with the help of artificial-intelligence workers at MIT to aid in the analysis of data gathered during oil exploration. The Advisor was generally not merely an inference engine and a knowledge base of \textasciitilde 90 rules, but generally was a full-fledged workstation, running on one of Xerox's 1100 Dolphin Lisp machines (or in general on Xerox's "1100 Series Scientific Information Processors" line) and written in INTERLISP-D, with a pattern recognition layer which in turn fed a GUI menu-driven interface. It was developed by a number of people, including Reid G. Smith, James D. Baker, and Robert L. Young.It was primarily influential not because of any great technical leaps, but rather because it was so successful for Schlumberger's oil divisions and because it was one of the few success stories of the AI bubble to receive wide publicity before the AI winter. The AI rules of the Dipmeter Advisor were primarily derived from Al Gilreath, a Schlumberger interpretation engineer who developed the "red, green, blue" pattern method of dipmeter interpretation. Unfortunately this method had limited application in more complex geological environments outside the Gulf Coast, and the Dipmeter Advisor was primarily used within Schlumberger as a graphical display tool to assist interpretation by trained geoscientists, rather than as an AI tool for use by novice interpreters. However, the tool pioneered a new approach to workstation-assisted graphical interpretation of geological information.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1060421060},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\JBB9W9ET\\Dipmeter_Advisor.html}
}

@misc{dyomkinRunningLispProduction2015,
  type = {Blog},
  title = {Running Lisp in Production},
  author = {Dyomkin, Vsevolod},
  year = {2015},
  month = jun,
  journal = {Running Lisp in Production | Grammarly Engineering Blog},
  url = {https://www.grammarly.com/blog/engineering/running-lisp-in-production/},
  urldate = {2022-02-02},
  abstract = {At Grammarly, the foundation of our business, our core grammar engine, is written in Common Lisp. It currently processes more than a thousand sentences per…},
  langid = {english},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\ITDSP2U5\\running-lisp-in-production.html}
}

@article{ehrlichConversationAustinHenderson1998,
  title = {A Conversation with Austin Henderson},
  author = {Ehrlich, Kate},
  year = {1998},
  month = nov,
  journal = {Interactions},
  volume = {5},
  number = {6},
  pages = {36--47},
  issn = {1072-5520},
  doi = {10.1145/287821.287827},
  url = {https://doi.org/10.1145/287821.287827},
  urldate = {2021-04-15},
  keywords = {sz}
}

@inproceedings{eisenbergExpressiveProgramsPresentation2007,
  title = {Expressive Programs through Presentation Extension},
  booktitle = {Proceedings of the 6th International Conference on Aspect-Oriented Software Development},
  author = {Eisenberg, Andrew D. and Kiczales, Gregor},
  year = {2007},
  month = mar,
  series = {AOSD '07},
  pages = {73--84},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1218563.1218573},
  url = {https://doi.org/10.1145/1218563.1218573},
  urldate = {2021-04-15},
  abstract = {Most approaches to programming language extensibility have worked by pairing syntactic extension with semantic extension. We present an approach that works through a combination of presentation extension and semantic extension. We also present an architecture for this approach, an Eclipse-based implementation targeting the Java programming language, and examples that show how presentation extension, both with and without semantic extension, can make programs more expressive.},
  isbn = {978-1-59593-615-7},
  keywords = {annotations,expressiveness,metadata,metaobject protocol,MOP,sz}
}

@inproceedings{emanuelsonCompilingEmbeddedLanguages1980,
  title = {On Compiling Embedded Languages in LISP},
  booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
  author = {Emanuelson, Pär and Haraldsson, Anders},
  year = {1980},
  month = aug,
  series = {LFP '80},
  pages = {208--215},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800087.802808},
  url = {https://doi.org/10.1145/800087.802808},
  urldate = {2021-04-25},
  abstract = {In INTERLISP we find a number of embedded languages such as the iterative statement and the pattern match facility in the CLISP package, the editor and makefile languages and so forth. We will in this paper concentrate on the problem of extending the LISP language and discuss a method to compile such extensions. We propose the language to be implemented through an interpreter (written in LISP) and that compilation of statements in such an embedded language is done through partial evaluation. The interpreter is partially evaluated with respect to the actual statements, and an object program in LISP is obtained. This LISP code can further be compiled to machine code by the standard LISP compiler. We have implemented the iterative statement and a CLISP-like pattern matcher and used a program manipulation system to generate object programs in LISP. Comparisons will be made with the corresponding INTERLISP implementations, which use special purpose compilers in order to generate the LISP code.},
  isbn = {978-1-4503-7396-8},
  keywords = {sz}
}

@misc{EnergySavingStrategies,
  title = {Energy Saving Strategies in the Design of Mobile Device Applications | Elsevier Enhanced Reader},
  doi = {10.1016/j.suscom.2018.07.011},
  url = {https://reader.elsevier.com/reader/sd/pii/S2210537917303980?token=237C9A3A6F6CE0520313FDBA09E7DEEC5BBF6D71510258E3291FEBB95541281384084840CD00E14E374B015A3E7E7A5E&originRegion=us-east-1&originCreation=20230401030929},
  urldate = {2023-04-01},
  langid = {english}
}

@misc{experienceHypertext89Trip1990,
  title = {Hypertext'89 Trip Report: Article by Jakob Nielsen},
  shorttitle = {Hypertext'89 Trip Report},
  author = {Experience, World Leaders in Research-Based User},
  year = {1990},
  month = apr,
  journal = {Nielsen Norman Group},
  url = {https://www.nngroup.com/articles/trip-report-hypertext-89/},
  urldate = {2023-03-02},
  abstract = {Jakob Nielsen's trip report from the ACM Hypertext'89 conference. Includes summary of Meyrowitz' discussion of open integrating hypertext and the extent to which the Memex vision has been realized so far.},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\WCIHJFPE\\trip-report-hypertext-89.html}
}

@patent{fabbrizioMethodApparatusProgramming2010,
  title = {Method and Apparatus for a Programming Language Having Fully Undoable, Timed Reactive Instructions},
  author = {Fabbrizio, Giuseppe Di and Klarlund, Nils},
  year = {2010},
  month = jun,
  number = {US7734958B1},
  url = {https://patents.google.com/patent/US7734958B1/en},
  urldate = {2021-06-01},
  abstract = {A method and apparatus are described for a programming language with fully undoable, timed reactive instructions. More specifically, the present invention relates to providing a multi-modal user interface for controlling the execution of fully undoable programs. An embodiment of the present invention includes a method for providing a multi-modal user interface that is enabled to control the order of execution of a program having fully undoable instructions using checkpoints associated with discrete locations within the program.},
  assignee = {AT\&T Intellectual Property II LP},
  nationality = {US},
  keywords = {displaying,modal,modal information,output,program,sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\RY38YC53\\Fabbrizio and Klarlund - 2010 - Method and apparatus for a programming language ha.pdf}
}

@misc{FAQLispImplementations1993,
  title = {FAQ: Lisp Implementations and Mailing Lists 4/7 [Monthly Posting] - [4-1] Commercial Common Lisp Implementations.},
  year = {1993},
  url = {https://www.cs.cmu.edu/Groups/AI/html/faqs/lang/lisp/part4/faq-doc-2.html},
  urldate = {2021-07-28},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\CTES72DT\\faq-doc-2.html}
}

@incollection{fatemanLisp2003,
  title = {Lisp},
  booktitle = {Encyclopedia of Computer Science},
  author = {Fateman, Richard and McCarthy, John},
  year = {2003},
  month = jan,
  pages = {991--992},
  publisher = {John Wiley and Sons Ltd.},
  url = {https://dl.acm.org/doi/10.5555/1074100.1074543},
  urldate = {2021-04-15},
  abstract = {Fortran (q.v.) is the only language in widespread use that is older than Lisp (LISt Processor). Lisp owes its longevity to two facts. First, its core elements occupy a kind of local optimum in the "space" of programming languages, given the resistance to purely notational changes. Recursive use of conditional expressions, representation of symbolic information externally by lists and internally by list data structures (q.v.), and the representation of programs in the same way as data will probably have a very long life.},
  isbn = {0-470-86412-5},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\T8EPTDXA\\Fateman and McCarthy - 2003 - Lisp.pdf}
}

@article{fialaMaxcSystems1978,
  title = {The Maxc Systems},
  author = {Fiala, E. R.},
  year = {1978},
  journal = {Computer},
  volume = {11},
  number = {11},
  pages = {57--67},
  publisher = {Institute of Electrical and Electronics Engineers},
  issn = {0018-9162},
  doi = {10.1109/c-m.1978.218184},
  url = {https://web.archive.org/web/2017/https://www.computer.org/web/csdl/index/-/csdl/mags/co/1978/05/01646959.pdf},
  urldate = {2021-07-18},
  langid = {english},
  annotation = {Fatcat ID: release\_q5bn52bkmvgfnfpyj3fa6wfnzy},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\STDRSGDZ\\Fiala - 1978 - The Maxc Systems.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\W7R5YP7V\\search.html}
}

@article{filmanInsertingIlitiesControlling2002,
  title = {Inserting Ilities by Controlling Communications},
  author = {Filman, Robert E. and Barrett, Stuart and Lee, Diana D. and Linden, Ted},
  year = {2002},
  month = jan,
  journal = {Communications of the ACM},
  volume = {45},
  number = {1},
  pages = {116--122},
  issn = {0001-0782},
  doi = {10.1145/502269.502274},
  url = {https://doi.org/10.1145/502269.502274},
  urldate = {2021-04-15},
  keywords = {sz}
}

@inproceedings{fininTranslatingKLOneInterlisp1982,
  title = {Translating KL-One from Interlisp to Franzlisp},
  booktitle = {Proceedings of the Second KL-One Workshop},
  author = {Finin, Tim},
  year = {1982},
  month = jun,
  pages = {106--114},
  publisher = {Bolt Beranek and Newman},
  url = {https://ebiquity.umbc.edu/paper/html/id/738/Translating-KL-One-from-interlisp-to-Franzlisp},
  urldate = {2021-06-01},
  abstract = {We describe an effort to translate the Interlisp KL-ONE system into Franzlisp to enable it to be run on a VAX . This effort has involved Tim Finin, Richard Duncan and Hassan Ait-Kaci from the University of Pennsylvania, Judy Weiner from Temple University, Jane Barnett from Computer Corporation of America and Jim Schmolze from Bolt Beranek and Newman. The primary motivation for this project was to make a version of KL-ONE available on a PDP 1 1/780 VAX . A VAX Interlisp is not yet available, although one is being written and will soon be available . Currently, the only substantial Lisp for a Vax is the Berkeley FranzLisp system. As a secondary motivation, we are interested in making KL-ONE more available in general - on a variety of Lisp dialects and machines.},
  langid = {english},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\GQ85BYLA\\Finin - 1982 - Translating KL-One from interlisp to Franzlisp.pdf}
}

@article{fisherMarvinMinsky192720162016,
  title = {Marvin Minsky: 1927-2016},
  shorttitle = {Marvin Minsky},
  author = {Fisher, Lawrence M.},
  year = {2016},
  month = mar,
  journal = {Communications of the ACM},
  volume = {59},
  number = {4},
  pages = {22--24},
  issn = {0001-0782},
  doi = {10.1145/2892716},
  url = {https://doi.org/10.1145/2892716},
  urldate = {2021-04-15},
  keywords = {sz}
}

@article{fletcherUnderstandingSolvingArithmetic1985,
  title = {Understanding and Solving Arithmetic Word Problems: A Computer Simulation},
  shorttitle = {Understanding and Solving Arithmetic Word Problems},
  author = {Fletcher, Charles R.},
  year = {1985},
  month = sep,
  journal = {Behavior Research Methods, Instruments, \& Computers},
  volume = {17},
  number = {5},
  pages = {565--571},
  issn = {0743-3808, 1532-5970},
  doi = {10.3758/BF03207654},
  url = {http://link.springer.com/10.3758/BF03207654},
  urldate = {2022-08-04},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\2ZRR6ZSM\\Fletcher - 1985 - Understanding and solving arithmetic word problems.pdf}
}

@incollection{floydParadigmsProgramming2007,
  title = {The Paradigms of Programming},
  booktitle = {ACM Turing Award Lectures},
  author = {Floyd, Robert W.},
  year = {2007},
  month = jan,
  pages = {396},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1283920.1283934},
  urldate = {2021-04-15},
  isbn = {978-1-4503-1049-9},
  keywords = {MACLISP,MYCIN program,sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\QZGD5QRW\\Floyd - 2007 - The paradigms of programming.pdf}
}

@article{foderaroLispEnvironments1987,
  title = {Lisp Environments},
  author = {Foderaro, John},
  year = {1987},
  month = jun,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {1},
  number = {2},
  pages = {33--35},
  issn = {1045-3563},
  doi = {10.1145/1317193.1317199},
  url = {https://doi.org/10.1145/1317193.1317199},
  urldate = {2021-04-25},
  abstract = {In this issue we survey the Lisp programming environment provided on the family of Lisp machines built by Xerox. These machines, which once ran only Interlisp-D, are now said to run 'Xerox Lisp' which is a combination of Interlisp-D and Common Lisp.},
  keywords = {sz}
}

@misc{FormatProposalsCleanup1988,
  title = {Format for Proposals to the Cleanup Committee (Version 14)},
  year = {1988},
  month = oct,
  url = {https://larrymasinter.net/cl-cleanup-proposal.txt},
  urldate = {2021-04-18},
  keywords = {sz}
}

@techreport{fosterCoLabToolsComputer,
  title = {CoLab, Tools for Computer Based Cooperation},
  author = {Foster, Gregg},
  number = {CSD-84-215},
  url = {https://digitalassets.lib.berkeley.edu/techreports/ucb/text/CSD-84-215.pdf},
  urldate = {2022-12-20},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\UK4LUYSV\\CSD-84-215.pdf}
}

@inproceedings{freemanTangibleActions2011,
  title = {Tangible Actions},
  booktitle = {Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces},
  author = {Freeman, Dustin and Balakrishnan, Ravin},
  year = {2011},
  month = nov,
  series = {ITS '11},
  pages = {87--96},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2076354.2076373},
  url = {https://doi.org/10.1145/2076354.2076373},
  urldate = {2021-04-15},
  abstract = {We present Tangible Actions, an ad-hoc, just-in-time, visual programming by example language designed for large multitouch interfaces. With the design of Tangible Actions, we contribute a continually-created system of programming tokens that occupy the same space as the objects they act on. Tangible Actions are created by the gestural actions of the user, and they allow the user to reuse and modify their own gestures with a lower interaction cost than the original gesture. We implemented Tangible Actions in three different tabletop applications, and ran an informal evaluation. While we found that study participants generally liked and understood Tangible Actions, having the objects and the actions co-located can lead to visual and interaction clutter.},
  isbn = {978-1-4503-0871-7},
  keywords = {end-user programming,gestures,multitouch,programming by example,scripting,sz,visual programming}
}

@incollection{friederShifting2003,
  title = {Shifting},
  booktitle = {Encyclopedia of Computer Science},
  author = {Frieder, Gideon},
  year = {2003},
  month = jan,
  pages = {1572--1573},
  publisher = {John Wiley and Sons Ltd.},
  address = {United Kingdom},
  url = {https://dl.acm.org/doi/abs/10.5555/1074100.1074788},
  urldate = {2021-06-02},
  abstract = {Shifting is the process of moving data in a storage device relative to the boundaries of the device (as opposed to moving it in and out of the device). The device in which the shift is performed is called a shift register. In order to discuss the various modes of the shift operation, we assume that the register in which the shift is to be performed is n bits wide, and number the bits from left to right, 1...n.},
  isbn = {0-470-86412-8},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\TB3ZHHZ8\\Frieder - 2003 - Shifting.pdf}
}

@article{friedlandSpecialSectionArchitectures1985,
  title = {Special Section on Architectures for Knowledge-Based Systems},
  author = {Friedland, Peter},
  year = {1985},
  month = sep,
  journal = {Communications of the ACM},
  volume = {28},
  number = {9},
  pages = {902--903},
  issn = {0001-0782},
  doi = {10.1145/4284.214937},
  url = {https://doi.org/10.1145/4284.214937},
  urldate = {2021-04-15},
  abstract = {A fundamental shift in the preferred approach to building applied artificial intelligence (AI) systems has taken place since the late 1960s. Previous work focused on the construction of general-purpose intelligent systems; the emphasis was on powerful inference methods that could function efficiently even when the available domain-specific knowledge was relatively meager. Today the emphasis is on the role of specific and detailed knowledge, rather than on reasoning methods. The first successful application of this method, which goes by the name of knowledge-based or expert-system research, was the DENDRAL program at Stanford, a long-term collaboration between chemists and computer scientists for automating the determination of molecular structure from empirical formulas and mass spectral data. The key idea is that knowledge is power, for experts, be they human or machine, are often those who know more facts and heuristics about a domain than lesser problem solvers. The task of building an expert system, therefore, is predominantly one of “teaching” a system enough of these facts and heuristics to enable it to perform competently in a particular problem-solving context. Such a collection of facts and heuristics is commonly called a knowledge base. Knowledge-based systems are still dependent on inference methods that perform reasoning on the knowledge base, but experience has shown that simple inference methods like generate and test, backward-chaining, and forward-chaining are very effective in a wide variety of problem domains when they are coupled with powerful knowledge bases. If this methodology remains preeminent, then the task of constructing knowledge bases becomes the rate-limiting factor in expert-system development. Indeed, a major portion of the applied AI research in the last decade has been directed at developing techniques and tools for knowledge representation. We are now in the third generation of such efforts. The first generation was marked by the development of enhanced AI languages like Interlisp and PROLOG. The second generation saw the development of knowledge representation tools at AI research institutions; Stanford, for instance, produced EMYCIN, The Unit System, and MRS. The third generation is now producing fully supported commercial tools like KEE and S.1. Each generation has seen a substantial decrease in the amount of time needed to build significant expert systems. Ten years ago prototype systems commonly took on the order of two years to show proof of concept; today such systems are routinely built in a few months. Three basic methodologies—frames, rules, and logic—have emerged to support the complex task of storing human knowledge in an expert system. Each of the articles in this Special Section describes and illustrates one of these methodologies. “The Role of Frame-Based Representation in Reasoning,” by Richard Fikes and Tom Kehler, describes an object-centered view of knowledge representation, whereby all knowldge is partitioned into discrete structures (frames) having individual properties (slots). Frames can be used to represent broad concepts, classes of objects, or individual instances or components of objects. They are joined together in an inheritance hierarchy that provides for the transmission of common properties among the frames without multiple specification of those properties. The authors use the KEE knowledge representation and manipulation tool to illustrate the characteristics of frame-based representation for a variety of domain examples. They also show how frame-based systems can be used to incorporate a range of inference methods common to both logic and rule-based systems. "Rule-Based Systems,” by Frederick Hayes-Roth, chronicles the history and describes the implementation of production rules as a framework for knowledge representation. In essence, production rules use IF conditions THEN conclusions and IF conditions THEN actions structures to construct a knowledge base. The autor catalogs a wide range of applications for which this methodology has proved natural and (at least partially) successful for replicating intelligent behavior. The article also surveys some already-available computational tools for facilitating the construction of rule-based knowledge bases and discusses the inference methods (particularly backward- and forward-chaining) that are provided as part of these tools. The article concludes with a consideration of the future improvement and expansion of such tools. The third article, “Logic Programming, ” by Michael Genesereth and Matthew Ginsberg, provides a tutorial introduction to the formal method of programming by description in the predicate calculus. Unlike traditional programming, which emphasizes how computations are to be performed, logic programming focuses on the what of objects and their behavior. The article illustrates the ease with which incremental additions can be made to a logic-oriented knowledge base, as well as the automatic facilities for inference (through theorem proving) and explanation that result from such formal descriptions. A practical example of diagnosis of digital device malfunctions is used to show how significantand complex problems can be represented in the formalism. A note to the reader who may infer that the AI community is being split into competing camps by these three methodologies: Although each provides advantages in certain specific domains (logic where the domain can be readily axiomatized and where complete causal models are available, rules where most of the knowledge can be conveniently expressed as experiential heuristics, and frames where complex structural descriptions are necessary to adequately describe the domain), the current view is one of synthesis rather than exclusivity. Both logic and rule-based systems commonly incorporate frame-like structures to facilitate the representation of large amounts of factual information, and frame-based systems like KEE allow both production rules and predicate calculus statements to be stored within and activated from frames to do inference. The next generation of knowledge representation tools may even help users to select appropriate methodologies for each particular class of knowledge, and then automatically integrate the various methodologies so selected into a consistent framework for knowledge.},
  keywords = {sz}
}

@incollection{fuquaListProcessing2003,
  title = {List Processing},
  booktitle = {Encyclopedia of Computer Science},
  author = {Fuqua, Paul and Slagle, James R. and Gini, Maria L.},
  year = {2003},
  month = jan,
  pages = {992--1000},
  publisher = {John Wiley and Sons Ltd.},
  address = {GBR},
  url = {https://dl.acm.org/doi/10.5555/1074100.1074544},
  urldate = {2021-04-15},
  abstract = {The two elements of a computer program are the computations (the actions we want done) and the data (the things we want the actions done upon). The computations are defined using expressions in a computer language, combined to form procedures, which are in turn combined to form compound procedures and eventually programs. The ability to combine simple expressions into procedures is the key to using computer programs to model processes in the real world. Data is defined in a similar way: compound data objects are built from simple parts, like numbers, and combined to represent real-world objects that have complex properties. Compound procedures and compound data are used for the same purposes: to improve the modularity of the program and to raise the conceptual level of its design. One of the simplest and most widespread form of compound data is the list.},
  isbn = {0-470-86412-5},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\48XK7MZW\\Fuqua et al. - 2003 - List processing.pdf}
}

@article{gabrielLispGoodNews1991,
  title = {Lisp: Good News, Bad News, How to Win Big},
  author = {Gabriel, Richard P.},
  year = {1991},
  journal = {Dreamsongs},
  url = {https://dreamsongs.com/WIB.html},
  urldate = {2021-04-25},
  abstract = {Lisp has done quite well over the last ten years: becoming nearly standardized, forming the basis of a commercial sector, achieving excellent performance, having good environments, able to deliver applications. Yet the Lisp community has failed to do as well as it could have. In this paper I look at the successes, the failures, and what to do next.},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\DSIAM556\\WIB.html}
}

@inproceedings{gabrielPatternLanguageEvolution2008,
  title = {A Pattern of Language Evolution},
  booktitle = {Celebrating the 50th Anniversary of Lisp},
  author = {Gabriel, Richard P. and Steele, Guy L.},
  year = {2008},
  month = oct,
  series = {LISP50},
  pages = {1--10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1529966.1529967},
  url = {https://doi.org/10.1145/1529966.1529967},
  urldate = {2021-04-23},
  abstract = {In 1992 when we completed our first draft of the History of Programming Languages II paper, The Evolution of Lisp [1], it included sections on a theory or model of how complex language families like Lisp grew and evolved, and in particular, how and when diversity would bloom and consolidation would prune. The historian who worked with all the HOPL II authors, Michael S. Mahoney, did not believe our theory was substantiated properly, so he recommended removing the material and sticking with the narrative of Lisp's evolution. We stopped working on those sections, but they remained in the original text sources but removed with conditionals.},
  isbn = {978-1-60558-383-9},
  keywords = {sz}
}

@book{gabrielPerformanceEvaluationLISP1985,
  title = {Performance and Evaluation of LISP Systems},
  author = {Gabriel, Richard P.},
  year = {1985},
  month = jan,
  publisher = {Massachusetts Institute of Technology},
  address = {USA},
  url = {https://dreamsongs.com/Files/Timrep.pdf},
  abstract = {The final report of the Stanford Lisp Performance Study, Performance and Evaluation of Lisp Systems is the first book to present descriptions on Lisp implementation techniques actually in use. It provides performance information using the tools of benchmarking to measure the various Lisp systems, and provides an understanding of the technical tradeoffs made during the implementation of a Lisp system. The study is divided into three parts. The first provides the theoretical background, outlining the factors that go into evaluating the performance of a Lisp system. The second part presents the Lisp implementations: MacLisp, MIT CADR, LMI Lambda, S-I Lisp, Franz Lisp, MIL, Spice Lisp, Vax Common Lisp, Portable Standard Lisp, and Xerox D-Machine. A final part describes the benchmark suite that was used during the major portion of the study and the results themselves.},
  isbn = {978-0-262-07093-5},
  keywords = {sz}
}

@book{gabrielPerformanceEvaluationLISP1985a,
  title = {Performance and Evaluation of LISP Systems},
  author = {Gabriel, Richard P.},
  year = {1985},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/5298.001.0001},
  url = {https://direct.mit.edu/books/book/3870/performance-and-evaluation-of-lisp-systems},
  urldate = {2021-10-23},
  isbn = {978-0-262-25619-3},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\UQ8T78QY\\Gabriel - 1985 - Performance and Evaluation of LISP Systems.pdf}
}

@inproceedings{gabrielQueuebasedMultiprocessingLISP1984,
  title = {Queue-Based Multi-Processing LISP},
  booktitle = {Proceedings of the 1984 ACM Symposium on LISP and Functional Programming},
  author = {Gabriel, Richard P. and McCarthy, John},
  year = {1984},
  month = aug,
  series = {LFP '84},
  pages = {25--44},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800055.802019},
  url = {https://doi.org/10.1145/800055.802019},
  urldate = {2021-06-02},
  abstract = {As the need for high-speed computers increases, the need for multi-processors will be become more apparent. One of the major stumbling blocks to the development of useful multi-processors has been the lack of a good multi-processing language—one which is both powerful and understandable to programmers. Among the most compute-intensive programs are artificial intelligence (AI) programs, and researchers hope that the potential degree of parallelism in AI programs is higher than in many other applications. In this paper we propose multi-processing extensions to Lisp. Unlike other proposed multi-processing Lisps, this one provides only a few very powerful and intuitive primitives rather than a number of parallel variants of familiar constructs.},
  isbn = {978-0-89791-142-3},
  keywords = {sz}
}

@patent{gendronComputerBasedWorkstation1989,
  title = {Computer Based Workstation for Development of Graphic Representation of Computer Programs},
  author = {Gendron, Robert F. and {E. Webb Stacy} and {Jr.Tudor V. Ionescu}},
  year = {1989},
  month = aug,
  number = {US4860204A},
  url = {https://patents.google.com/patent/US4860204A},
  urldate = {2021-04-16},
  abstract = {A workstation that employs methods to construct computer programs through use of visual graphical representations. Computer programs are illustrated as visual road maps of the intended sequence of actions. Each operational entity in a program graph on the screen is represented as an elemental "atomic" unit, called a "Softron". The Softron is a multidimensional, graphical "atom" of programming information which has four modes of operation, termed "layers". The four layers are Normal, where the basic functionally of the application resides; Initialization/Reset, responsible both for the startup values of important variables and for their values at strategic checkpoints; Error, which handles conditions outside design limits; and Input/Output, which performs human input/output and other I/O tasks. Softrons reside in very general form in the workstation's library, and are optimized by the process of specialization. Softrons may be grouped to form new Softrons by a process called Logical Zoom (TM). Logically Zoomed Softrons may combine with other Softrons to form a computer program of arbitrary complexity.},
  assignee = {Softron, Inc.},
  nationality = {United States},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\YM7SHTJ4\\Gendron - 1989 - Computer based workstation for development of grap.pdf}
}

@article{gladwinReviewInterlispLanguage1987,
  title = {Review of Interlisp: The Language and Its Usage},
  shorttitle = {Interlisp},
  author = {Gladwin, Lee A. and Gladwin, Lee A.},
  year = {1987},
  month = jul,
  journal = {IEEE Intelligent Systems},
  volume = {2},
  number = {03},
  pages = {94--94},
  publisher = {IEEE Computer Society},
  issn = {1541-1672},
  doi = {10.1109/MEX.1987.4307102},
  url = {https://www.computer.org/csdl/magazine/ex/1987/03/04307102/1e7uj6wTMVG},
  urldate = {2021-05-31},
  langid = {english},
  keywords = {interlisp,s2z}
}

@inproceedings{goldmanSoftwareEvolutionIterative1992,
  title = {Software Evolution through Iterative Prototyping},
  booktitle = {Proceedings of the 14th International Conference on Software Engineering},
  author = {Goldman, Neil and Narayanaswamy, K.},
  year = {1992},
  month = jun,
  series = {ICSE '92},
  pages = {158--172},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/143062.143109},
  url = {https://doi.org/10.1145/143062.143109},
  urldate = {2021-04-15},
  abstract = {The process of developing and evolving complex software systems is intrinsically exploratory in nature. Some prototyping activity is therefore inevitable in every stage of that process. Our program development and evolution methodology is predicated upon this observation. In this methodology, a prototype software system is developed as an approximation to an envisioned target system by compromising along one or more of the following dimensions: system performance, system functionality, or user interface. However, the prototype is not the end-product of the process. Instead, we support iterative evolution of the prototype towards the envisioned system by gradually dealing with the three general areas of compromise. This paper describes the methodology of using this alternative lifecycle; to wit, the programming language concepts and related implementation technology that support practice of the suggested methodology. We summarize the lessons we have learned in building and using this technology over the last several years.},
  isbn = {978-0-89791-504-5},
  keywords = {sz}
}

@patent{greenfeldApparatusAnalyzingSource1990,
  title = {Apparatus for Analyzing Source Code},
  author = {Greenfeld, Norton R.},
  year = {1990},
  month = jun,
  number = {US4931928A},
  url = {https://patents.google.com/patent/US4931928A},
  urldate = {2021-04-16},
  abstract = {Apparatus in a computer system provides source code analysis. The apparatus includes an analysis member which extracts programming semantics information from an input source code. The analysis member operates according to the programming language of the source code as defined by a grammar mechanism. The analysis member employs a database interface which enables the extracted programming semantics information to be placed in a user desired database for subsequent recall by a desired query system. The database and query system may be pre-existing elements which are supported by a digital processor independently of the analysis member. A relational database with an SQL query system may be used.},
  assignee = {Greenfeld Norton R},
  nationality = {United States},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\VKSL4IDF\\Greenfeld - 1990 - Apparatus for analyzing source code.pdf}
}

@article{greussayIterativeInterpretationTailrecursive1978,
  title = {Iterative Interpretation of Tail-Recursive LISP Procedures},
  author = {Greussay, Patrick},
  year = {1978},
  month = jul,
  journal = {ACM Lisp Bulletin},
  number = {2},
  pages = {35--46},
  doi = {10.1145/1411798.1411809},
  url = {https://doi.org/10.1145/1411798.1411809},
  urldate = {2021-04-25},
  abstract = {The design of a LISP interpreter that allows tail-recursive procedures to be interpreted iteratively is presented at the machine-language level. Iterative interpretation means that, without any program transformations, no environments and continuations will be stacked unless necessary. We apply a specific modification within a traditional stack-oriented version of LISP interpreter, without any non-recursive control structure. The design is compatible with value-cells as well as a-lists LISP processors. We present a complete modified interpreter written itself in LISP and an informal proof that it meets its requirements.},
  keywords = {sz}
}

@misc{gumbyManyPeopleWho2023,
  title = {Many People Who Read about Lisp Machines Are Not Aware That the InterLisp-D Worl... | Hacker News},
  author = {{gumby}},
  year = {2023},
  month = jan,
  journal = {Hacker News},
  url = {https://news.ycombinator.com/item?id=34301284},
  urldate = {2023-02-25},
  abstract = {Many people who read about Lisp Machines are not aware that the InterLisp-D world and the MIT world (CADR, LMI, Symbolics etc) had significantly different approaches to how the systems should work, so even if you have read or used the MIT-style systems you will learn a lot by using Medley. I came from MIT out to PARC for a year, and later moved CYC from D machines to Symbolics machines (a complete reimplementation using a different fundamental architecture) so have good experiences with them both. At heart, the InterLisp language itself isn't that different from MIT lisps, as Interlisp started down the road at BBN and there was a lot of cross fertilization in both directions. And CommonLisp, while heavily based on the "MIT" model has a lot of Interlisp influence in it.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\L2PNFTBE\\item.html}
}

@article{halaszNotecardsNutshell1986,
  title = {Notecards in a Nutshell},
  author = {Halasz, Frank G. and Moran, Thomas P. and Trigg, Randall H.},
  year = {1986},
  month = may,
  journal = {ACM SIGCHI Bulletin},
  volume = {17},
  number = {SI},
  pages = {45--52},
  issn = {0736-6906},
  doi = {10.1145/30851.30859},
  url = {https://doi.org/10.1145/30851.30859},
  urldate = {2023-03-03},
  abstract = {NoteCards is an extensible environment designed to help people formulate, structure, compare, and manage ideas. NoteCards provides the user with a “semantic network” of electronic notecards interconnected by typed links. The system provides tools to organize, manage, and display the structure of the network, as well as a set of methods and protocols for creating programs to manipulate the information in the network. NoteCards is currently being used by more than 50 people engaged in idea processing tasks ranging from writing research papers through designing parts for photocopiers. In this paper we briefly describe NoteCards and the conceptualization of idea processing tasks that underlies its design. We then describe the NoteCards user community and several prototypical NoteCards applications. Finally, we discuss what we have learned about the system's strengths and weaknesses from our observations of the NoteCards user community.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\YGDJGRBI\\Halasz et al. - 1986 - Notecards in a nutshell.pdf}
}

@article{halaszReflectionsNoteCardsSeven1988,
  title = {Reflections on NoteCards: Seven Issues for the next Generation of Hypermedia Systems},
  shorttitle = {Reflections on NoteCards},
  author = {Halasz, G., Frank},
  year = {1988},
  month = jul,
  journal = {Communications of the ACM},
  volume = {31},
  number = {7},
  pages = {836--852},
  issn = {0001-0782},
  doi = {10.1145/48511.48514},
  url = {https://doi.org/10.1145/48511.48514},
  urldate = {2023-03-03},
  abstract = {NoteCards, developed by a team at Xerox PARC, was designed to support the task of transforming a chaotic collection of unrelated thoughts into an integrated, orderly interpretation of ideas and their interconnections. This article presents NoteCards as a foil against which to explore some of the major limitations of the current generation of hypermedia systems, and characterizes the issues that must be addressed in designing the next generation systems.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\KWFC2LVE\\Halasz - 1988 - Reflections on NoteCards seven issues for the nex.pdf}
}

@misc{hansenIntroducingSmalltalkZoo2020,
  title = {Introducing the Smalltalk Zoo},
  author = {Hansen, Hsu},
  year = {2020},
  month = dec,
  journal = {CHM},
  url = {https://computerhistory.org/blog/introducing-the-smalltalk-zoo-48-years-of-smalltalk-history-at-chm/},
  urldate = {2021-08-03},
  abstract = {In commemoration of the 40th anniversary of the release of Smalltalk-80, the Computer History Museum is proud to announce a collaboration with Dan Ingalls to preserve and host the “Smalltalk Zoo.”},
  chapter = {Software History Center},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\QZILQA7B\\introducing-the-smalltalk-zoo-48-years-of-smalltalk-history-at-chm.html}
}

@book{harmonExpertSystemsTools1988,
  title = {Expert Systems: Tools and Applications},
  shorttitle = {Expert Systems},
  author = {Harmon, Paul and Maus, Rex and Morrissey, William},
  year = {1988},
  publisher = {Wiley},
  address = {New York},
  url = {http://www.loc.gov/catdir/description/wiley034/87017608.html},
  abstract = {Paul Harmon's 1985 classic Expert Systems: Artificial Intelligence in Business (with David King) gave many professionals their first taste of Al technology. Now Harmon returns, along with management training specialists William Morrissey and Rex Maus, with this timely, in-depth look at the enormous number of expert system-building tools and commercial appli- cations now available. Expert Systems Tools and Applications gives you a complete overview of today's expert system market-where it is and where it's going, how to use available expert system-building tools to facilitate the development of expert system applications, plus everything you'll want to consider when purchasing the latest Al applications, from capabilities to costs to hardware requirements. Expert Systems Tools and Applications features: • Small, mid-size, and large rule-based expert system-building tools as well as inductive and hybrid tools-with summary compari- sons to help you decide which tools best suit your business needs • Step-by-step guidance through the development stage-from task analysis, knowledge engineering, and prototype development to field-testing, implementing and maintaining the system • A complete catalog of available commercial expert system applications, organized by business area-from sales, management, and operations to programming, research, and service industries If you're an executive, middle manager, or computer professional who's ready to extend your company's expert system efforts, Expert Systems Tools and Applications offers the technical advice and information you need to make informed Al decisions for improving the performance of your company. PAUL HARMON, internationally recognized journalist and lecturer, edits Expert Systems Strategies, a monthly newsletter. WILLIAM MORRISSEY, Senior Consultant and Partner in Harmon Associates, manages the com- pany's Workshops Division. REX MAUS is a management consultant who specializes in computer-related documentation and training.},
  isbn = {978-0-471-83950-7 978-0-471-83951-4},
  langid = {english},
  lccn = {HF5548.2 .H367 1988},
  keywords = {Artificial intelligence -- History,Business,Data processing,Expert systems (Computer science)}
}

@article{harrisonReviewProgrammingLanguage1967,
  title = {Review of The Programming Language LISP: Its Operation and Applications},
  shorttitle = {Review of The Programming Language LISP},
  author = {Harrison, Malcolm},
  year = {1967},
  journal = {Mathematics of Computation},
  volume = {21},
  number = {99},
  eprint = {2003282},
  eprinttype = {jstor},
  pages = {518--519},
  publisher = {American Mathematical Society},
  issn = {0025-5718},
  doi = {10.2307/2003282},
  url = {https://www.jstor.org/stable/2003282},
  urldate = {2021-06-01},
  abstract = {An introduction to LISP is given on an elementary level. Topics covered include the programming system, 240 exercises with solutions, debugging of LISP programs, and styles of programming. More advanced discussions are contained in the following articles: Techniques using LISP for automatically discovering interesting relations in data; Automation, using LISP, of inductive inference on sequences; Application of LISP to machine checking of mathematical proofs; METEOR: A LISP interpreter for string transformations; Notes on implementing LISP for the M-460 computer; LISP as the language for an incremental computer; The LISP system for the Q-2 computer; An auxiliary language for more natural expression -- the A-language. Some applications of the utilization of the LISP programming language are given in the appendices.},
  collaborator = {Berkeley, Edmund C. and Bobrow, Daniel G.},
  keywords = {sz}
}

@article{hendersonRoomsUseMultiple1986,
  title = {Rooms: The Use of Multiple Virtual Workspaces to Reduce Space Contention in a Window-Based Graphical User Interface},
  shorttitle = {Rooms},
  author = {Henderson, D. Austin Jr. and Card, Stuart K.},
  year = {1986},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {5},
  number = {3},
  pages = {211--243},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/24054.24056},
  url = {https://dl.acm.org/doi/10.1145/24054.24056},
  urldate = {2023-02-14},
  abstract = {A key constraint on the effectiveness of window-based human-computer interfaces is that the display screen is too small for many applications. This results in “window thrashing,” in which the user must expend considerable effort to keep desired windows visible. Rooms is a window manager that overcomes small screen size by exploiting the statistics of window access, dividing the user's workspace into a suite of virtual workspaces with transitions among them. Mechanisms are described for solving the problems of navigation and simultaneous access to separated information that arise from multiple workspaces.},
  langid = {english}
}

@inproceedings{hendersonTrilliumUserInterface1986,
  title = {The Trillium User Interface Design Environment},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  author = {Henderson, D. A.},
  year = {1986},
  month = apr,
  series = {CHI '86},
  pages = {221--227},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/22627.22375},
  url = {https://doi.org/10.1145/22627.22375},
  urldate = {2023-02-14},
  abstract = {Trillium is a computer-based environment for simulating and experimenting with interfaces for simple machines. For the past four years it has been use by Xerox designers for fast prototyping and testing of interfaces for copiers and printers. This paper defines the class of “functioning frame” interfaces which Trillium is used to design, discusses the major concerns that have driven the design of Trillium, and describes the Trillium mechanisms chosen to satisfy them.},
  isbn = {978-0-89791-180-1}
}

@patent{hendersonUserInterfaceMultiple1991,
  title = {User Interface with Multiple Workspaces for Sharing Display System Objects},
  author = {Henderson, D. Austin and Card, Stuart K. and Maxwell, John T.},
  year = {1991},
  month = dec,
  number = {US5072412A},
  url = {https://patents.google.com/patent/US5072412A/en},
  urldate = {2021-06-01},
  abstract = {Workspaces provided by an object-based user interface appear to share windows and other display objects. Each workspace's data structure includes, for each window in that workspace, a linking data structure called a placement which links to the display system object which provides that window, which may be a display system object in a preexisting window system. The placement also contains display characteristics of the window when displayed in that workspace, such as position and size. Therefore, a display system object can be linked to several workspaces by a placement in each of the workspaces' data structures, and the window it provides to each of those workspaces can have unique display characteristics, yet appear to the user to be the same window or versions of the same window. As a result, the workspaces appear to be sharing a window. Workspaces can also appear to share a window if each workspace's data structure includes data linking to another workspace with a placement to the shared window. The user can invoke a switch between workspaces by selecting a display object called a door, and a back door to the previous workspace is created automatically so that the user is not trapped in a workspace. A display system object providing a window to a workspace being left remains active so that when that workspace is reentered, the window will have the same contents as when it disappeared. Also, the placements of a workspace are updated so that when the workspace is reentered its windows are organized the same as when the user left that workspace. The user can enter an overview display which shows a representation of each workspace and the windows it contains so that the user can navigate to any workspace from the overview.},
  assignee = {Xerox Corp},
  nationality = {US},
  keywords = {accessing,data,display,objects,workspace},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\2PTESCDF\\Jr et al. - 1991 - User interface with multiple workspaces for sharin.pdf}
}

@misc{IndustryBriefs,
  title = {Industry Briefs},
  journal = {The Scientist Magazine®},
  url = {https://www.the-scientist.com/briefs/industry-briefs-61883},
  urldate = {2023-04-29},
  abstract = {Tables Turn For Xerox Spin-Off Although Envos Corp., an artificial intelligence spin-off of the Xerox Corp., folded back into Xerox last spring after nine months in operation, the parent company is “absolutely” committed to developing similar ventures in the future, according to Xerox spokesman Peter Hawes. “We have been trying to identify [Xerox] technologies,” says Hawes, “and choose which. ..might lend themselves to alternative exploitation.” Envos, which},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\3UQDW85M\\industry-briefs-61883.html}
}

@misc{ingallsPLDI2021Evolution2021,
  title = {PLDI 2021: The Evolution of Smalltalk from Smalltalk-72 through Squeak},
  author = {Ingalls, Daniel},
  year = {2021},
  month = jun,
  journal = {The Evolution of Smalltalk from Smalltalk-72 through Squeak},
  url = {https://www.pldi21.org/prerecorded_hopl.17.html},
  urldate = {2021-09-04},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\HXCDYIN9\\prerecorded_hopl.17.html}
}

@misc{InterlispWasSocalled2013,
  type = {Forums},
  title = {Interlisp Was the So-Called "West Coast" Lisp That Emphasized an Interactive pro... | Hacker News},
  year = {2013},
  month = jun,
  url = {https://news.ycombinator.com/item?id=5966399},
  urldate = {2023-04-29},
  langid = {english},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\MB3VSCEZ\\item.html}
}

@misc{InternationalLispConference2014,
  title = {International Lisp Conference 2014},
  year = {2014},
  month = aug,
  url = {http://ilc2014.iro.umontreal.ca/},
  urldate = {2021-04-26},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\N2DZUKLD\\ilc2014.iro.umontreal.ca.html}
}

@book{J778SYSREMDOC1972,
  title = {J778.SYSREM DOC on SYS05 (LISP Features Dsigned to Aid the LISP Programmer)},
  year = {1972},
  series = {Gift of Larry Masinter},
  publisher = {Masinter},
  annotation = {Catalog Number: 102721861 Category: Program Listing Credit: Gift of Larry Masinter}
}

@article{jainExpertSystemsManagement1989,
  title = {Expert Systems: A Management Perspective},
  shorttitle = {Expert Systems},
  author = {Jain, Rekha},
  year = {1989},
  month = oct,
  journal = {Vikalpa: The Journal for Decision Makers},
  volume = {14},
  number = {4},
  pages = {17--28},
  issn = {0256-0909, 2395-3799},
  doi = {10.1177/0256090919890404},
  url = {http://journals.sagepub.com/doi/10.1177/0256090919890404},
  urldate = {2021-04-15},
  abstract = {Expert systems are computer programmes that can reproduce the behaviour of human experts in specific problem domains. In many places, development of expert systems is the major focus of fifth generation software projects. Accordingly, enormous amounts of resources are being spent on work in this field. Expert systems have enjoyed considerable success in many scientific and technological applications but their application in the field of management. is relatively recent.             In this article, Rekha Jain presents an overview of expert systems and addresses several issues that will be of interest to managers who are likely to consider using expert systems in their organizations.},
  langid = {english},
  keywords = {sz}
}

@patent{jano.pedersenIterativeTechniquePhrase1994,
  title = {Iterative Technique for Phrase Query Formation and an Information Retrieval...},
  author = {{Jan O. Pedersen} and {Per-Kristian Halvorsen} and {Douglass R. Cutting} and {John W. Tukey} and {Eric A. Bier} and {Daniel G. Bobrow}},
  year = {1994},
  month = jan,
  number = {US5278980A},
  url = {https://patents.google.com/patent/US5278980A},
  urldate = {2021-04-16},
  abstract = {An information retrieval system and method are provided in which an operator inputs one or more query words which are used to determine a search key for searching through a corpus of documents, and which returns any matches between the search key and the corpus of documents as a phrase containing the word data matching the query word(s), a non-stop (content) word next adjacent to the matching word data, and all intervening stop-words between the matching word data and the next adjacent non-stop word. The operator, after reviewing one or more of the returned phrases can then use one or more of the next adjacent non-stop-words as new query words to reformulate the search key and perform a subsequent search through the document corpus. This process can be conducted iteratively, until the appropriate documents of interest are located. The additional non-stop-words from each phrase are preferably aligned with each other (e.g., by columnation) to ease viewing of the "new" content words.},
  assignee = {Xerox Corporation},
  nationality = {United States},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\5KWEQUUY\\Pedersen - 1994 - Iterative technique for phrase query formation and.pdf}
}

@inproceedings{jayaprakashPLispFriendlyLisp2018,
  title = {pLisp: A Friendly Lisp IDE for Beginners},
  shorttitle = {pLisp},
  booktitle = {Proceedings of the 11th European Lisp Symposium on European Lisp Symposium},
  author = {Jayaprakash, Rajesh},
  year = {2018},
  month = apr,
  series = {ELS2018},
  pages = {66--67},
  publisher = {European Lisp Scientific Activities Association},
  address = {Marbella, Spain},
  url = {https://dl.acm.org/doi/10.5555/3323215.3323224},
  urldate = {2021-06-02},
  abstract = {This abstract describes the design and implementation of pL isp, a Lisp dialect and integrated development environment modeled on Smalltalk that targets beginners},
  isbn = {978-2-9557474-2-1},
  keywords = {Integrated Development Environment,Lisp,sz}
}

@article{jekkaraInterlisp2021,
  title = {Interlisp},
  editor = {{Jekkara}},
  year = {2021},
  month = mar,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Interlisp&oldid=1014034897},
  urldate = {2021-04-21},
  abstract = {Interlisp (also seen with a variety of capitalizations) is a programming environment built around a version of the programming language Lisp. Interlisp development began in 1966 at Bolt, Beranek and Newman (renamed BBN Technologies) in Cambridge, Massachusetts with Lisp implemented for the Digital Equipment Corporation (DEC) PDP-1 computer by Danny Bobrow and D. L. Murphy. In 1970, Alice K. Hartley implemented BBN LISP, which ran on PDP-10 machines running the operating system TENEX (renamed TOPS-20). In 1973, when Danny Bobrow, Warren Teitelman and Ronald Kaplan moved from BBN to the Xerox Palo Alto Research Center (PARC), it was renamed Interlisp. Interlisp became a popular Lisp development tool for artificial intelligence (AI) researchers at Stanford University and elsewhere in the community of the Defense Advanced Research Projects Agency (DARPA). Interlisp was notable for integrating interactive development tools into an integrated development environment (IDE), such as a debugger, an automatic correction tool for simple errors (via do what I mean (DWIM) software design, and analysis tools.},
  langid = {english},
  keywords = {sz}
}

@inproceedings{jellinekOdradekPrologBasedLisp1984,
  title = {Odradek - A Prolog-Based Lisp Translator},
  booktitle = {Proceedings / Seventh Annual MICRO-DELCON '84, the Delaware Bay Computer Conference, [March, 6, 1984, John M. Clayton Hall, University of Delaware, Newark]},
  author = {Jellinek, Herb},
  editor = {IEEE Computer Society},
  year = {1984},
  publisher = {IEEE Computer Society Press},
  address = {Silver Spring, Md},
  isbn = {978-0-8186-0554-3 978-0-8186-4554-9 978-0-8186-8554-5},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\NWVR4DXH\\Jellinek - 1984 - Odradek - A Prolog-Based Lisp Translator.pdf}
}

@inproceedings{jellinekPowermiceUserPerformance1990,
  title = {Powermice and User Performance},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  author = {Jellinek, Herbert D. and Card, Stuart K.},
  year = {1990},
  month = mar,
  series = {CHI '90},
  pages = {213--220},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/97243.97276},
  url = {https://doi.org/10.1145/97243.97276},
  urldate = {2023-03-15},
  abstract = {Claims of increased pointing speed by users and manufacturers of variable-gain mice (“powermice”) have become rife. Yet, there have been no demonstrations of this claim, and theoretical considerations suggest it may not even be true. In this paper, the claim is tested. A search of the design space of powermice failed to find a design point that improved performance compared to a standard mouse. No setting for the gain for a constant-gain mouse was found that improved performance. No threshold setting for a variable gain mouse was found that improved performance. In fact, even gain and threshold combinations favored by powermouse enthusiasts failed to improve performance. It is suggested that the real source of enthusiasm for powermice is that users are willing to accept reduced pointing speed in return for a smaller desk footprint.},
  isbn = {978-0-201-50932-8},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\4FZPFMAP\\Jellinek and Card - 1990 - Powermice and user performance.pdf}
}

@misc{jillmarcisybalskyMedley2010,
  title = {Medley},
  author = {{Jill Marci Sybalsky}},
  year = {2010},
  month = mar,
  journal = {VENUE},
  url = {https://web.archive.org/web/20100304002925/http://top2bottom.net:80/medley.html},
  urldate = {2021-04-21},
  keywords = {sz}
}

@inproceedings{kaplanAddingTypeDeclarations1980,
  title = {Adding Type Declarations to Interlisp.},
  booktitle = {IFIP Congress},
  author = {Kaplan, Ronald M. and Sheil, B. A.},
  year = {1980},
  pages = {355--360},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\D8SNPHXD\\Kaplan and Sheil - 1980 - Adding Type Declarations to Interlisp..pdf}
}

@patent{kaplanFiniteStateMachine1995,
  title = {Finite State Machine Data Storage Where Data Transition Is Accomplished without the Use of Pointers},
  author = {Kaplan, Ronald M. and Kay, Martin and Maxwell, John},
  year = {1995},
  month = sep,
  number = {US5450598A},
  url = {https://patents.google.com/patent/US5450598A/en},
  urldate = {2021-06-01},
  abstract = {An FSM data structure is encoded by generating a transition unit of data corresponding to each transition which leads ultimately to a final state of the FSM. Information about the states is included in the transition units, so that the encoded data structure can be written without state units of data. The incoming transition units to a final state each contain an indication of finality. The incoming transition units to a state which has no outgoing transition units each contain a branch ending indication. The outgoing transition units of each state are ordered into a comparison sequence for comparison with a received element, and all but the last outgoing transition unit contain an alternative indication of a subsequent alternative outgoing transition. The indications are incorporated with the label of each transition unit into a single byte, and the remaining byte values are allocated among a number of pointer data units, some of which begin full length pointers and some of which begin pointer indexes to tables where pointers are entered. The pointers may be used where a state has a large number of incoming transitions or where the block of transition units depending from a state is broken down to speed access. The first outgoing transition unit of a state is positioned immediately after one of the incoming transitions so that it may be found without a pointer. Each alternative outgoing transition unit is stored immediately after the block beginning with the previous outgoing transition unit so that it may be found by proceeding through the transition units until the number of alternative bits and the number of branch ending bits balance.},
  assignee = {Xerox Corp},
  nationality = {US},
  keywords = {alternative,data,state,subsequence,sz,transition},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\R4R9VK8Z\\Kaplan et al. - 1995 - Finite state machine data storage where data trans.pdf}
}

@patent{kaplanTextcompressionTechniqueUsing1994,
  title = {Text-Compression Technique Using Frequency-Ordered Array of Word-Number Mappers},
  author = {Kaplan, Ronald M. and Maxwell, John T. III},
  year = {1994},
  month = jun,
  number = {US5325091A},
  url = {https://patents.google.com/patent/US5325091A/en},
  urldate = {2021-06-01},
  abstract = {A text-compression technique utilizes a plurality of word-number mappers ("WNMs") in a frequency-ordered hierarchical structure. The particular structure of the set of WNMs depends on the specific encoding regime, but can be summarized as follows. Each WNM in the set is characterized by an ordinal WNM number and a WNM size (maximum number of tokens) that is in general a non-decreasing function of the WNM number. A given token is assigned a number pair, the first being one of the WNM numbers, and the second being the token's position or number in that WNM. Typically, the most frequently occurring tokens are mapped with a smaller-numbered WNM. The set of WNMs is generated on a first pass through the database to be compressed. The database is parsed into tokens, and a rank-order list based on the frequency of occurrence is generated. This list is partitioned in a manner to define the set of WNMs. Actual compression of the data base occurs on a second pass, using the set of WNMs generated on the first pass. The database is parsed into tokens, and for each token, the set of WNMs is searched to find the token. Once the token is found, it is assigned the appropriate number pair and is encoded. This proceeds until the entire database has been compressed.},
  assignee = {Xerox Corp},
  nationality = {US},
  keywords = {encoded,sz,token,tokens,wnm,wnms},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\MCUMEMS6\\Kaplan and III - 1994 - Text-compression technique using frequency-ordered.pdf}
}

@article{karttunenWordPlay2007,
  title = {Word Play},
  author = {Karttunen, Lauri},
  year = {2007},
  month = dec,
  journal = {Computational Linguistics},
  volume = {33},
  number = {4},
  pages = {443--467},
  issn = {0891-2017},
  doi = {10.1162/coli.2007.33.4.443},
  url = {https://doi.org/10.1162/coli.2007.33.4.443},
  urldate = {2021-04-15},
  abstract = {This article is a perspective on some important developments in semantics and in computational linguistics over the past forty years. It reviews two lines of research that lie at opposite ends of the field: semantics and morphology. The semantic part deals with issues from the 1970s such as discourse referents, implicative verbs, presuppositions, and questions. The second part presents a brief history of the application of finite-state transducers to linguistic analysis starting with the advent of two-level morphology in the early 1980s and culminating in successful commercial applications in the 1990s. It offers some commentary on the relationship, or the lack thereof, between computational and paper-and-pencil linguistics. The final section returns to the semantic issues and their application to currently popular tasks such as textual inference and question answering.},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\GVANPLTG\\Karttunen - 2007 - Word play.pdf}
}

@inproceedings{kazmanInformationOrganizationMultimedia1993,
  title = {Information Organization in Multimedia Resources},
  booktitle = {Proceedings of the 11th Annual International Conference on Systems Documentation},
  author = {Kazman, Rick and Kominek, John},
  year = {1993},
  month = nov,
  series = {SIGDOC '93},
  pages = {149--162},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/166025.166055},
  url = {https://doi.org/10.1145/166025.166055},
  urldate = {2021-04-15},
  isbn = {978-0-89791-630-1},
  keywords = {sz}
}

@misc{kentpitmanX3J13Charter1999,
  title = {X3J13 Charter},
  shorttitle = {Purposes of X3J13 Committee},
  author = {{Kent Pitman}},
  year = {1999},
  month = apr,
  url = {http://www.nhplace.com/kent/CL/x3j13-sd-05.html},
  urldate = {2021-04-16},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\22VUNNA7\\x3j13-sd-05.html}
}

@inproceedings{kerstenUsingTaskContext2006,
  title = {Using Task Context to Improve Programmer Productivity},
  booktitle = {Proceedings of the 14th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  author = {Kersten, Mik and Murphy, Gail C.},
  year = {2006},
  month = nov,
  series = {SIGSOFT '06/FSE-14},
  pages = {1--11},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1181775.1181777},
  url = {https://doi.org/10.1145/1181775.1181777},
  urldate = {2021-04-15},
  abstract = {When working on a large software system, a programmer typically spends an inordinate amount of time sifting through thousands of artifacts to find just the subset of information needed to complete an assigned task. All too often, before completing the task the programmer must switch to working on a different task. These task switches waste time as the programmer must repeatedly find and identify the information relevant to the task-at-hand. In this paper, we present a mechanism that captures, models, and persists the elements and relations relevant to a task. We show how our task context model reduces information overload and focuses a programmer's work by filtering and ranking the information presented by the development environment. A task context is created by monitoring a programmer's activity and extracting the structural relationships of program artifacts. Operations on task contexts integrate with development environment features, such as structure display, search, and change management. We have validated our approach with a longitudinal field study of Mylar, our implementation of task context for the Eclipse development environment. We report a statistically significant improvement in the productivity of 16 industry programmers who voluntarily used Mylar for their daily work.},
  isbn = {978-1-59593-468-5},
  keywords = {degree-of-interest,IDE,interaction history,program views,sz,task management},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\UMJTGEWU\\Kersten and Murphy - 2006 - Using task context to improve programmer productiv.pdf}
}

@inproceedings{knightBuildingCommonLisp2016,
  title = {Building Common Lisp Programs Using Bazel},
  booktitle = {Proceedings of the 9th European Lisp Symposium on European Lisp Symposium},
  author = {Knight, James Y. and Rideau, François-René and Walczak, Andrzej},
  year = {2016},
  month = may,
  series = {ELS2016},
  pages = {95--96},
  publisher = {European Lisp Scientific Activities Association},
  address = {Kraków, Poland},
  url = {https://dl.acm.org/doi/10.5555/3005729.3005741},
  urldate = {2021-04-25},
  abstract = {We will demonstrate how to build Common Lisp programs using Bazel, Google's hermetic and reproducible build system. Unlike the state of the art so far for building Lisp programs, Bazel ensures that incremental builds are always both fast and correct. With Bazel, one can statically link C libraries into the SBCL runtime, making the executable file self-contained.},
  isbn = {978-2-9557474-0-7},
  keywords = {Bazel,Build System,Common Lisp,Determinism,Hermeticity,Reproducibility,sz}
}

@inproceedings{konkinExploitingSoftwareInterfaces1998,
  title = {Exploiting Software Interfaces for Performance Measurement},
  booktitle = {Proceedings of the 1st International Workshop on Software and Performance},
  author = {Konkin, Douglas P. and Oster, Gregory M. and Bunt, Richard B.},
  year = {1998},
  month = oct,
  series = {WOSP '98},
  pages = {208--218},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/287318.287364},
  url = {https://doi.org/10.1145/287318.287364},
  urldate = {2021-04-15},
  abstract = {Software performance measurement can be a difficult and tedious procedure, and this difficulty may explain the lack of interest shown in software performance optimisation in all but the most demanding areas, such as parallel computation and embedded systems. This paper describes the measurement shim. an approach to software perfor-mance which we have found to significantly reduce the effort required to make performance measurements. The measurement shim exploits the interfaces between software modules, and allows measurement at both data stream and procedure call interfaces. Experimental results indicate that the measurement shim provides high-quality data, and can he inserted with low impact on system performance.},
  isbn = {978-1-58113-060-7},
  keywords = {sz}
}

@phdthesis{koomenInterlispVirtualMachine1980,
  title = {The Interlisp Virtual Machine: Study of Its Design and Its Implementation as Multilisp},
  shorttitle = {The Interlisp Virtual Machine},
  author = {Koomen, Johannes A. G. M.},
  year = {1980},
  doi = {10.14288/1.0051801},
  url = {https://open.library.ubc.ca/cIRcle/collections/ubctheses/831/items/1.0051801},
  urldate = {2021-06-02},
  abstract = {Abstract machine definitions have been recognized as convenient and powerful tools for enhancing software portability. One such machine, the Inter lisp Virtual Machine, is examined in this thesis. We present the Multilisp System as an implementation of the Virtual Machine and discuss some of the design criteria and difficulties encountered in mapping the Virtual Machine onto a particular environment. On the basis of our experience with Multilisp we indicate several weaknesses of the Virtual Machine which impair its adequacy as a basis for a portable Interlisp System.},
  langid = {english},
  school = {University of British Columbia},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\SD3M6KV3\\Koomen - 1980 - The interlisp virtual machine  study of its desig.pdf}
}

@inproceedings{korkutExtensibleTypedirectedEditing2018,
  title = {Extensible Type-Directed Editing},
  booktitle = {Proceedings of the 3rd ACM SIGPLAN International Workshop on Type-Driven Development},
  author = {Korkut, Joomy and Christiansen, David Thrane},
  year = {2018},
  month = sep,
  series = {TyDe 2018},
  pages = {38--50},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3240719.3241791},
  url = {https://doi.org/10.1145/3240719.3241791},
  urldate = {2021-04-15},
  abstract = {Dependently typed programming languages, such as Idris and Agda, feature rich interactive environments that use informative types to assist users with the construction of programs. However, these environments have been provided by the authors of the language, and users have not had an easy way to extend and customize them. We address this problem by extending Idris's metaprogramming facilities with primitives for describing new type-directed editing features, making Idris's editors as extensible as its elaborator.},
  isbn = {978-1-4503-5825-5},
  keywords = {dependent types,editors,Metaprogramming,sz}
}

@article{koschmannBridgingGapObjectoriented1988,
  title = {Bridging the Gap between Object-Oriented and Logic Programming},
  author = {Koschmann, T. and Evens, M.W.},
  year = {1988},
  month = jul,
  journal = {IEEE Software},
  volume = {5},
  number = {4},
  pages = {36--42},
  issn = {0740-7459},
  doi = {10.1109/52.17800},
  url = {http://ieeexplore.ieee.org/document/17800/},
  urldate = {2022-08-04},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\CLYTP6YI\\Koschmann and Evens - 1988 - Bridging the gap between object-oriented and logic.pdf}
}

@misc{kossowPDP10SoftwareArchive2006,
  title = {PDP-10 Software Archive},
  shorttitle = {Tape Images from Computer History},
  author = {Kossow, Al},
  year = {2006},
  url = {http://pdp-10.trailing-edge.com/},
  urldate = {2021-04-25},
  keywords = {sz}
}

@inproceedings{kurlanderInteractiveConstraintbasedSearch1992,
  title = {Interactive Constraint-Based Search and Replace},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  author = {Kurlander, David and Feiner, Steven},
  year = {1992},
  month = jun,
  series = {CHI '92},
  pages = {609--618},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/142750.143053},
  url = {https://doi.org/10.1145/142750.143053},
  urldate = {2021-04-15},
  abstract = {We describe enhancements to graphical search and replace that allow users to extend the capabilities of a graphical editor. Interactive constraint-based search and replace can search for objects that obey user-specified sets of constraints and automatically apply other constraints to modify these objects. We show how an interactive tool that employs this technique makes it possible for users to define sets of constraints graphically that modify existing illustrations or control the creation of new illustrations. The interface uses the same visual language as the editor and allows users to understand and create powerful rules without conventional programming. Rules can be saved and retrieved for use alone or in combination. Examples, generated with a working implementation, demonstrate applications to drawing beautification and transformation.},
  isbn = {978-0-89791-513-5},
  keywords = {constraint specification,demonstrational techniques,editor extensibility,graphical editing,interactive techniques,sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\4PLEVNZU\\Kurlander and Feiner - 1992 - Interactive constraint-based search and replace.pdf}
}

@inproceedings{lampsonProcessorHighperformancePersonal1998,
  title = {A Processor for a High-Performance Personal Computer},
  booktitle = {25 Years of the International Symposia on Computer Architecture (Selected Papers)},
  author = {Lampson, Butler W. and Pier, Kenneth A.},
  year = {1998},
  month = aug,
  series = {ISCA '98},
  pages = {180--194},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/285930.285978},
  url = {https://doi.org/10.1145/285930.285978},
  urldate = {2021-04-15},
  abstract = {This paper describes the design goals, micro-architecture. and implementation of the microprogrammed processor for a compact high-performance personal computer. This computer supports a range of high-level language environments and high bandwidth I/O devices. Besides the processor. it has a cache, a memory map, main storage. and an instruction fetch unit; these are described in other papers. The processor can be shared among 16 microcode tasks, performing microcode context switches on-demand with essentially no overhead. Conditional branches are done without any lookahead or delay. Micro-instructions are fairly tightly encoded and use an interesting variant on control field sharing. The processor implements a large number of internal registers. hardware stacks. acyclic shifter/masker, and an arithmetic/logic unit, together with external data paths for instruction fetching, memory interface, and I/O. in a compact, pipe-lined organization. The machine has a 50 ns microcycle, and can execute a simple macroinstruction in one cycle; the available I/O bandwidth is 640 Mbits/sec. The entire machine. including disk, display and network interfaces, is implemented with approximately 3000 NISI components, mostly EC:. 10K; the processor is about 35\% of this. In addition, there are up to 4 storage modules, each with about 300 16K or 64K RAMS and 200 nisi components, for a total of 8 Mbytes. Several prototypes are currently running.},
  isbn = {978-1-58113-058-9},
  keywords = {sz}
}

@article{lawOverviewDebuggingTools1997,
  title = {An Overview of Debugging Tools},
  author = {Law, Rob},
  year = {1997},
  month = mar,
  journal = {ACM SIGSOFT Software Engineering Notes},
  volume = {22},
  number = {2},
  pages = {43--47},
  issn = {0163-5948},
  doi = {10.1145/251880.251926},
  url = {https://doi.org/10.1145/251880.251926},
  urldate = {2021-04-15},
  abstract = {This paper reviews empirical studies on debugging models and the findings associated with these models. There is a discussion on the evolution of program slicing applied to program debugging and different generations of debugging tools are analyzed and criticized.Finally, a programming environment section provides examples of program maintenance tools.},
  keywords = {sz}
}

@misc{leealisonFigureINTERLISPDHISTMENU1992,
  title = {Figure 1: INTERLISP-D's HISTMENU Displays a History of the Commands...},
  shorttitle = {HISTMENU (Figure 1)},
  author = {{Lee, Alison}},
  year = {1992},
  month = jan,
  journal = {ResearchGate},
  url = {https://www.researchgate.net/figure/INTERLISP-Ds-HISTMENU-displays-a-history-of-the-commands-issued-to-the-Executive-in-the_fig1_242625827},
  urldate = {2022-10-21},
  abstract = {Figure 1 from paper by Lee: INTERLISP-D's HISTMENU displays a history of the commands issued to the Executive in the form of a menu. The user may select the items from the menu (the window entitled History Window). from publication: Investigations into history tools for user support | | ResearchGate, the professional network for scientists.},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\MT7B2WMN\\INTERLISP-Ds-HISTMENU-displays-a-history-of-the-commands-issued-to-the-Executive-in-the_fig1_24.html}
}

@article{leeInvestigationsHistoryTools1992,
  title = {Investigations into History Tools for User Support},
  author = {Lee, Alison},
  year = {1992},
  month = jan,
  journal = {University of Toronto},
  pages = {187},
  abstract = {History tools allow users to access past interactions kept in a history and to incorporate them into the context of their current operations. Such tools appear in various forms in many of today’s computing systems, but despite their prevalence,they have received little attention as user support tools. This dissertation investigates, through a series of studies, history–based, user support tools. The studies focus on three primary factors influencing the utility of history–based, user support tools: design of history tools, support of a behavioural phenomenon in user interactions, and mental and physical effort associated with using history tools. Design of history tools strongly influences a user’s perception of their utility. In surveying a wide collection of history tools, we identify seven independent uses of the information with no single history tool supporting all seven uses. Based on cognitive and behavioural considerations associated with the seven history uses, we propose several kinds of history information and history functions that need to be supported in new designs of history tools integrating all seven uses of history. An exploratory study of the UNIX environment reveals that user interactions exhibit a behavioural phenomenon, nominally referred to as locality. This is the phenomenon where users repeatedly reference a small group of commands during extended intervals of their session. We apply two concepts from computer memory research (i.e., working sets and locality) to examine this behavioural artifact and to propose a strategy for predicting repetitive opportunities and candidates. Our studies reveal that users exhibit locality in only 31\% of their sessions whereas users repeat individual commands in 75\% of their sessions. We also found that history tool use occurs primarily in locality periods. Thus, history tools which localize their prediction opportunities to locality periods can predict effectively the reuse candidates. Finally, the effort, mental and physical, associated with using a history tool to expedite repetitive commands can influence a user’s decision to use history tools. We analyze the human information–processing operations involved in the task of specifying a recurrent command for a given approach and design (assuming that the command is fully generated and resides in the user’s working memory and that users exhibit expert, error–free task performance behaviour). We find that in most of the proposed history designs, users expend less physical effort at the expense of more mental effort. The increased mental effort can be alleviated by providing history tools which require simpler mental operations (e.g., working memory retrievals and perceptual processing). Also, we find that the typing approach requires less mental effort at the expense of more physical effort. Finally, despite the overhead associated with switching to the use of history tools, users (with a typing speed of 55 wpm or less) do expend less overall effort to specify recurrent commands (which have been generated and appear in working memory) using history tools compared to typing from scratch. The results of the three sets of studies provide insights into current history tools and point favourably towards the use of history tools for user support, especially history tools that support the reuse of previous commands, but additional research into history tool designs and usability factors is needed. Our studies demonstrate the importance of considering various psychological and behavioural factors and the importance of different grains of analysis.},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\F8YNSWLM\\Lee - 1992 - Investigations into history tools for user support.pdf}
}

@inproceedings{lehtolaLanguagebasedEnvironmentNatural1985,
  title = {Language-Based Environment for Natural Language Parsing},
  booktitle = {Proceedings of the Second Conference on European Chapter of the Association for Computational Linguistics},
  author = {Lehtola, A. and Jäppinen, H. and Nelimarkka, E.},
  year = {1985},
  month = mar,
  series = {EACL '85},
  pages = {98--106},
  publisher = {Association for Computational Linguistics},
  address = {USA},
  doi = {10.3115/976931.976946},
  url = {https://doi.org/10.3115/976931.976946},
  urldate = {2021-04-15},
  abstract = {This paper introduces a special programming environment for the definition of grammars and for the implementation of corresponding parsers. In natural language processing systems it is advantageous to have linguistic knowledge and processing mechanisms separated. Our environment accepts grammars consisting of binary dependency relations and grammatical functions. Well-formed expressions of functions and relations provide constituent surroundings for syntactic categories in the form of two-way automata. These relations, functions, and automata are described in a special definition language.In focusing on high level descriptions a linguist may ignore computational details of the parsing process. He writes the grammar into a DPL-description and a compiler translates it into efficient LISP-code. The environment has also a tracing facility for the parsing process, grammar-sensitive lexical maintenance programs, and routines for the interactive graphic display of parse trees and grammar definitions. Translator routines are also available for the transport of compiled code between various LISP-dialects. The environment itself exists currently in INTERLISP and FRANZLISP. This paper focuses on knowledge engineering issues and does not enter linguistic argumentation.},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\PF5IE2YR\\Lehtola et al. - 1985 - Language-based environment for natural language pa.pdf}
}

@article{lenatCYCUsingCommon1985,
  title = {CYC: Using Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks},
  shorttitle = {CYC},
  author = {Lenat, Douglas B. and Prakash, Mayank and Shepherd, Mary},
  year = {1985},
  month = mar,
  journal = {AI magazine},
  volume = {6},
  number = {4},
  pages = {65--65},
  doi = {10.1609/aimag.v6i4.510},
  url = {https://ojs.aaai.org/index.php/aimagazine/article/view/510},
  abstract = {The major limitations in building large software have always been (a) its brittleness when confronted by problems that were not foreseen by its builders, and (by the amount of manpower required. The recent history of expert systems, for example highlights how constricting the brittleness and knowledge acquisition bottlenecks are. Moreover, standard software methodology (e.g., working from a detailed "spec") has proven of little use in AI, a field which by definition tackles ill- structured problems. How can these bottlenecks be widened? Attractive, elegant answers have included machine learning, automatic programming, and natural language understanding. But decades of work on such systems have convinced us that each of these approaches has difficulty "scaling up" for want a substantial base of real world knowledge.},
  keywords = {sz}
}

@patent{lipkisDesignSystemUsing1990,
  title = {Design System Using Visual Language},
  author = {Lipkis, Thomas A. and Mark, William S. and Pirtle, Melvin W.},
  year = {1990},
  month = apr,
  number = {US4914567A},
  url = {https://patents.google.com/patent/US4914567A/en},
  urldate = {2021-06-01},
  abstract = {A computer-based tool, in the form of a computer system and method, for designing, constructing and interacting with any system containing or comprising concurrent asynchronous processes, such as a factory operation. In the system according to the invention a variety of development and execution tools are supported. The invention features a highly visual user presentation of a control system, including structure, specification, and operation, offering a user an interactive capability for rapid design, modification, and exploration of the operating characteristics of a control system comprising asynchronous processes. The invention captures a representation of the system (RS) that is equivalent to the actual system (AS)--rather than a simulation of the actual system. This allows the invention to perform tests and modification on RS instead of AS, yet get accurate results. RS and AS are equivalent because AS is generated directly from RS by an automated process. Effectively, pressing a button in the RS environment can "create" the AS version or any selected portion of it, by "downloading" a translation of the RS version that can be executed by a programmable processor in the AS environment. Information can flow both ways between AS and RS. That AS and RS can interact is important. This allows RS to "take on" the "state" of AS whenever desired, through an "uploading" procedure, thereby reflecting accurately the condition of AS at a specific point in time.},
  assignee = {Savoir},
  nationality = {US},
  keywords = {control,designing,objects,programming,recited,sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\7C49LF2W\\Lipkis et al. - 1990 - Design system using visual language.pdf}
}

@misc{Lisp50NotesPart2008,
  title = {Lisp50 Notes Part V: Interlisp, PARC, and the Common Lisp Consolidation Wars},
  shorttitle = {Lisp50 Notes Part V},
  year = {2008},
  month = oct,
  journal = {Learning Lisp},
  url = {https://lispy.wordpress.com/2008/10/24/lisp50-notes-part-v-interlisp-parc-and-the-common-lisp-consolidation-wars/},
  urldate = {2022-08-05},
  abstract = {Okay, quick… how many people besides Alan Kay can you name that worked at Xerox PARC? Not very many, eh? Yeah, that’s your loss. It wasn’t all about the guys like Kay that get all…},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\BITPJSLF\\lisp50-notes-part-v-interlisp-parc-and-the-common-lisp-consolidation-wars.html}
}

@misc{LispEditing80s2017,
  title = {Lisp Editing in the 80s - Interlisp SEdit},
  year = {2017},
  month = jun,
  publisher = {thoughtupquick},
  url = {https://www.youtube.com/watch?v=2qsmF8HHskg},
  urldate = {2021-05-02},
  abstract = {Reuploaded from:  http://people.csail.mit.edu/riastradh...\hspace{0pt} Thanks to "lispm" on reddit for all the info:  https://www.reddit.com/r/lisp/comment...\hspace{0pt} From what I understand SEdit was developed later than DEdit. SEdit is documented first in the 1987 Lyric release of Interlisp-D, see Appendix B: http://bitsavers.trailing-edge.com/pd...\hspace{0pt} SEdit is expanded in the virtual machine version of Interlisp-D, called Medley. See the Medley 1.0 release notes, appendix B: http://bitsavers.trailing-edge.com/pd...\hspace{0pt} Some hints for using SEdit http://bitsavers.trailing-edge.com/pd...\hspace{0pt} If you want to try it out, maybe this contains the editors: http://www2.parc.com/isl/groups/nltt/...\hspace{0pt}},
  keywords = {sz}
}

@misc{LispMachinesSummary1983,
  title = {Lisp Machines Summary -3600Edition},
  year = {1983},
  month = aug,
  publisher = {Symbolics Corporation},
  langid = {english},
  annotation = {\#990075}
}

@misc{LispSymbolicComputation2022,
  title = {Lisp and Symbolic Computation},
  year = {2022},
  month = dec,
  journal = {Table of contents for issues of Lisp and Symbolic Computation},
  url = {http://ftp.math.utah.edu/pub/tex/bib/toc/lispsymbcomput.html},
  urldate = {2021-04-25},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno),sz}
}

@patent{mackinlayImageDisplaySystems1998,
  title = {Image Display Systems},
  author = {Mackinlay, Jock D. and Card, Stuart K. and Robertson, George G.},
  year = {1998},
  month = sep,
  number = {EP0471484B1},
  url = {https://patents.google.com/patent/EP0471484B1/en},
  urldate = {2021-06-01},
  assignee = {Xerox Corp},
  langid = {english},
  nationality = {EP},
  keywords = {image,motion,poi,region,sz,viewpoint},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\TZNL3GXQ\\Mackinlay et al. - 1998 - Image display systems.pdf}
}

@article{maloneExperimentsOvalRadically1995,
  title = {Experiments with Oval: A Radically Tailorable Tool for Cooperative Work},
  shorttitle = {Experiments with Oval},
  author = {Malone, Thomas W. and Lai, Kum-Yew and Fry, Christopher},
  year = {1995},
  month = apr,
  journal = {ACM Transactions on Information Systems},
  volume = {13},
  number = {2},
  pages = {177--205},
  issn = {1046-8188},
  doi = {10.1145/201040.201047},
  url = {https://doi.org/10.1145/201040.201047},
  urldate = {2021-04-15},
  abstract = {This article describes a series of tests of the generality of a “radically tailorable” tool for cooperative work. Users of this system can create applications by combining and modifying four kinds of building blocks: objects, views, agents, and links. We found that user-level tailoring of these primitives can provide most of the functionality found in well-known cooperative work systems such as gIBIS, Coordinator, Lotus Notes, and Information Lens. These primitives, therefore, appear to provide an elementary “tailoring language” out of which a wide variety of integrated information management and collaboration applications can be constructed by end users.},
  keywords = {computer-supported cooperative work,end-user programming,groupware,radical tailorability,sz}
}

@misc{maloneInformationLens2021,
  title = {The Information Lens},
  author = {Malone, Thomas W.},
  year = {2021},
  month = jan,
  publisher = {ACM SIGCHI},
  address = {Toronto, Canada},
  url = {https://www.youtube.com/watch?v=o7P0cM5VqKc},
  urldate = {2021-05-02},
  abstract = {The Information Lens Thomas Malone (MIT) CHI+GI '87 Technical Video Program Abstract An intelligent system for information sharing and coordination (subtitle from the video) WEB:: http://www.cs.umd.edu/hcil/chivideosl...\hspace{0pt} Published in two videotapes: issue 27, and issue 33-34 of ACM SIGGRAPH Video Review (issue 27 appeared in same tape as issue 26, i.e. the CHI '87 Electronic Theater). Video Chair: Richard J. Beach (Xerox PARC) Location: Toronto, Canada},
  keywords = {sz}
}

@patent{maloneObjectorientedComputerUser1998,
  title = {Object-Oriented Computer User Interface},
  author = {Malone, Thomas W. and Lai, Kum-Yew and Yu, Keh-Chiang and Berenson, Richard W.},
  year = {1998},
  month = aug,
  number = {US5790116A},
  url = {https://patents.google.com/patent/US5790116A/en},
  urldate = {2021-06-01},
  abstract = {A computer user interface includes a mechanism of graphically representing and displaying user-definable objects of multiple types. The object types that can be represented include data records, not limited to a particular kind of data, and agents. An agent processes information automatically on behalf of the user. Another mechanism allows a user to define objects, for example by using a template. These two mechanisms act together to allow each object to be displayed to the user and acted upon by the user in a uniform way regardless of type. For example, templates for defining objects allow a specification to be input by a user defining processing that can be performed by an agent.},
  assignee = {Massachusetts Institute of Technology},
  nationality = {US},
  keywords = {folder,objects,sz,type,types,user},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\C385L9XX\\Malone et al. - 1998 - Object-oriented computer user interface.pdf}
}

@inproceedings{mancoridisMultidimensionalTaxonomySoftware1993,
  title = {A Multi-Dimensional Taxonomy of Software Development Environments},
  booktitle = {Proceedings of the 1993 Conference of the Centre for Advanced Studies on Collaborative Research: Software Engineering - Volume 1},
  author = {Mancoridis, Spiros},
  year = {1993},
  month = oct,
  series = {CASCON '93},
  volume = {1},
  pages = {581--594},
  publisher = {IBM Press},
  address = {Toronto, Ontario, Canada},
  url = {https://dl.acm.org/doi/10.5555/962289.962338},
  urldate = {2021-04-15},
  abstract = {A Software Development Environment (SDE) is a set of tools that, at the very least, supports coding and possibly other software development activities. Related to SDEs are meta-SDEs, which are classes of SDEs that must be configured or populated by tools before they can be useful. We will use the generic term environment to refer to both SDEs and meta-SDEs.This paper presents a multi-dimensional taxonomy of environments. The primary dimensions of our taxonomy are scale and genericity. Scale distinguishes environments that are suitable for small-scale programming from those that are suitable for large-scale software development. Genericity differentiates monolithic environments from highly configurable and extendible ones. Secondary taxonomy dimensions include tool integration, which identifies the degree of interoperability and data sharing between tools, and the historical dimension, which gives insight into past and present research trends in these environments.},
  langid = {english},
  keywords = {sz}
}

@misc{markstefikColabMovie19872011,
  title = {The Colab Movie (1987)},
  shorttitle = {The Colab Movie},
  author = {{Mark Stefik}},
  year = {2011},
  month = apr,
  url = {https://www.youtube.com/watch?v=iPZTOosKjAE},
  urldate = {2021-05-17},
  abstract = {The Colab project at PARC was an experiment in creating an electronic meeting room. This project developed multi-user interfaces, telepointers, and other innovations at the time. This movie shows the Cognoter tool which was a multi-user brainstorming tool used for collaborative development of an outline for a paper. See /www.markstefik.com/?page\_id=155"},
  keywords = {sz}
}

@misc{markstefikTruckinKnowledgeCompetition2011,
  title = {Truckin Knowledge Competition (1983)},
  author = {{Mark Stefik}},
  year = {2011},
  month = apr,
  url = {https://www.youtube.com/watch?v=Pt-Sv1ynGKc},
  urldate = {2021-05-17},
  abstract = {In 1983 the Knowledge Systems Area at Xerox PARC taught experimental courses on knowledge programming. The Truckin' knowledge competition was the final exam at the end of a one week course. Students programmed their trucks to compete in Truckin' simulation world -- buying and selling goods, getting gas as needed, avoiding bandits, and so on. All of the trucks competed in the final. The winner was the truck with the most cash parked nearest Alice's Restaurant. See www.markstefik.com/?page\_id=359},
  keywords = {sz}
}

@incollection{martzExpertSystemOptimizing1986,
  title = {An Expert System for Optimizing Ultracentrifugation Runs},
  booktitle = {Artificial Intelligence Applications in Chemistry},
  author = {Martz, Philip R. and Heffron, Matt and Griffith, Owen Mitch},
  year = {1986},
  month = apr,
  series = {ACS Symposium Series},
  volume = {306},
  pages = {297--311},
  publisher = {American Chemical Society},
  doi = {10.1021/bk-1986-0306.ch023},
  url = {https://doi.org/10.1021/bk-1986-0306.ch023},
  urldate = {2022-06-20},
  abstract = {The SpinPro™ Ultracentrifugation Expert System is a computer program that designs optimal ultracentrifugation procedures to satisfy the investigator's research requirements. SpinPro runs on the IBM PC/XT. Ultracentrifugation is a common method in the separation of biological materials. Its capabilities, however, are too often under-utilized. SpinPro addresses this problem by employing Artificial Intelligence (AI) techniques to design efficient and accurate ultracentrifugation procedures. To use SpinPro, the investigator describes the centrifugation problem in a question and answer dialogue. SpinPro then offers detailed advice on optimal and alternative procedures for performing the run. This advice results in cleaner and faster separations and improves the efficiency of the ultracentrifugation laboratory.},
  chapter = {23},
  isbn = {978-0-8412-0966-4},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\2ISMN6C8\\bk-1986-0306.html}
}

@inproceedings{martzPepProPeptideSynthesis1989,
  title = {The PepPro™ Peptide Synthesis Expert System},
  booktitle = {PROCEEDINGS OF THE FIRST ANNUAL CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE},
  author = {Martz, Philip R. and Heffron, Matt and Kalbag, Suresh and Dyckes, Douglas F. and Voelker, Paul},
  year = {1989},
  month = mar,
  publisher = {The AAAI Press, Menlo Park, California},
  address = {Stanford, California},
  url = {https://www.aaai.org/Papers/IAAI/1989/IAAI89-010.pdf},
  abstract = {Peptide synthesis is an important research tool. However, successful syntheses require considerable effort from the scientist. We have produced an expert System, the PepPro™ Peptide Synthesis Expert System, that helps the scientist improve peptide syntheses. To use PepPro the scientist enters the peptide to be synthesized. PepPro then applies its synthesis rules to analyze the peptide, to predict coupling. problems, and to recommend solutions. PepPro produces a synthesis report that summarizes the analysis and recommendations. The program includes a capability that allows the scientist to write new synthesis rules and add them to the PepPro knowledge base. PepPro was developed on Xerox 11xx series workstations using Beckman’s proprietary development environment MP). We then compiled PepPro to run on the IBM PC. PepPro has limitations that derive from unpredictable events during a synthesis. Despite the limitations, PepPro provides several important benefits. The major one is that it makes peptide syntheses easier, less time-consuming, and more efficient.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\UWDLB5J7\\Martz et al. - 1989 - The PepPro™ Peptide Synthesis Expert System.pdf}
}

@misc{masadComputersDoingRight2021,
  title = {Computers Doing The Right Thing},
  author = {Masad, Amjad},
  year = {2021},
  month = dec,
  journal = {Amjad Masad},
  url = {https://amasad.me/right},
  urldate = {2023-02-25},
  abstract = {I'm fascinated by the idea of computers doing The Right thing without explicit user input. Today this is most apparent in autocorrect, but the idea -- in a more advanced form -- goes back to the early...},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\68JTUL9F\\right.html}
}

@inproceedings{masinterCommonLispCleanup1988,
  title = {Common Lisp Cleanup. — Software Preservation Group},
  booktitle = {Proceedings of the First International Workshop on LISP Evolution and Standardization},
  author = {Masinter, Larry},
  year = {1988},
  month = jan,
  pages = {6},
  publisher = {IOS},
  address = {Amsterdam},
  url = {http://www.softwarepreservation.org/projects/LISP/conference/iwoleas88/Masinter-CommonLispCleanup.pdf},
  urldate = {2021-04-18},
  abstract = {This paper describes some of the activities of the "cleanup" sub-committee of the ANSI X3J13 group. It describes some fundamental assumptions of our work in this sub-committee, the process we use to consider changes, and a sampler of some of the changes we are considering.},
  keywords = {sz}
}

@phdthesis{masinterGlobalProgramAnalysis1980,
  type = {Doctor of Philosophy},
  title = {Global Program Analysis in an Interactive Envi Ronment by Larry Melvin Masinter SSL.80-1 JANUARY 1980},
  author = {Masinter, Larry Melvin},
  year = {1980},
  address = {3333 Coyote Hil Road I Palo Alto I Caliornia 94304},
  url = {https://larrymasinter.net/thesis.pdf},
  urldate = {2021-04-18},
  abstract = {This disscrttion dcscribes a programming tool. implemented in Lisp. callcd SCOPE. The basic idea behind ScoPE can be stated simply: SCOPE analyzes a user's programs. rcmembers what it sees. is able to answer questions based on the facts it remembers. and is able to incrcmentay update thc data basc when a picce of thc program changes. A varicty of program infonnation is available about cross rcfcrences. data flow and program organi7.aticil. Facts about programs are stored in a data bas: to answer a question. SCOPE rctrieves and makes inferences basd on infonnation in the data base. SCOPE is interactive because it keeps track of which par of the programs have changed during the course of an editing and debugging sesion. and is able to automatically and incrementally update its data bas. Because SCOPE perfonns whatever re analysis is necesry to answer the question when the question is asked. SCOPE maintans the ilusion that the data bas is always up to date-ther than the additional wait tie. it is as if SCOPE knew the answer al along. SCOPE'S foundation is a representauon system in which propertes of pieces of progras ca be expred. The objects of SCOPE'S language are pieces of progrs, and in par. definitions of symbols-.g.. the definition of a proedure or a data strcture. SCOPE doe not model propertes of individua statements or expreions in the program: SCOPE knows only individual facts about procedures varables data strctures and other pieces of a progr which ca be asigned as the definiuon of symbols. The facts are relauons between the name of a definiuon and other symbols. For example. one of the relauons that SCOPE keeps trk of is Call: Call(FNl'FNil holds if the definiùon whose nae is FNi contans a ca to a procedure named FNi" SCOPE has two interfaces: one to the user and one to other progras. The user interface is an English-like command language which allows for a unifonn command strcture and convenient defaults: the most frequently used commands are the easiest to type. All of the power avaiable with the command language is accesible Jirough the progra interface as well. The compiler and varouš other uulities use the progra interf\textasciitilde "},
  langid = {american},
  school = {PALO ALTO RESEARCH CENTER},
  keywords = {sz}
}

@misc{masinterInterlispDAAAI822017,
  title = {Interlisp-D at AAAI-82},
  author = {Masinter, Larry},
  year = {2017},
  month = sep,
  journal = {Google Photos},
  url = {https://photos.google.com/share/AF1QipORUrk2uwraYYJVOZ2R8mH51U4n5uv30V1KJk5zvu5Pd5XtEXuXp8jg1BfwdHBHkw?key=OGxZSU5LbXZPaTdmbnU3QmZiOTRlYnR6SDdMNUJ3},
  urldate = {2021-04-16},
  abstract = {17 new photos added to shared album},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\VHWFM3IZ\\AF1QipORUrk2uwraYYJVOZ2R8mH51U4n5uv30V1KJk5zvu5Pd5XtEXuXp8jg1BfwdHBHkw.html}
}

@techreport{masinterInterlispVAXReport1981,
  title = {Interlisp-VAX: A Report},
  author = {Masinter, Larry M.},
  year = {1981},
  month = aug,
  number = {SUN-CS-81-879},
  pages = {13},
  address = {Stanford University Stanford, CA 94305},
  institution = {Department of Computer Science, Stanford University},
  url = {http://www.softwarepreservation.org/projects/LISP/interlisp/Interlisp-VAX_A_Report.pdf/view},
  urldate = {2021-04-23},
  keywords = {INTERLISP-VAX},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\3PRV5JKX\\Masinter - 1981 - Interlisp-VAX A Report.pdf}
}

@inproceedings{masinterLocalOptimizationCompiler1980,
  title = {Local Optimization in a Compiler for Stack-Based Lisp Machines},
  booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
  author = {Masinter, Larry M. and Deutsch, L. Peter},
  year = {1980},
  month = aug,
  series = {LFP '80},
  pages = {223--230},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800087.802810},
  url = {https://doi.org/10.1145/800087.802810},
  urldate = {2021-04-26},
  abstract = {We describe the local optimization phase of a compiler for translating the INTERLISP dialect of LISP into stack-architecture (0-address) instruction sets. We discuss the general organization of the compiler, and then describe the set of optimization techniques found most useful, based on empirical results gathered by compiling a large set of programs. The compiler and optimization phase are machine independent, in that they generate a stream of instructions for an abstract stack machine, which an assembler subsequently turns into the actual machine instructions. The compiler has been in successful use for several years, producing code for two different instruction sets.},
  isbn = {978-1-4503-7396-8},
  keywords = {Interlisp-D}
}

@misc{masinterPARCMESSAGETXT1976,
  title = {PARCMESSAGE.TXT.1.},
  author = {Masinter, Larry},
  year = {1976},
  month = jan,
  journal = {Software Preservation Group},
  url = {http://www.softwarepreservation.org/projects/LISP/interlisp/tenex/twenex.org/PARCMESSAGE.TXT.1/view},
  urldate = {2021-04-23},
  keywords = {sz}
}

@article{mccarthyInterestingLISPFunction1979,
  title = {An Interesting LISP Function},
  author = {McCarthy, J.},
  year = {1979},
  month = dec,
  journal = {ACM Lisp Bulletin},
  number = {3},
  pages = {6--8},
  doi = {10.1145/1411829.1411833},
  url = {https://doi.org/10.1145/1411829.1411833},
  urldate = {2021-04-25},
  keywords = {sz}
}

@inproceedings{mccarthyLISPNotesIts1980,
  title = {LISP - Notes on Its Past and Future},
  booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
  author = {McCarthy, John},
  year = {1980},
  month = aug,
  series = {LFP '80},
  pages = {.5--viii},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800087.802782},
  url = {https://doi.org/10.1145/800087.802782},
  urldate = {2021-06-02},
  abstract = {LISP has survived for 21 years because it is an approximate local optimum in the space of programming languages. However, it has accumulated some barnacles that should be scraped off, and some long-standing opportunities for improvement have been neglected. It would benefit from some co-operative maintenance especially in creating and maintaining program libraries. Computer checked proofs of program correctness are now possible for pure LISP and some extensions, but more theory and some smoothing of the language itself are required before we can take full advantage of LISP's mathematical basis.},
  isbn = {978-1-4503-7396-8},
  langid = {english},
  keywords = {sz}
}

@inproceedings{mccarthyLISPProgrammingSystem1959,
  title = {LISP: A Programming System for Symbolic Manipulations},
  shorttitle = {LISP},
  booktitle = {Preprints of Papers Presented at the 14th National Meeting of the Association for Computing Machinery},
  author = {McCarthy, John},
  year = {1959},
  month = sep,
  series = {ACM '59},
  pages = {1--4},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/612201.612243},
  url = {https://doi.org/10.1145/612201.612243},
  urldate = {2021-06-02},
  abstract = {LISP (for LISt Processor) is a programming system for the IBM 704 being developed by the Artificial Intelligence Group at MIT. We are developing it in order to program the Advice Taker which is to be a system for instructing a machine in a combination of declarative and imperative sentences.},
  isbn = {978-1-4503-7364-7}
}

@article{mccarthyRecursiveFunctionsSymbolic1960,
  title = {Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I},
  author = {McCarthy, John},
  year = {1960},
  month = apr,
  journal = {Communications of the ACM},
  volume = {3},
  number = {4},
  pages = {184--195},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/367177.367199},
  url = {https://dl.acm.org/doi/10.1145/367177.367199},
  urldate = {2021-04-25},
  abstract = {A programming system called LISP (for Lisp Processor) has been developed for the IBM 704 computer by the Artificial Intelligence group at M.I.T. The system was designed to facilitate experiments with a proposed system called the Advice Taker, whereby a machine could be instructed to handle declarative as well as imperative sentences and could exhibit, "common sense"  in carrying out its instructions. The original proposal for the Advice Taker was made in November l958. The main requirement was a programming system for manipulating expressions representing formalized declarative and imperative sentences so that the Advice Taker system could make deductions.},
  langid = {english},
  keywords = {sz}
}

@misc{mearsArtificialIntelligenceSystems1987,
  title = {Artificial Intelligence Systems Xerox LOOPS, A Friendly Primer},
  shorttitle = {Interlisp-D\_A-Friendly-Primer},
  author = {Mears, Lyn Ann and Rees, Ted},
  year = {1987},
  month = mar,
  publisher = {Xerox Corporation},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198510_Koto/3102242_Xerox_LOOPS_A_Friendly_Primer_Mar87.pdf},
  urldate = {2021-04-23},
  langid = {english},
  keywords = {Interlisp-D,s2z}
}

@book{michaelsannellaInterlispReferenceManual1983,
  title = {Interlisp Reference Manual: Revised},
  author = {{Michael Sannella} and {Xerox} and {Palo Alto Research Center}},
  year = {1983},
  publisher = {Xerox Corp.},
  address = {Palo Alto Research Center, Pasadena, Calif.},
  langid = {english},
  keywords = {sz},
  annotation = {OCLC: 11098633}
}

@article{monkbotX3J132020,
  title = {X3J13},
  editor = {{Monkbot}},
  year = {2020},
  month = nov,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=X3J13&oldid=990841364},
  urldate = {2021-04-18},
  abstract = {X3J13 is the name of a technical committee which was part of the International Committee for Information Technology Standards (INCITS, then named X3).  The X3J13 committee was formed in 1986 to draw up an American National Standards Institute (ANSI) Common Lisp standard based on the first edition of the book Common Lisp the Language (also termed CLtL, or CLtL1), by Guy L. Steele Jr., which was formerly a de facto standard for the language.  The primary output of X3J13 was an American National Standard for programming language Common Lisp (X3.226/1994), approved December 8, 1994. X3J13 later worked with International Organization for Standardization (ISO) working group SC22/WG16 on an internationally standardised dialect of Lisp named ISLISP.},
  langid = {english},
  keywords = {sz}
}

@inproceedings{moonGarbageCollectionLarge1984,
  title = {Garbage Collection in a Large LISP System},
  booktitle = {Proceedings of the 1984 ACM Symposium on LISP and Functional Programming},
  author = {Moon, David A.},
  year = {1984},
  month = aug,
  series = {LFP '84},
  pages = {235--246},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800055.802040},
  url = {https://doi.org/10.1145/800055.802040},
  urldate = {2021-04-25},
  abstract = {This paper discusses garbage collection techniques used in a high-performance Lisp implementation with a large virtual memory, the Symbolics 3600. Particular attention is paid to practical issues and experience. In a large system problems of scale appear and the most straightforward garbage-collection techniques do not work well. Many of these problems involve the interaction of the garbage collector with demand-paged virtual memory. Some of the solutions adopted in the 3600 are presented, including incremental copying garbage collection, approximately depth-first copying, ephemeral objects, tagged architecture, and hardware assists. We discuss techniques for improving the efficiency of garbage collection by recognizing that objects in the Lisp world have a variety of lifetimes. The importance of designing the architecture and the hardware to facilitate garbage collection is stressed.},
  isbn = {978-0-89791-142-3},
  keywords = {sz}
}

@techreport{mooreInterlispVirtualMachine1976,
  title = {The Interlisp Virtual Machine Specification},
  author = {Moore, J. Strother},
  year = {1976},
  institution = {Xerox Palo Alto Research Center},
  url = {http://www.bitsavers.org/pdf/xerox/parc/techReports/CSL-76-5_The_Interlisp_Virtual_Machine_Specification.pdf},
  abstract = {The INTERLISP Virtual Machine is the environment in which the INTERLISP System is implemented. It includes such abstract objects as "Literal Atoms", "List Cells", "Integers", etc., the basic LISP functions for manipulating them, the underlying program control and variable binding mechanisms, the input/output facilities, and interrupt processing facilities. In order to Implement the INTER LISP System (as described in The INTERLISP Reference Manual by W. Teitelman, et. al.) on some physical machine, it is only necessary to implement the INTERLISP Virtual Machine, since Virtual Machine compatible source code for the rest of the INTERLISP System can be obtained from publicly available files. This document specifies the behavior of the INTER LISP Virtual Machine from the implementor's point of view. That is, it is an attempt to make explicit those things which must be implemented to allow the INTERLISP System to run on some machine. KEY WORDS AND PHRASES programming language semantics, LISP, dynamic storage allocation, interpreters, spaghetti stacks, abstract data types, function objects, FUNARGs, applicative programming languages, control structures, interactive systems, DWIM, programmer's assistant, automatic error correction, eval, error handling, interrupt},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\KPAUIGCL\\Tion and Moore - 1976 - The Interlisp Virtual Machine.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\YF5IFL3A\\summary.html}
}

@techreport{mooreINTERLISPVirtualMachine1979,
  title = {The INTERLISP Virtual Machine Specification: Revised},
  author = {Moore, J. Strother},
  year = {1979},
  month = mar,
  pages = {126},
  url = {http://www.cs.utexas.edu/~moore/publications/interlisp-vm.pdf},
  abstract = {The INTERLISP Virtual Machine is the environment in which the INTERLISP System is implemented. It includes such abstract objects as \textasciitilde Literal Atom s\textasciitilde. List CelIs\textasciitilde, ‘Integers. etc.. the basic LISP functions for manipulating them, the underlying program control, and variable binding mechanisms. the input/output facilities, and interrupt processing facilities. In order to implement the INTERLISP System (as described in The INTERLISP Reference Manual by W. Teitelman. et. al.) on some physical machine, it is only necessary to implement the INTERLISP Virtual Machine. since Virtual Machine compatible source code for the rest of the INTERLISP System can be obtained from publicly available files. This document specifies the behavior of the INTERLISP Virtual Machine from the implementor s point of view. That is. it is an attempt to make explicit those things that must be implemented to allow the INTERLISP System to run on some machine.},
  keywords = {interlisp,s2z}
}

@techreport{mooreTXDTPackageInterlispText1981,
  title = {The TXDT Package-Interlisp Text Editing Primitives},
  author = {Moore, J. Strother},
  year = {1981},
  pages = {34},
  address = {California},
  institution = {Xerox. Palo Alto Research Center},
  url = {http://129.69.211.95/pdf/xerox/parc/techReports/CSL-81-2_The_TXDT_Package.pdf},
  abstract = {The TXDT package is a collection of INTERLISP programs designed for those who wish to build text editors in INTERLISP. TXDT provides a new INTERLISP data type, called a buffer, and programs for efficiently inserting, deleting, searching and manipulating text in buffers. Modifications may be made undoable. A unique feature of TXDT is that an address may be "stuck" to a character occurrence so as to follow that character wherever it Is subsequently moved. TXDT also has provisions for fonts.},
  keywords = {sz}
}

@misc{murpheyDanMurphyTECO,
  type = {Blog},
  title = {Dan Murphy's TECO, TENEX, and TOPS-20 Papers},
  author = {Murphey, Dan},
  journal = {TECO, TENEX, and TOPS-20 Papers And assorted memorabilia},
  url = {https://opost.com/tenex/},
  urldate = {2022-01-30},
  langid = {english},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\ZMJUKF8Q\\tenex.html}
}

@article{murphyTENEXTOPS202015,
  title = {TENEX and TOPS-20},
  author = {Murphy, Dan},
  year = {2015},
  month = jan,
  journal = {Annals of the History of Computing, IEEE},
  volume = {37},
  pages = {75--82},
  publisher = {IEEE},
  doi = {10.1109/MAHC.2015.15},
  url = {https://www.researchgate.net/publication/273523084_TENEX_and_TOPS-20},
  abstract = {In the late 1960s, a small group of developers at Bolt, Beranek, and Newman (BBN) in Cambridge, Massachusetts, began work on a new computer operating system, including a kernel, system call API, and user command interface (shell). While such an undertaking, particularly with a small group, became rare in subsequent decades, it was not uncommon in the 1960s. During development, this OS was given the name TENEX. A few years later, TENEX was adopted by Digital Equipment Corporation (DEC) for its new line of large machines to be known as the DECSYSTEM-20, and the operating system was renamed to TOPS-20. The author followed TENEX (or vice versa) on this journey, and these are some reflections and observations from that journey. He touches on some of the technical aspects that made TENEX notable in its day and an influence on operating systems that followed as well as on some of the people and other facets involved in the various steps along the way.},
  keywords = {BBN-LISP,s2z}
}

@misc{museum+labsLivingcomputermuseumDarkstar2020,
  title = {Livingcomputermuseum/Darkstar},
  author = {Museum+Labs, Living Computers:},
  year = {2020},
  month = dec,
  url = {https://github.com/livingcomputermuseum/Darkstar},
  urldate = {2021-04-15},
  abstract = {A Xerox Star 8010 Emulator. Contribute to livingcomputermuseum/Darkstar development by creating an account on GitHub.},
  copyright = {BSD-2-Clause License},
  isbn = {N/A},
  keywords = {Dandelion,Emulation,Reviewed by SHFT - CSUCI (Ron Vincent A.),Star,sz}
}

@inproceedings{myersBackgroundINTERNISTQMR1987,
  title = {The Background of INTERNIST I and QMR},
  booktitle = {Proceedings of ACM Conference on History of Medical Informatics},
  author = {Myers, J. D.},
  year = {1987},
  month = dec,
  series = {HMI '87},
  pages = {195--197},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/41526.41543},
  url = {https://doi.org/10.1145/41526.41543},
  urldate = {2021-04-15},
  abstract = {During my tenure as Chairman of the Department of Medicine at the University of Pittsburgh, 1955 to 1970, two points became clear in regard to diagnosis in internal medicine. The first was that the knowledge base in that field had become vastly too large for any single person to encompass it. The second point was that the busy practitioner, even though he knew the items of information pertinent to his patients correct diagnosis, often did not consider the right answer particularly if the diagnosis was an unusual disease. I resigned the position of Chairman in 1970 intending to resume my position as Professor of Medicine. However, the University saw fit to offer me the appointment as University Professor (Medicine). The University of Pittsburgh follows the practice of Harvard University, established by President James Bryant Conant in the late 1930s, in which a University Professor is a professor at large and reports only to the president of the university. He has no department, no school and is not under administrative supervision by a dean or vice-president. Thus the position allows maximal academic freedom. In this new position I felt strongly that I should conduct worthwhile research. It was almost fifteen years since I had worked in my chosen field of clinical investigation, namely splanchnic blood flow and metabolism, and I felt that research in that area had passed me by. Remembering the two points mentioned earlier — the excessive knowledge base of internal medicine and the problem of considering the correct diagnosis — I asked myself what could be done to correct these problems. It seemed that the computer with its huge memory could correct the first and I wondered if it could not help as well with the second. At that point I knew no more about computers than the average layman so I sought advice. Dr. Gerhard Werner, our Chairman of Pharmacology, was working with computers in an attempt to map all of the neurological centers of the human brain stem with particular reference to their interconnections and functions. He was particularly concerned about the actions of pharmacological agents on this complex system. Working with him on this problem was Dr. Harry Pople, a computer scientist with special interest in “artificial intelligence”. The problem chosen was so complex and difficult that Werner and Pople were making little progress. Gerhard listened patiently to my ideas and promptly stated that he thought the projects were feasible utilizing the computer. In regard to the diagnostic component of my ambition he strongly advised that “artificial intelligence” be used. Pople was brought into the discussion and was greatly interested, I believe because of the feasibility of the project and the recognition of its practical application to the practice of medicine. The upshot was that Pople joined me in my project and Werner and Pople abandoned the work on the brain stem. Pople knew nothing about medicine and I knew nothing about computer science. Thus the first step in our collaboration was my analysis for Pople of the diagnostic process. I chose a goodly number of actual cases from clinical pathological conferences (CPCs) because they contained ample clinical data and because the correct diagnoses were known. At each small step of the way through the diagnostic process I was required to explain what the clinical information meant in context and my reasons for considering certain diagnoses. This provided to Pople insight into the diagnostic process. After analyzing dozens of such cases I felt as though I had undergone a sort of “psychoanalysis”. From this experience Pople wrote the first computer diagnostic programs seeking to emulate my diagnostic process. This has led certain “wags” to nickname our project “Jack in the box”. For this initial attempt Pople used the LISP computer language. We were granted access to the PROPHET PDP-10, a time-sharing mainframe maintained in Boston by the National Institutes of Health (NIH) but devoted particularly to pharmacological research. Thus we were interlopers. The first name we applied to our project was DIALOG, for diagnostic logic, but this had to be dropped because the name was in conflict with a computer program already on the market and copyrighted. The next name chosen was INTERNIST for obvious reason. However, the American Society for Internal Medicine publishes a journal entitled “The Internist” and they objected to our use of INTERNIST although there seems to be little relationship or conflict between a printed journal and a computer software program. Rather than fight the issue we simply added the Roman numeral one to our title which then became INTERNIST-I, which continues to this day. Pople's initial effort was unsuccessful, however. He diligently had incorporated details regarding anatomy and much basic pathophysiology, I believe because in my initial CPC analyses I had brought into consideration such items of information so that Pople could understand how I got from A to B etc. The diagnostician in internal medicine knows, of course, much anatomy and patho-physiology but these are brought into consideration in only a minority of diagnostic problems. He knows, for example, that the liver is in the right upper quadrant and just beneath the right leaf of the diaphragm. In most diagnostic instances this information is “subconscious”. Our first computer diagnostic program included too many such details and as a result was very slow and frequently got into analytical “loops” from which it could not extricate itself. We decided that we had to simplify the program but by that juncture much of 1971 had passed on. The new program was INTERNIST-I and even today most of the basic structure devised in 1972 remains intact. INTERNIST-I is written in INTERLISP and has operated on the PDP-10 and the DEC 2060. It has also been adapted to the VAX 780. Certain younger people have contributed significantly to the program, particularly Dr. Zachary Moraitis and Dr. Randolph Miller. The latter interrupted his regular medical school education to spend the year 1974-75 as a fellow in our laboratory and since finishing his formal medical education in 1979 has been active as a full time faculty member of the team. Several Ph.D. candidates in computer science have also made significant contributions as have dozens of medical students during electives on the project. INTERNIST-I is really quite a simple system as far as its operating system or inference engine is concerned. Three basic numbers are concerned in and manipulated in the ranking of elicited disease hypotheses. The first of these is the importance (IMPORT) of each of the more than 4,100 manifestations of disease which are contained in the knowledge base. IMPORTS are a global representation of the clinical importance of a given finding graded from 1 to 5, the latter being maximal, focusing on how necessary it is to explain the manifestation regardless of the final diagnosis. Thus massive splenomegaly has an IMPORT of 5 whereas anorexia has an IMPORT of 1. Mathematical weights are assigned to IMPORT numbers on a non-linear scale. The second basic number is the evoking strength (EVOKS), the numbers ranging from 0 to 5. The number answers the question, that given a particular manifestation of disease, how strongly does one consider disease A versus all other diagnostic possibilities in a clinical situation. A zero indicates that a particular clinical manifestation is non-specific, i.e. so widely spread among diseases that the above question cannot be answered usefully. Again, anorexia is a good example of a non-specific manifestation. The EVOKS number 5, on the other hand, indicates that a manifestation is essentially pathognomonic for a particular disease. The third basic number is the frequency (FREQ) which answers the question that given a particular disease what is the frequency or incidence of occurrence of a particular clinical finding. FREQ numbers range from 1 to 5, one indicating that the finding is rare or unusual in the disease and 5 indicating that the finding is present in essentially all instances of the disease. Each diagnosis which is evoked is ranked mathematically on the basis of support for it, both positive and negative. Like the import number, the values for EVOKS and FREQ numbers increase in a non-linear fashion. The establishment or conclusion of a diagnosis is not based on any absolute score, as in Bayesian systems, but on how much better is the support of diagnosis A as compared to its nearest competitor. This difference is anchored to the value of an EVOKS of 5, a pathognomonic finding. When the list of evoked diagnoses is ranked mathematically on the basis of EVOKS, FREQ and IMPORT, the list is partitioned based upon the similarity of support for individual diagnoses. Thus a heart disease is compared with other heart diseases and not brain diseases since the patient may have a heart disorder and a brain disease concommitantly. Thus apples are compared with apples and not oranges. When a diagnosis is concluded, the computer consults a list of interrelationships among diseases (LINKS) and bonuses are awarded, again in a non-linear fashion for numbers ranging from 1 to 5 — 1 indicating a weak interrelationship and 5 a universal interrelationship. Thus multiple interrelated diagnoses are preferred over independent ones provided the support for the second and other diagnoses is adequate. Good clinicians use this same rule of thumb. LINKS are of various types: PCED is used when disease A precedes disease B, e.g. acute rheumatic fever precedes early rheumatic valvular disease; PDIS - disease A predisposes to disease B, e.g. AIDS predisposes to pneumocystis pneumonia; CAUS - disease A causes disease B, e.g. thrombophlebitis of the lower extremities may cause pulmonary embolism; and COIN - there is a statistical interrelationship between disease A and disease B but scientific medical information is not explicit on the relationship, e.g. Hashimoto's thyroiditis coincides with pernicious anemia, both so called autoimmune diseases. The maximal number of correct diagnoses made in a single case analysis is, to my recollection, eleven. In working with INTERNIST-I during the remainder of the 1970s several important points about the system were learned or appreciated. The first and foremost of these is the importance of a complete and accurate knowledge base. Omissions from a disease profile can be particularly troublesome. If a manifestation of disease is not listed on a disease profile the computer can only conclude that that manifestation does not occur in the disease, and if a patient demonstrates the particular manifestation it counts against the diagnosis. Fortunately, repeated exercise of the diagnostic system brings to attention many inadvertent omissions. It is important to establish the EVOKS and FREQ numbers as accurately as possible. Continual updating of the knowledge base, including newly described diseases and new information about diseases previously profiled, is critical. Dr. Edward Feigenbaum recognized the importance of the accuracy and completeness of knowledge bases as the prime requisite of expert systems of any sort. He emphasized this point in his keynote address to MEDINFO-86 (1). Standardized, clear and explicit nomenclature is required in expressing disease names and particularly in naming the thousands of individual manifestations of disease. Such rigidity can make the use of INTERNIST-I difficult for the uninitiated user. Therefore, in QMR more latitude and guidance is provided the user. For example, the user of INTERNIST-I must enter ABDOMEN PAIN RIGHT UPPER QUADRANT exactly whereas in QMR the user may enter PAI ABD RUQ and the system recognizes the term as above. The importance of “properties” attached to the great majority of clinical manifestations was solidly evident. Properties express such conditions that if A is true then B is automatically false (or true as the case may be). The properties also allow credit to be awarded for or against B as the case may be. Properties also provide order to the asking of questions in the interrogative mode. They also state prerequisites and unrequisites for various procedures. As examples, one generally does not perform a superficial lymph node biopsy unless lymph nodes are enlarged (prerequisite). Similarly, a percutaneous liver biopsy is inadvisable if the blood platelets are less than 50,000 (unrequisite). It became clear quite early in the utilization of INTERNIST-I that systemic or multisystem diseases had an advantage versus localized disorders in diagnosis. This is because systemic diseases have very long and more inclusive manifestation lists. It became necessary, therefore, to subdivide systemic diseases into various components when appropriate. Systemic lupus erythematosus provides a good example. Lupus nephritis must be compared in our system with other renal diseases and such comparison is allowed by our partitioning algorithm. Likewise, cerebral lupus must be differentiated from other central nervous system disorders. Furthermore, either renal lupus or cerebral lupus can occur at times without significant clinical evidence of other systemic involvement. In order to reassemble the components of a systemic disease we devised the systemic LINK (SYST) which expresses the interrelationship of each subcomponent to the parent systemic disease. It became apparent quite early that expert systems like INTERNIST do not deal with the time axis of a disease well at all, and this seems to be generally true of expert systems in “artificial intelligence”. Certain parameters dealing with time can be expressed by devising particular manifestations, e.g. a blood transfusion preceding the development of acute hepatitis B by 2 to 6 months. But time remains a problem which is yet to be solved satisfactorily including QMR. It has been clearly apparent over the years that both the knowledge base and the diagnostic consultant programs of both INTERNIST-I and QMR have considerable educational value. The disease profiles, the list of diseases in which a given clinical manifestation occurs (ordered by EVOKS and FREQ), and the interconnections among diseases (LINKS) provide a quick and ready means of acquiring at least orienting clinical information. Such has proved useful not only to medical students and residents but to clinical practitioners as well. In the interrogative mode of the diagnostic systems the student will frequently ask “Why was that question asked?” An instructor can either provide insight or ready consultation of the knowledge base by the student will provide a simple semi-quantitative reason for the question. Lastly, let the author state that working with INTERNIST-I and QMR over the years seems to have had real influence on his own diagnostic approaches and habits. Thus my original psycho-analysis when working with Pople has been reinforced.},
  isbn = {978-0-89791-248-8},
  keywords = {sz}
}

@misc{myersScrollbars2014,
  title = {Scrollbars},
  author = {Myers, Brad},
  year = {2014},
  month = sep,
  publisher = {worrydream},
  url = {https://www.youtube.com/watch?v=Hg4YFuz6HT8},
  urldate = {2021-05-02},
  abstract = {Scrollbars, in Interlisp-D, appear on a window only when they are needed. src: https://vimeo.com/61556918\hspace{0pt}},
  keywords = {sz}
}

@inproceedings{naralnLargescaleSystemDevelopment1983,
  title = {Large-Scale System Development in Several Lisp Environments},
  booktitle = {Proceedings of the Eighth International Joint Conference on Artificial Intelligence - Volume 2},
  author = {Naraln, Sanjai and McArthur, David and Klahr, Philip},
  year = {1983},
  month = aug,
  series = {IJCAI'83},
  pages = {859--861},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco},
  url = {https://dl.acm.org/doi/10.5555/1623516.1623579},
  urldate = {2021-06-03},
  abstract = {ROSS [7] is an object-oriented language developed for building knowledge-based simulations [4]. SWIRL [5, 6] is a program written in ROSS that embeds knowledge about defensive and offensive air battle strategies. Given an initial configuration of military forces, SWIRL simulates the resulting air battle. We have implemented ROSS and SWIRL in several different Lisp environments. We report upon this experience by comparing the various environments in terms of cpu usage, real-time usage, and various user aids.},
  keywords = {sz}
}

@inproceedings{newmanPEPYSGeneratingAutobiographies1991,
  title = {PEPYS: Generating Autobiographies by Automatic Tracking},
  shorttitle = {PEPYS},
  author = {Newman, William and Eldridge, Margery and Lamming, Michael},
  year = {1991},
  month = jan,
  doi = {10.1007/978-94-011-3506-1_13},
  abstract = {This paper presents one part of a broad research project entitled 'Activity-Based Information Retrieval' (AIR) which is being carded out at EuroPARC. The basic hypothesis of this project is that if contextual data about human activities can be automatically captured and later presented as recognisable descriptions of past episodes, then human memory of those past episodes can be improved. This paper describes an application called Pepys, designed to yield descriptions of episodes based on automatically collected location data. The program pays particular attention to meetings and other episodes involving two or more people. The episodes are presented to the user as a diary generated at the end of each day and distributed by electronic mail. The paper also discusses the methods used to assess the accuracy of the descriptions generated by the recogniser.},
  isbn = {978-0-7923-1439-4},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\JJ4SFENY\\Newman et al. - 1991 - PEPYS Generating Autobiographies by Automatic Tra.pdf}
}

@book{newquistBrainMakers1994,
  title = {The Brain Makers},
  author = {Newquist, H. P. (Harvey P. )},
  year = {1994},
  publisher = {Indianapolis, Ind. : Sams Pub.},
  url = {http://archive.org/details/brainmakers0000newq},
  urldate = {2022-09-29},
  abstract = {xv, 488 p. ; 24 cm; Includes index},
  collaborator = {{Internet Archive}},
  isbn = {978-0-672-30412-5},
  langid = {english},
  keywords = {Artificial intelligence -- History}
}

@article{novakjrGLISPLispbasedProgramming1983,
  title = {GLISP: A Lisp-Based Programming System with Data Abstraction},
  shorttitle = {GLISP},
  author = {Novak, Jr, Gordon S.},
  year = {1983},
  url = {https://www.cs.utexas.edu/users/ai-lab/?novak:aimag83},
  urldate = {2022-08-05},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\DTIZPG2Y\\ai-lab.html}
}

@patent{nunbergMethodManipulatingDigital1998,
  title = {Method for Manipulating Digital Text Data},
  author = {Nunberg, Geoffrey D. and Stansbury, Tayloe H. and Abbott, Curtis and Smith, Brian C.},
  year = {1998},
  month = jun,
  number = {EP0370778B1},
  url = {https://patents.google.com/patent/EP0370778B1/en},
  urldate = {2021-06-01},
  assignee = {Xerox Corp},
  langid = {english},
  nationality = {EP},
  keywords = {data,punctuational,sz,text,units,words},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\QT5Q9B6C\\Nunberg et al. - 1998 - Method for manipulating digital text data.pdf}
}

@misc{oldfordGraphicalProgramming19882012,
  title = {Graphical Programming (1988) - Parts 1 and 2},
  author = {Oldford, Wayne},
  year = {2012},
  month = feb,
  publisher = {Xerox Lisp Workstation},
  url = {https://www.youtube.com/watch?v=wlN0hHLZL8c},
  urldate = {2021-05-02},
  abstract = {Guy DesVignes and R. Wayne Oldford, 1988    This video (in 3 pieces) describes the use of graphical programming with an example, showing the encapsulation of several steps of an analysis into a single reusable tool.   An INTERLISP-D programming environment with the object oriented system LOOPS is used for software development.  Work is on a Xerox Lisp Workstation  (Xerox 1186).    Second of 3 pieces of a single video.    First piece: Graphical Programming (1988) - Part 0         Contains:          "Opening"                -  Introduction by Wayne Oldford                   (refers to earlier video called "Data Analysis Networks                  in DINDE")          "Part 0 Statistical Analysis Maps"              - review of the interactive data analysis network representation                 of a statistical analysis.    Second piece:  Graphical Programming (1988) - Parts 1 and 2         Contains:          "Part 1   Toolboxes"                -  Review of the elements of a statistical toolbox in DINDE          "Part 2 The Analysis Path"              - Demonstrates exploration of a path in an existing                analysis map and its representation as a pattern,                It is shown how to capture this pattern in DINDE as a new               new program represented as an "AnalysisPath" object..                This is what is meant by  "graphical programming".      Third piece: "Graphical Programming (1988) - Part 3"         Contains:          "Part 3   Graphical Programming                          Example: Added Variable Plots"                - Demonstrates graphical programming by constructing                an added variable plot.  This is done by constructing the                appropriate analysis path on some data, capturing the pattern                adding it to the toolbox and then applying it to new data.            "Summary"      Sound has been cleaned up a little.  Complete video also available in whole at           stat-graphics.org/movies/graphical-programming.html},
  keywords = {sz}
}

@misc{oldfordGraphicalProgramming19882012a,
  title = {Graphical Programming (1988) - Part 0},
  author = {Oldford, Wayne},
  year = {2012},
  month = feb,
  publisher = {Xerox Lisp Workstation},
  url = {https://www.youtube.com/watch?v=J4F6ioMKiqw&t=53s},
  urldate = {2021-05-02},
  abstract = {Guy DesVignes and R. Wayne Oldford, 1988    This video (in 3 pieces) describes the use of graphical programming with an example, showing the encapsulation of several steps of an analysis into a single reusable tool.   An INTERLISP-D programming environment with the object oriented system LOOPS is used for software development.  Work is on a Xerox Lisp Workstation  (Xerox 1186).    First of 3 pieces of a single video.    First piece: Graphical Programming (1988) - Part 0         Contains:          "Opening"                -  Introduction by a young Wayne Oldford                   (refers to earlier video called "Data Analysis Networks                  in DINDE")          "Part 0 Statistical Analysis Maps"              - review of the interactive data analysis network representation                 of a statistical analysis.    Second piece:  Graphical Programming (1988) - Parts 1 and 2         Contains:          "Part 1   Toolboxes"                -  Review of the elements of a statistical toolbox in DINDE          "Part 2 The Analysis Path"              - Demonstrates exploration of a path in an existing                analysis map and its representation as a pattern,                It is shown how to capture this pattern in DINDE as a new               new program represented as an "AnalysisPath" object..                This is what is meant by  "graphical programming".      Third piece: "Graphical Programming (1988) - Part 3"         Contains:          "Part 3   Graphical Programming                          Example: Added Variable Plots"                - Demonstrates graphical programming by constructing                an added variable plot.  This is done by constructing the                appropriate analysis path on some data, capturing the pattern                adding it to the toolbox and then applying it to new data.            "Summary"      Sound has been cleaned up a little.  Complete video also available in whole at           stat-graphics.org/movies/graphical-programming.html},
  keywords = {sz}
}

@inproceedings{padgetDesiderataStandardizationLISP1986,
  title = {Desiderata for the Standardization of LISP},
  booktitle = {Proceedings of the 1986 ACM Conference on LISP and Functional Programming},
  author = {Padget, Julian and Chailloux, Jérôme and Christaller, Thomas and DeMantaras, Ramon and Dalton, Jeff and Devin, Matthieu and Fitch, John and Krumnack, Timm and Neidl, Eugen and Papon, Eric and Pope, Stephen and Queinnec, Christian and Steels, Luc and Stoyan, Herbert},
  year = {1986},
  month = aug,
  series = {LFP '86},
  pages = {54--66},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/319838.319850},
  url = {https://doi.org/10.1145/319838.319850},
  urldate = {2021-04-25},
  abstract = {This paper reports work-in-progress within the LISP community on efforts to bring the LISP language to national and international standardisation. The paper discusses the objective criteria that have been established, how it is planned that these will be satisfied, when it is expected these will be fulfilled and what it still open. The Common LISP definition has made a very valuable contribution to the standardisation of LISP and the current authors have learned much from that experience. The result is a rationale for how LISP could be standardised along with identification of key features in the language and its environment, which together lead to a layered definition. This is followed by detail of the proposal for LISP standardisation based on the strategies that will have been outlined.},
  isbn = {978-0-89791-200-4},
  keywords = {sz}
}

@article{petrusSKILLLispBased1993,
  title = {SKILL: A Lisp Based Extension Language},
  shorttitle = {SKILL},
  author = {Petrus, Edwin S.},
  year = {1993},
  month = jul,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {VI},
  number = {3},
  pages = {71--79},
  issn = {1045-3563},
  doi = {10.1145/174169.174185},
  url = {https://doi.org/10.1145/174169.174185},
  urldate = {2021-06-02},
  abstract = {This paper describes an experience with Lisp as an extension language for a large electronics CAD environment and the role it plays in software design automation. This paper is not about extension languages in general, for an analysis of extension languages in CAD, see, [HNS90] and [Bar89]. Cadence is a full range supplier of software based Electronics CAD tools.},
  langid = {english},
  keywords = {sz}
}

@article{pitmanAmbitiousEvaluationNew1995,
  title = {Ambitious Evaluation: A New Reading of an Old Issue},
  shorttitle = {Ambitious Evaluation},
  author = {Pitman, Kent M.},
  year = {1995},
  month = may,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {VIII},
  number = {2},
  pages = {1--44},
  issn = {1045-3563},
  doi = {10.1145/224133.224137},
  url = {https://dl.acm.org/doi/10.1145/224133.224137},
  urldate = {2021-04-25},
  abstract = {Much has been written about Lazy Evaluation in Lisp---less about the other end of the spectrum---Ambitious Evaluation. Ambition is a very subjective concept, though, and if you have some preconceived idea of what you think an Ambitious Evaluator might be about, you might want to set it aside for a few minutes because this probably isn't going to be what you expect.},
  langid = {english},
  keywords = {sz}
}

@misc{pitmanCommonLispCondition1988,
  title = {Common Lisp Condition System},
  shorttitle = {Common-Lisp},
  author = {Pitman, Kent M.},
  year = {1988},
  month = mar,
  url = {http://www.nhplace.com/kent/CL/Revision-18.txt},
  urldate = {2021-04-16},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\94PMP5UF\\Revision-18.html}
}

@inproceedings{pitmanCommonLispUntold2008,
  title = {Common Lisp: The Untold Story},
  shorttitle = {Common Lisp},
  booktitle = {Celebrating the 50th Anniversary of Lisp},
  author = {Pitman, Kent M.},
  year = {2008},
  month = oct,
  series = {LISP50},
  pages = {1--12},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1529966.1529972},
  url = {https://doi.org/10.1145/1529966.1529972},
  urldate = {2021-04-15},
  abstract = {This paper summarizes a talk given at "[email protected]," the 50th Anniversary of Lisp workshop, Monday, October 20, 2008, an event co-located with the OOPSLA'08 in Nashville, TN, in which I offered my personal, subjective account of how I came to be involved with Common Lisp and the Common Lisp standard, and of what I learned from the process. The account highlights the role of luck in the way various details of history played out, emphasizing the importance of seizing and making the best of the chance opportunities that life presents. The account further underscores the importance of understanding the role of controlling influences such as funding and intellectual property in shaping processes and outcomes. As noted by Louis Pasteur, "chance favors the prepared mind." The talk was presented extemporaneously from notes. As such, it covered the same general material as does this paper, although the two may differ in details of structure and content. It is suggested that the talk be viewed as an invitation to read this written text, and that the written account be deemed my position of record on all matters covered in the talk.},
  isbn = {978-1-60558-383-9},
  keywords = {ANSI,common Lisp,copyright,funding,history,intellectual property,ISLISP,ISO,politics,sz}
}

@article{prakashFrameworkUndoingActions1994,
  title = {A Framework for Undoing Actions in Collaborative Systems},
  author = {Prakash, Atul and Knister, Michael J.},
  year = {1994},
  month = dec,
  journal = {ACM Transactions on Computer-Human Interaction},
  volume = {1},
  number = {4},
  pages = {295--382},
  issn = {1073-0516},
  doi = {10.1145/198425.198427},
  url = {https://doi.org/10.1145/198425.198427},
  urldate = {2021-04-15},
  abstract = {The ability to undo operations is a standard feature in most single-user interactive applications. We propose a general framework for implementing undo in collaborative systems. The framework allows users to reverse their own changes individually, taking into account the possibility of conflicts between different users' operations that may prevent an undo. The proposed framework has been incorporated into DistEdit, a toolkit for building group text editors. Based on our experience with DistEdit's undo facilities, we discuss several issues that need to be taken into account in using the framework, in order to ensure that a reasonable undo behavior is provided to users. We show that the framework is also applicable to single-user systems, since the operations to undo can be selected not just on the basis of who performed them, but by any appropriate criterion, such as the document region in which the operations occurred or the time interval in which the operations were carried out.},
  keywords = {computer-supported cooperative work,concurrency control,DistEdit,groupware,selective undo,state recovery,sz,undo,user recovery}
}

@inproceedings{prakashUndoingActionsCollaborative1992,
  title = {Undoing Actions in Collaborative Work},
  booktitle = {Proceedings of the 1992 ACM Conference on Computer-Supported Cooperative Work},
  author = {Prakash, Atul and Knister, Michael J.},
  year = {1992},
  month = dec,
  series = {CSCW '92},
  pages = {273--280},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/143457.143527},
  url = {https://doi.org/10.1145/143457.143527},
  urldate = {2021-04-15},
  abstract = {The abihly to undo operations is a standard feature in most single-user interactive applications. However, most current collaborative applications that allow several users to work simultaneously on a shared document lack undo capabilities; those which provide undo generally provide only a globe undo, in which the last change made by anyone to a document is undone, rather than allowing users to individually reverse their own changes. In this paper, we propose a general framework for undoing actions in collaborative systems. The framework takes into account the possibility of conflicts between different users' actions that may prevent a normal undo. The framework also allows selection of actions to undo based on who performed them, where they occurred, or any other appropriate criterion.},
  isbn = {978-0-89791-542-7},
  keywords = {collaboration,conflict analysis,groupware,sz,undo}
}

@book{prattLISPanAmicusCuriae1977,
  title = {LISP-an Amicus Curiae Brief},
  author = {Pratt, V. R.},
  year = {1977},
  month = jan,
  url = {http://www.softwarepreservation.net/projects/LISP/MIT/Pratt-LISP_Amicus_Curiae_Brief-1977.pdf},
  abstract = {To the complexity of building a single interface between people, machines, and problems, which has made this brief so long},
  keywords = {sz}
}

@misc{provenThoughtsRaisingProfile2021,
  type = {Blog},
  title = {Some Thoughts about Raising the Profile of Lisp},
  author = {Proven, Liam},
  year = {2021},
  month = aug,
  journal = {Some thoughts about raising the profile of Lisp},
  url = {https://liam-on-linux.livejournal.com/81798.html},
  urldate = {2021-09-04},
  abstract = {I must be mellowing in my old age (possibly as opposed to bellowing) because I have been getting praise and compliments recently on comments in various places. Dont worry, there are still people angrily shouting at me as well. This was the earlier comment, I think... There was a slightly…},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\EVFRN6N3\\81798.html}
}

@article{queinnecSubjectiveViewLisp1989,
  title = {A Subjective View of Lisp},
  author = {Queinnec, Christian},
  year = {1989},
  month = jul,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {III},
  number = {1},
  pages = {7--61},
  issn = {1045-3563},
  doi = {10.1145/121999.122004},
  url = {https://dl.acm.org/doi/10.1145/121999.122004},
  urldate = {2021-04-25},
  abstract = {No abstract available},
  langid = {english},
  keywords = {sz}
}

@article{raoRichInteractionDigital1995,
  title = {Rich Interaction in the Digital Library},
  author = {Rao, Ramana and Pedersen, Jan O. and Hearst, Marti A. and Mackinlay, Jock D. and Card, Stuart K. and Masinter, Larry and Halvorsen, Per-Kristian and Robertson, George C.},
  year = {1995},
  month = apr,
  journal = {Communications of the ACM},
  volume = {38},
  number = {4},
  pages = {29--39},
  issn = {0001-0782},
  doi = {10.1145/205323.205326},
  url = {https://doi.org/10.1145/205323.205326},
  urldate = {2021-04-25},
  abstract = {Effective information access involves rich interactions between users and information residing in diverse locations. Users seek and retrieve information from the sources—for example, file serves, databases, and digital libraries—and use various tools to browse, manipulate, reuse, and generally process the information. We have developed a number of techniques that support various aspects of the process of user/information interaction. These techniques can be considered attempts to increase the bandwidth and quality of the interactions between users and information in an information workspace—an environment designed to support information work (see Figure 1).},
  keywords = {sz}
}

@patent{raoWindowSystemIndependently1992,
  title = {Window System with Independently Replaceable Window Functionality},
  author = {Rao, Ramana B.},
  year = {1992},
  month = jun,
  number = {US5121478A},
  url = {https://patents.google.com/patent/US5121478A},
  urldate = {2021-04-16},
  abstract = {A workspace data structure, such as a window hierarchy or network, includes functional data units that include data relating to workspace functionality. These functional data units are associated with data units corresponding to the workspaces such that a functional data unit can be replaced by a functional data unit compatible with a different set of functions without modifying the structure of other data units. Each workspace data unit may have a replaceably associated functional data unit called an input contract relating to its input functions and another called an output contract relating to its output functions. A parent workspace's data unit and the data units of its children may together have a replaceably associated functional data unit, called a windowing contract, relating to the windowing relationship between the parent and the children. The data structure may also include an auxiliary data unit associated between the data units of the parent and children windows, and the windowing contract may be associated with the auxiliary data unit. The contracts can be accessed and replaced by a processor in a system that includes the data structure. The contracts can be instances of classes in an object-oriented programming language, and can be replaceably associated by pointers associated with the system objects. Alternatively, a contract can be replaceably associated through dynamic multiple inheritance, with the superclasses of each workspace class including one or more contract classes such that changing the class of an instance of a workspace class serves to replace the contract.},
  assignee = {Xerox Corporation},
  nationality = {United States},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\A232G9JM\\Rao - 1992 - Window system with independently replaceable windo.pdf}
}

@patent{rebohDatadrivenFunctionalExpert1989,
  title = {Data-Driven, Functional Expert System Shell},
  author = {Reboh, Rene and {Tore J. M. Risch}},
  year = {1989},
  month = sep,
  number = {US4866634A},
  url = {https://patents.google.com/patent/US4866634A},
  urldate = {2021-04-16},
  abstract = {An expert system shell efficiently computes functions of variables in response to numeric or symbolic data values input by a user. The system comprises a Knowledge Base in the form of a network of functions, an Inference Engine for efficiently updating values in the knowledge base in response to changes in entered data, and a Forms System that manages interaction with the user. A knowledge engineer creates the network of functions, and defines the user screens and the connection between screen objects and variables in the function network. The system allows many different types of variables, including numeric and symbolic types. The system associates a probability distribution with every variable, and computes the probability distributions for the dependent variables from the probability distributions for the independent variables. A variable can store multiple values as tables of probability distributions keyed by one or more key variables. When a user action changes the probability distributions for any variable, the system automatically maintains the specified functional relationships among all the related variables.},
  assignee = {Syntelligence},
  langid = {english},
  nationality = {United States},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\8PZRYAN7\\Reboh - 1989 - Data-driven, functional expert system shell.pdf}
}

@techreport{rebohPreliminaryQLISPManual1973,
  title = {A Preliminary QLISP Manual},
  author = {Reboh, Rene and Sacerdoti, Earl},
  year = {1973},
  month = aug,
  pages = {38},
  institution = {Stanford Research Institute Menlo Park United States},
  url = {https://apps.dtic.mil/sti/citations/AD1015722},
  urldate = {2021-05-29},
  abstract = {A preliminary version of QL1SP is described. QLISP permits free intermingling of QA4-like constructs with INTERLISP code. The preliminary version contains features similar to those of QA4 except for the backtracking of control environments. It provides several new features as well. This preliminary manual presumes a familiarity with both INTERL1SPand the basic concepts of QA4. It is intended to update rather than replace the existing documentation of QA4.},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {sz}
}

@article{reissDesertEnvironment1999,
  title = {The Desert Environment},
  author = {Reiss, Steven P.},
  year = {1999},
  month = oct,
  journal = {ACM Transactions on Software Engineering and Methodology},
  volume = {8},
  number = {4},
  pages = {297--342},
  issn = {1049-331X},
  doi = {10.1145/322993.322994},
  url = {https://doi.org/10.1145/322993.322994},
  urldate = {2021-04-15},
  abstract = {The Desert software engineering environment is a suite of tools developed to enhance programmer productivity through increased tool integration. It introduces an inexpensive form of data integration to provide additional tool capabilities and information sharing among tools, uses a common editor to give high-quality semantic feedback and to integrate different types of software artifacts, and builds virtual files on demand to address specific tasks. All this is done in an open and extensible environment capable of handling large software systems.},
  keywords = {integrated programming environments,program editors,sz},
  annotation = {Annotation: This is an example of an annotation on an item.}
}

@inproceedings{reissSimplifyingDataIntegration1996,
  title = {Simplifying Data Integration: The Design of the Desert Software Development Environment},
  shorttitle = {Simplifying Data Integration},
  booktitle = {Proceedings of the 18th International Conference on Software Engineering},
  author = {Reiss, Steven P.},
  year = {1996},
  month = may,
  series = {ICSE '96},
  pages = {398--407},
  publisher = {IEEE Computer Society},
  address = {USA},
  url = {https://dl.acm.org/doi/10.5555/227726.227811},
  urldate = {2021-06-02},
  abstract = {This paper describes the design and motivations behind the Desert environment. The Desert environment has been created to demonstrate that the facilities typically associated with expensive data integration can be provided inexpensively in an open framework. It uses three integration mechanisms: control integration, simple data integration based on fragments, and a common editor. It offers a variety of capabilities including hyperlinks and the ability to create virtual files containing only the portions of the software that are relevant to the task on hand. It does this in an open environment that is compatible with existing tools and programs. The environment currently consists of a set of support facilities including a context database, a fragment database, scanners, and a ToolTalk interface, as well as a preliminary set of programming tools including a context manager and extensions to FrameMaker to support program editing and insets for non-textual software artifacts.},
  isbn = {9780818672463},
  keywords = {common editor,context manager,control integration,data integration,Desert environment,Desert software development environment,fragments,FrameMaker,hyperlinks,programming environments,programming tools,software engineering,software tools,sz,ToolTalk interface,virtual files}
}

@inproceedings{rhodesUsingLispbasedPseudocode2018,
  title = {Using Lisp-Based Pseudocode to Probe Student Understanding},
  booktitle = {Proceedings of the 11th European Lisp Symposium on European Lisp Symposium},
  author = {Rhodes, Christophe},
  year = {2018},
  month = apr,
  series = {ELS2018},
  pages = {68--75},
  publisher = {European Lisp Scientific Activities Association},
  address = {Marbella, Spain},
  url = {https://dl.acm.org/doi/10.5555/3323215.3323225},
  urldate = {2021-04-25},
  abstract = {We describe our use of Lisp to generate teaching aids for an Algorithms and Data Structures course taught as part of the undergraduate Computer Science curriculum. Specifically, we have made use of the ease of construction of domain-specific languages in Lisp to build an restricted language with programs capable of being pretty-printed as pseudocode, interpreted as abstract instructions, and treated as data in order to produce modified distractor versions. We examine student performance, report on student and educator reflection, and discuss practical aspects of delivering using this teaching tool.},
  isbn = {978-2-9557474-2-1},
  keywords = {Lisp,multiple choice questions,sz}
}

@misc{rindfleischNOTESXEROXLISP,
  title = {NOTES ON XEROX LISP MACH DEMO},
  author = {Rindfleisch},
  url = {https://ml.cddddr.org/lisp@parc/msg00137.html},
  urldate = {2021-09-16},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\E7MVMRLT\\msg00137.html}
}

@techreport{rosenthalEmulationVirtualizationPreservation2015,
  title = {Emulation \& Virtualization as Preservation Strategies},
  author = {Rosenthal, David S.H.},
  year = {2015},
  month = oct,
  institution = {The Andrew W. Mellon Foundation},
  urldate = {2016-01-23},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\F2GF8RDB\\Rosenthal - 2015 - Emulation & Virtualization as Preservation Strateg.pdf}
}

@inproceedings{sacerdotiQlispLanguageInteractive1976,
  title = {Qlisp: A Language for the Interactive Development of Complex Systems},
  shorttitle = {Qlisp},
  booktitle = {Proceedings of the June 7-10, 1976, National Computer Conference and Exposition},
  author = {Sacerdoti, Earl D. and Fikes, Richard E. and Reboh, Rene and Sagalowicz, Daniel and Waldinger, Richard J. and Wilber, B. Michael},
  year = {1976},
  pages = {349--356}
}

@article{saeedBookReviewEXPERT1990,
  title = {Book Review: EXPERT DATABASE SYSTEMS Proceedings from the 2nd Intl. Conference. April 25-27, 1988 Vienna, VA. Edited by Larry Kerschberg (Benjamin/Cummings Publishing Company, 1988)},
  shorttitle = {Book Review},
  author = {Saeed, Faisel},
  year = {1990},
  month = jun,
  journal = {ACM SIGART Bulletin},
  volume = {1},
  number = {2},
  pages = {21},
  issn = {0163-5719},
  doi = {10.1145/84234.1056291},
  url = {https://doi.org/10.1145/84234.1056291},
  urldate = {2021-04-25},
  abstract = {Expert Database Systems (EDS) has emerged in the recent years as a powerful combination of disciplines like Artificial Intelligence, Database Management, Logic Programming, and Fuzzy System Theory. This new field incorporates the benefits of both data-based and knowledge-based systems and has generated a great interest among the research, industrial and government communities. An International Workshop on EDS was held in South Carolina in October, 1984, which became the initiative for starting a series of International Conferences on EDS. The first conference on EDS was held in April, 1986 in South Carolina. The second conference, EDS'88, was held in Virginia on April 25--27, 1988. This conference was attended by 350 participants from Australia, Belgium, Brazil, Canada, Denmark, Egypt, England, Federal Republic of Germany, France, Ireland, Italy, Japan, Mexico, Netherlands, Singapore, the Soviet Union, Switzerland, and USA.},
  keywords = {sz}
}

@article{sandewallProgrammingInteractiveEnvironment1978,
  title = {Programming in an Interactive Environment: The "Lisp" Experience},
  shorttitle = {Programming in an Interactive Environment},
  author = {Sandewall, Erik},
  year = {1978},
  month = mar,
  journal = {ACM Computing Surveys},
  volume = {10},
  number = {1},
  pages = {35--71},
  issn = {0360-0300},
  doi = {10.1145/356715.356719},
  url = {https://doi.org/10.1145/356715.356719},
  urldate = {2021-06-02},
  abstract = {Lisp systems have been used for highly interactive programming for more than a decade. During that time, special properties of the Lisp language (such as program/ data equivalence) have enabled a certain style of interactive programming to develop. characterized by powerful interactive support for the programmer, nonstandard program structures, and nonstandard program development methods. The paper summa-rizes the Lisp style of interactive programming for readers outside the Lisp community, describes those properties of Lisp systems that were essential for the development of this style. and discusses some current and not yet resolved issues},
  keywords = {sz}
}

@book{sannellaInterlispDReferenceManual1985,
  title = {Interlisp-D Reference Manual, Volume III: Input/Output},
  shorttitle = {Volume III: Input/Output},
  editor = {Sannella, Michael},
  year = {1985},
  month = oct,
  volume = {3},
  publisher = {Xerox Corporation},
  address = {S.l.},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198510_Koto/3101274_Interlisp-D_Vol_3_Input_Output_Oct85.pdf},
  langid = {english},
  keywords = {Interlisp-D},
  annotation = {OCLC: 802551877}
}

@book{sannellaInterlispDReferenceManual1985a,
  title = {Interlisp-D Reference Manual, Volume II: Environment},
  shorttitle = {Volume II: Environment},
  editor = {Sannella, Michael},
  year = {1985},
  month = oct,
  volume = {2},
  publisher = {Xerox Corporation},
  address = {S.l.},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198510_Koto/3101273_Interlisp-D_Vol_2_Environment_Oct85.pdf},
  langid = {english},
  keywords = {Interlisp-D},
  annotation = {OCLC: 802551877}
}

@book{sannellaInterlispDReferenceManual1985b,
  title = {Interlisp-D Reference Manual, Volume I: Language},
  shorttitle = {Volume I: Language},
  editor = {Sannella, Michael},
  year = {1985},
  month = oct,
  volume = {1},
  publisher = {Xerox Corporation},
  address = {S.l.},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198510_Koto/3101272_Interlisp-D_Vol_1_Language_Oct85.pdf},
  langid = {english},
  keywords = {Interlisp-D},
  annotation = {OCLC: 802551877}
}

@inproceedings{schafmeisterCANDOCompiledProgramming2016,
  title = {CANDO: A Compiled Programming Language for Computer-Aided Nanomaterial Design and Optimization Based on Clasp Common Lisp},
  shorttitle = {CANDO},
  booktitle = {Proceedings of the 9th European Lisp Symposium on European Lisp Symposium},
  author = {Schafmeister, Christian E.},
  year = {2016},
  month = may,
  series = {ELS2016},
  pages = {75--82},
  publisher = {European Lisp Scientific Activities Association},
  address = {Kraków, Poland},
  url = {https://dl.acm.org/doi/abs/10.5555/3005729.3005738},
  urldate = {2021-04-25},
  abstract = {CANDO is a compiled programming language designed for rapid prototyping and design of macromolecules and nanometer-scale materials. CANDO provides functionality to write programs that assemble atoms and residues into new molecules and construct three-dimensional coordinates for them. CANDO also provides functionality for searching molecules for substructures, automatically assigning atom types, identifying rings, carrying out conformational searching, and automatically determining stereochemistry, among other things. CANDO extends the Clasp implementation of the dynamic language Common Lisp. CANDO provides classes for representing atoms, residues, molecules and aggregates (collections of molecules) as primitive objects that are implemented in C++ and subject to automatic memory management, like every other object within the language. CANDO inherits all of the capabilities of Clasp, including the easy incorporation of C++ libraries using a C++ template programming library. This automatically builds wrap- per code to expose the C++ functionality to the CANDO Common Lisp environment and the use of the LLVM library[1] to generate fast native code. A version of CANDO can be built that incorporates the Open Message Passing Interface C++ library[2], which allows CANDO to be run on supercomputers, in order to automatically setup, start, and analyze molecular mechanics simulations on large parallel computers. CANDO is currently available under the LGPL 2.0 license.},
  isbn = {978-2-9557474-0-7},
  keywords = {C++,Common Lisp,Computational Chemistry,Interoperation,LLVM{$>$},sz}
}

@techreport{schragNotesConversionLogLisp1983,
  title = {Notes on the Conversion of LogLisp from Rutgers/UCI-Lisp to InterLisp,},
  author = {Schrag, Robert C.},
  year = {1983},
  month = jan,
  institution = {ROME AIR DEVELOPMENT CENTER GRIFFISS AFB NY},
  url = {https://apps.dtic.mil/sti/citations/ADA127718},
  urldate = {2021-06-02},
  abstract = {Conversion of the LogLispLogic programming in Lisp Artificial Intelligence programming environment from its original RutgersUCI-Lisp RUCI-Lisp implementation to an InterLisp implementation is described. This report may be useful to researchers wishing to convert LogLisp to yet another Lisp dialect, or to those wishing to convert other RUCI-Lisp programs into InterLisp. It is also intended to help users of the InterLisp version of LogLisp to understand the implementation. The conversion process is described at a level aimed toward potential translators who might benefit from approaches taken and lessons learned. General issues of conversion of Lisp software between dialects are discussed, use of InterLisps dialect translation package is described, and specific issues of non-mechanizable conversion are addressed. The latter include dialect differences in function definitions, arrays, integer arithmetic, io, interrupts, and macros. Subsequent validation, compilation, and efficiency enhancement of the InterLisp version are then described. A brief users guide to the InterLisp version and points of contact for information on LogLisp software distribution are also provided. Author},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\6VVGY4V5\\Schrag - 1983 - Notes on the Conversion of LogLisp from RutgersUC.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\BSZAMP2T\\ADA127718.html}
}

@article{shanorDipmeterAdvisorDipmeter1987,
  title = {The Dipmeter Advisor - A Dipmeter Interpretation Workstation},
  author = {Shanor, Gordy G.},
  year = {1987},
  month = dec,
  journal = {Bulletin of the Geological Society of Malaysia},
  volume = {21},
  pages = {37--54},
  issn = {01266187, 2637109X},
  doi = {10.7186/bgsm21198703},
  url = {https://gsm.org.my/content.php?id=54&pid=702001-101136},
  urldate = {2021-04-15},
  abstract = {The Dipmeter Advisor is a knowledge-base system, linked to a computer work-station, designed to aid in the interpretation of dipmeter results through interaction between the interpreter and the "expert" system. The system utilizes dipmeter results, other wireline log data, computer processed results such as LITHO*, and user-input local geological knowledge as the framework for the interpretation. A work session proceeds through a number of phases, which leads to first a structural, then a stratigraphic interpretation of the well data. Conclusions made by the Dipmeter Advisor can be accepted, modified, or rejected by the interpreter at any stage of the work session. The user may also make his own conclusions and comments, which are stored as part of the final interpretation and become part of an updated knowledge-base for input to further field studies.},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\CRJVHW23\\Schlumberger Overseas S.A., Kuala Lumpur, West Malaysia and Shanor - 1987 - The Dipmeter Advisor - A dipmeter interpretation w.pdf}
}

@article{shawInteractiveKnowledgebasedSystem1988,
  title = {An Interactive Knowledge-Based System for Group Problem Solving},
  author = {Shaw, Mildred L.},
  year = {1988},
  journal = {IEEE Transactions on Systems, Man, \& Cybernetics},
  volume = {18},
  number = {4},
  pages = {610--617},
  publisher = {Institute of Electrical \& Electronics Engineers Inc},
  address = {US},
  issn = {0018-9472},
  doi = {10.1109/21.17379},
  abstract = {Discusses a distributed system for human–computer interaction based on a network of computers. The system aids group problem solving by enabling participants to share in a construct elicitation process based on repertory grid techniques that have applications in education, management, and expert systems development. In education, the learner is attempting to acquire a specific construct system for the subject matter; in management, people with different construct systems are attempting to work together toward common objectives; in expert systems development, the knowledge engineer is attempting to make overt and encode the relevant construction system of an expert. The participant construct system enables individuals to interact through networked personal computers to develop mutual understanding of a problem domain through the use of repertory grid techniques. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Computer Applications,Education,Group Problem Solving,Human Machine Systems,Management},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\Z6P9SAMI\\Shaw - 1988 - An interactive knowledge-based system for group pr.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\FRXZM53F\\1989-20900-001.html}
}

@article{sheilInterlispDFurtherSteps1981,
  title = {Interlisp-D: Further Steps in the Flight from Time-Sharing},
  shorttitle = {Interlisp-D},
  author = {Sheil, Beau},
  year = {1981},
  month = jul,
  journal = {ACM SIGART Bulletin},
  number = {77},
  pages = {31--32},
  issn = {0163-5719},
  doi = {10.1145/1056743.1056745},
  url = {https://doi.org/10.1145/1056743.1056745},
  urldate = {2021-04-15},
  abstract = {The Interslip-D project was formed to develop a personal machine implementation of Interlisp for use as an environment for research in artificial intelligence and cognitive science [Burton et al., 80b]. This note describes the principal developments since our last report almost a year ago [Burton et al., 80a].},
  keywords = {Interlisp-D,s2z}
}

@incollection{sheilPOWERTOOLSPROGRAMMERS1986,
  title = {POWER TOOLS FOR PROGRAMMERS},
  shorttitle = {DATAMATION®},
  booktitle = {Readings in Artificial Intelligence and Software Engineering},
  author = {Sheil, Beau},
  editor = {Rich, Charles and Waters, Richard C.},
  year = {1986},
  month = jan,
  pages = {573--580},
  publisher = {Morgan Kaufmann},
  doi = {10.1016/B978-0-934613-12-5.50048-3},
  url = {https://www.sciencedirect.com/science/article/pii/B9780934613125500483},
  urldate = {2021-06-02},
  abstract = {This chapter discusses the power tools for programmers. Essentially, all of the intelligent programming tools described in this volume are at most experimental prototypes. Given that these tools are still quite far from being commercial realities, it is worthwhile to note that there is a completely different way in which artificial intelligence research has to help programmers. Artificial intelligence researchers are themselves programmers. Creating such programs is more a problem of exploration than implementation and does not conform to conventional software lifecycle models. The artificial intelligence programming community has always been faced with this kind of exploratory programming and has, therefore, had a head start on developing appropriate language, environment, and hardware features. Redundancy protects the design from unintentional change, the conventional programming technology restrains the programmer, and the programming languages used in exploratory systems minimize and defer constraints on the programmer.},
  isbn = {978-0-934613-12-5},
  langid = {english},
  keywords = {sz}
}

@article{slagleHeuristicProgramThat1963,
  title = {A Heuristic Program That Solves Symbolic Integration Problems in Freshman Calculus},
  author = {Slagle, James R.},
  year = {1963},
  month = oct,
  journal = {Journal of the ACM},
  volume = {10},
  number = {4},
  pages = {413--581},
  issn = {0004-5411, 1557-735X},
  doi = {10.1145/321186.321193},
  url = {https://dl.acm.org/doi/10.1145/321186.321193},
  urldate = {2021-04-25},
  abstract = {A large high-speed general-purpose digital computer (IBM 7090) was programmed to solve elementary symbolic integration problems at approximately the level of a good college freshman. The program is called SAINT, an acronym for "Symbolic Automatic INTegrator." This paper discusses the SAINT program and its performance. SAINT performs indefinite integration. It also performs definite and multiple integration when these are trivial extensions of indefinite integration. It uses many of the methods and heuristics of students attacking the same prombles. SAINT took an average of two minutes each to solve 52 of the 54 attempted problems taken from the Massachusetts Institute of Technology freshman calculus final examinations. Based on this and other experiments with SAINT, some conclusions coneering computer solution of such problems are: (1) Pattern recognition is of fundamental importance. (2) Great benefit would have been derived from a large memory and more convenient symbol manipulating facilities. (3) The solution of a symbolic integration problem by a commercially available computer is far cheaper and faster than by man.},
  langid = {english},
  keywords = {sz}
}

@inproceedings{smithCommonLispPredilection2014,
  title = {Common Lisp's Predilection for Mathematical Programming},
  booktitle = {Proceedings of ILC 2014 on 8th International Lisp Conference},
  author = {Smith, Robert},
  year = {2014},
  month = aug,
  series = {ILC '14},
  pages = {10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2635648.2639484},
  url = {https://doi.org/10.1145/2635648.2639484},
  urldate = {2021-04-25},
  abstract = {Common Lisp is a towering language that supports a plethora of functionality useful for both scientific and mathematical programming. However---except for a few notable systems such as Axiom, Macsyma/Maxima, and ACL2---Lisp has not taken center stage for such kinds of programming tasks. We will analyze exiting systems, including computer algebra systems, technical computing systems, and other programming languages, and their utility in scientific and mathematical programming. Such a discussion will form a foundation for comparative study. Following that, we will expound on some features of Lisp that augment the expressiveness, simplicity, and utility of programs written in the language. In particular, we do so by way of three carefully selected pragmatic examples arising in fields ranging from the theory of special functions to numerical simulation.},
  isbn = {978-1-4503-2931-6},
  keywords = {arbitrary precision arithmetic,Common Lisp,computer algebra,experimental mathematics,hypergeometric series,Lagrangian mechanics,lattice reduction,mathematics,number identification,numerical differential equations,numerical simulation,pi,sz}
}

@article{smithDevelopmentCommercialExpert1984,
  title = {On the Development of Commercial Expert Systems},
  author = {Smith, Reid G.},
  year = {1984},
  month = sep,
  journal = {AI Magazine},
  volume = {5},
  number = {3},
  pages = {61--61},
  issn = {2371-9621},
  doi = {10.1609/aimag.v5i3.449},
  url = {https://ojs.aaai.org/index.php/aimagazine/article/view/449},
  urldate = {2022-06-27},
  abstract = {We use our experience with the Dipmeter Advisor system for well-log interpretation as a case study to examine the development of commercial expert system. We discuss the nature of these systems as we see them in the coming decade, characteristics of the evolution process, development methods, and skills required in the development team. We argue that the tools and ideas of rapid prototyping and successive refinement accelerate the development process. We note that different types of people are required at different stages of expert system development: Those who are primarily knowledgeable in the domain, but who can use the framework to expand the domain knowledge; and those who can actually design and build expert systems. Finally, we discuss the problem of technology transfer and compare our experience with some of the traditional wisdom of expert system development.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\CKC6CWIC\\Smith - 1984 - On the Development of Commercial Expert Systems.pdf}
}

@patent{smithObjectorientedFrameworkMenu1992,
  title = {Object-Oriented Framework for Menu Definition},
  author = {Smith, Reid G. and Schoen, Eric J.},
  year = {1992},
  month = jun,
  number = {US5119475A},
  url = {https://patents.google.com/patent/US5119475A/en},
  urldate = {2021-06-01},
  abstract = {A declarative object-oriented approach to menu construction provides a mechanism for specifying the behavior, appearance and function of menus as part of an interactive user interface. Menus are constructed from interchangeable object building blocks to obtain the characteristics wanted without the need to write new code or code and maintaining a coherent interface standard. The approach is implemented by dissecting interface menu behavior into modularized objects specifying orthogonal components of desirable menu behaviors. Once primary characteristics for orthogonal dimensions of menu behavior are identified, individual objects are constructed to provide specific alternatives for the behavior within the definitions of each dimension. Finally, specific objects from each dimension are combined to construct a menu having the desired selections of menu behaviors.},
  assignee = {Schlumberger Technology Corp},
  nationality = {US},
  keywords = {behavior,behaviors,class,display,menu},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\QCPEBZT3\\Smith and Schoen - 1992 - Object-oriented framework for menu definition.pdf}
}

@inproceedings{sproullClippingDivider1968,
  title = {A Clipping Divider},
  booktitle = {Proceedings of the December 9-11, 1968, Fall Joint Computer Conference, Part I on - AFIPS '68 (Fall, Part I)},
  author = {Sproull, Robert F. and Sutherland, Ivan E.},
  year = {1968},
  volume = {I},
  pages = {765--775},
  publisher = {ACM Press},
  address = {San Francisco, California},
  doi = {10.1145/1476589.1476687},
  url = {http://portal.acm.org/citation.cfm?doid=1476589.1476687},
  urldate = {2023-04-29},
  abstract = {When compared with a drawing on paper, the pictures presented by today's computer display equipment are sadly lacking in resolution. Most modern display equipment uses 10 bit digital to analog converters, providing for display in a 1024 by 1024 square raster. The actual resolution available is usually somewhat less since adjacent spots or lines will overlap. Even large-screen displays have limited resolution, for although they give a bigger picture, they also draw wider lines so that the amount of material which can appear at one time is still limited. Users of larger paper drawings have become accustomed to having a great deal of material presented at once. The computer display scope alone cannot serve the many tasks which require relatively large drawings with fine details.},
  isbn = {978-1-4503-7899-4},
  langid = {english},
  keywords = {AFIPS Conference Paper,Reviewed by SHFT - CSUCI (Ron Vincent A.)}
}

@techreport{sproullINTERLISPDISPLAYPRIMITIVES1977,
  title = {INTERLISP DISPLAY PRIMITIVES},
  author = {Sproull, Robert F.},
  year = {1977},
  month = jul,
  address = {Xerox Palo Alto Research Center3333 Coyote H iII RoadPalo Altot California 94304},
  url = {http://scholar.googleusercontent.com/scholar?q=cache:fAjwtL8R9ogJ:scholar.google.com/+INTERLISP+DISPLAY+PRIl%5ClITIVES&hl=en&as_sdt=0,5},
  abstract = {This report describes briefly a set of display primitives that we have developed at PARC toextend the capabilities of InterLisp[l]. These primitives are designed to operate araster-scanned displaYt and concentrate on facilities for placing text carefully on the displayand for moving chunks of an already-created display.},
  langid = {american},
  keywords = {interlisp,s2z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\3E2QGNFX\\Sproull - INTERLISP DISPLAY PRIllITIVES.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\5LD3EJ9I\\summary.html}
}

@inproceedings{sproullRasterGraphicsInteractive1979,
  title = {Raster Graphics for Interactive Programming Environments},
  booktitle = {Proceedings of the 6th Annual Conference on Computer Graphics and Interactive Techniques},
  author = {Sproull, Robert F.},
  year = {1979},
  month = aug,
  series = {SIGGRAPH '79},
  pages = {83--93},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800249.807428},
  url = {https://doi.org/10.1145/800249.807428},
  urldate = {2021-04-15},
  abstract = {Raster-scan display terminals can significantly improve the quality of interaction with conventional computer systems. The design of a graphics package to provide a “window” into the extensive programming environment of interlisp is presented. Two aspects of the package are described: first, the functional view of display output and interactive input facilities as seen by the programmer, and second, the methods used to link the display terminal to the main computer via a packet-switched computer network. Recommendations are presented for designing operating systems and programming languages so as to simplify attaching display terminals.},
  isbn = {978-0-89791-004-4},
  keywords = {Computer graphics,Computer networks,Frame buffer,interlisp,Network graphics,Raster-scan display,s2z}
}

@techreport{sproullRasterGraphicsInteractive1979a,
  type = {N/A},
  title = {Raster Graphics for Interactive Programming Environments},
  author = {Sproull, Robert F.},
  year = {1979},
  month = jun,
  number = {N/A},
  pages = {36},
  address = {6th Annual Conference on Computer Graphics and Interacive Techniques},
  institution = {Xerox Palo Alto Research Center},
  url = {http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/CSL-79-6_Raster_Graphics_for_Interactive_Programming_Environments.pdf},
  urldate = {2022-06-14},
  abstract = {Raster-scan display terminals can significantly imrpove the quality of interaction with conventional computer systems. the design of a graphics package to provide a "window" into the extensive programming environment of Interlisp is presented. Two aspects of the package are described: first, the functional view of display output and interactive input facilities as seen by the programmer, and second, the methods used to link the display terminal to the main computer via a packet-switched computer network. Recommendations are presented for designing operating systems and programming languages so as to simplifly attaching display terminals. An appendix contains detailed documentation of the graphics package.},
  langid = {english},
  keywords = {DLISP,Interlisp-D,Reviewed by SHFT - CSUCI (Ron Vincent A.)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\RNYPDS4F\\CSL-79-6_Raster_Graphics_for_Interactive_Programming_Environments.pdf}
}

@book{steeleCOMMONLISPLanguage1984,
  title = {COMMON LISP : The Language},
  shorttitle = {COMMON LISP},
  author = {Steele, Guy L.},
  year = {1984},
  publisher = {Burlington, MA : Digital Press},
  url = {http://archive.org/details/commonlisplangua00stee},
  urldate = {2021-04-16},
  collaborator = {{Internet Archive}},
  isbn = {978-0-932376-41-1},
  langid = {english},
  keywords = {COMMON LISP (Computer program language)}
}

@article{steeleEvolutionLisp1993,
  title = {The Evolution of Lisp},
  author = {Steele, Guy L. and Gabriel, Richard P.},
  year = {1993},
  month = mar,
  journal = {ACM SIGPLAN Notices},
  volume = {28},
  number = {3},
  pages = {231--270},
  issn = {0362-1340},
  doi = {10.1145/155360.155373},
  url = {https://doi.org/10.1145/155360.155373},
  urldate = {2021-06-02},
  abstract = {Lisp is the world's greatest programming language—or so its proponents think. The structure of Lisp makes it easy to extend the language or even to implement entirely new dialects without starting from scratch. Overall, the evolution of Lisp has been guided more by institutional rivalry, one-upsmanship, and the glee born of technical cleverness that is characteristic of the “hacker culture” than by sober assessments of technical requirements. Nevertheless this process has eventually produced both an industrial-strength programming language, messy but powerful, and a technically pure dialect, small but powerful, that is suitable for use by programming-language theoreticians. We pick up where McCarthy's paper in the first HOPL conference left off. We trace the development chronologically from the era of the PDP-6, through the heyday of Interlisp and MacLisp, past the ascension and decline of special purpose Lisp machines, to the present era of standardization activities. We then examine the technical evolution of a few representative language features, including both some notable successes and some notable failures, that illuminate design issues that distinguish Lisp from other programming languages. We also discuss the use of Lisp as a laboratory for designing other programming languages. We conclude with some reflections on the forces that have driven the evolution of Lisp.},
  langid = {english},
  keywords = {sz}
}

@article{steeleParallelismLisp1995,
  title = {Parallelism in Lisp},
  author = {Steele, Guy L.},
  year = {1995},
  month = may,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {VIII},
  number = {2},
  pages = {1--14},
  issn = {1045-3563},
  doi = {10.1145/224133.224134},
  url = {https://dl.acm.org/doi/10.1145/224133.224134},
  urldate = {2021-04-25},
  abstract = {Maybe not as hot a topic in computer architecture as it used to be, but still of considerable interest, is parallelism. How do you make a faster computer? Just strap 20 or 200 or 2000 processors together? As we have learned, the architectural and hardware difficulties are immense (How do you connect them? A shared bus? A network? Is there a single system clock or many clocks?), and after these have been solved there remains the matter of programming.},
  langid = {english},
  keywords = {sz}
}

@article{stefikIntegratingAccessOrientedProgramming1986,
  title = {Integrating Access-Oriented Programming into a Multiparadigm Environment},
  author = {Stefik, Mark and Bobrow, Daniel and Kahn, Kenneth},
  year = {1986},
  month = feb,
  journal = {Software, IEEE},
  volume = {3},
  pages = {10--18},
  doi = {10.1109/MS.1986.232428},
  url = {https://www.researchgate.net/profile/Mark-Stefik-2/publication/3248853_Integrating_Access-Oriented_Programming_into_a_Multiparadigm_Environment/links/02e7e52139c2d9c03f000000/Integrating-Access-Oriented-Programming-into-a-Multiparadigm-Environment.pdf?_sg%5B0%5D=started_experiment_milestone&origin=journalDetail&_rtd=e30%3D},
  abstract = {The Loops knowledge programming system integrates function-oriented, system object-oriented, rule-oriented, and—something notfound in most other systems—access-oriented programming.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\CE6ANN3L\\Stefik et al. - 1986 - Integrating Access-Oriented Programming into a Mul.pdf}
}

@article{stefikKNOWLEDGEPROGRAMMINGLOOPS1983,
  title = {KNOWLEDGE PROGRAMMING IN LOOPS:},
  author = {Stefik, Mark and Bobrow, Daniel G and Mittal, Sanjay and Conway, Lynn},
  year = {1983},
  pages = {11},
  abstract = {Early this year fifty people took an experimental course at Xerox PARC on knowledge programming in Loops During the course, they extended and debugged small knowledge systems in a simulated economics domain called Truckin Everyone learned how to use the Loops environment, formulated the knowledge for their own program, and represented it in Loops At the end of the course a knowledge competition was run so that the strategies used in the different systems could be compared The punchline to this story is that almost everyone learned enough about Loops to complete a small knowledge system in only three days. Although one must exercise caution in extrapolating from small experiments, the results suggest that there is substantial power in integrating multiple programming paradigms.},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\MDBEKVZJ\\Stefik et al. - 1983 - KNOWLEDGE PROGRAMMING IN LOOPS.pdf}
}

@article{stefikKNOWLEDGEPROGRAMMINGLOOPS1983a,
  title = {KNOWLEDGE PROGRAMMING IN LOOPS:},
  author = {Stefik, Mark and Bobrow, Daniel G and Mittal, Sanjay and Conway, Lynn},
  year = {1983},
  pages = {11},
  abstract = {Early this year fifty people took an experimental course at Xerox PARC on knowledge programming in Loops During the course, they extended and debugged small knowledge systems in a simulated economics domain called Truckin Everyone learned how to use the Loops environment, formulated the knowledge for their own program, and represented it in Loops At the end of the course a knowledge competition was run so that the strategies used in the different systems could be compared The punchline to this story is that almost everyone learned enough about Loops to complete a small knowledge system in only three days. Although one must exercise caution in extrapolating from small experiments, the results suggest that there is substantial power in integrating multiple programming paradigms.},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\ZD6ZAF69\\Stefik et al. - 1983 - KNOWLEDGE PROGRAMMING IN LOOPS.pdf}
}

@article{stefikLOOPSManual1983,
  title = {The LOOPS Manual},
  author = {Stefik, Mark and Bobrow, Daniel G},
  year = {1983},
  month = dec,
  pages = {50},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\79VQWSW9\\The LOOPS Manual part 1.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\IKIETQM6\\The LOOPS Manual part 2.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\YEYPYAG6\\The LOOPS Manual part 3.pdf}
}

@misc{stefikTruckinKnowledgeCompetitions1983,
  type = {Blog},
  title = {Truckin’ and the Knowledge Competitions | MJSBlog},
  author = {Stefik, Mark and Bobrow, Daniel and Mittal, Sanjay and Conway, Lynn},
  year = {1983},
  url = {https://www.markstefik.com/?page_id=359},
  urldate = {2021-10-25},
  abstract = {MJSBlog - Workin on it},
  langid = {american},
  keywords = {Reviewed by SHFT - CSUCI (Joseph Moreno)},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\CZWMLN7R\\www.markstefik.com.html}
}

@book{stephenh.kaislerINTERLISPLanguageIts1986,
  title = {INTERLISP The Language And Its Usage},
  author = {{Stephen H. Kaisler}},
  year = {1986},
  publisher = {A Wiley-lnterscience Publication JOHN WILEY \& SONS},
  address = {Canada},
  url = {https://interlisp.org/docs/1986-Interlisp-language-book-1.pdf},
  urldate = {2021-04-25},
  abstract = {LISP, as a language, has been around for about 25 years [mcca78]. It was originally developed to support artificial intelligence (AI) research. At first, it seemed to be little noticed except by a small band of academics who implemented some of the early LISP interpreters and wrote some of the early AI programs. In the early 60’s, LISP began to diverge as various implementations were developed for different machines. McCarthy [mcca78] gives a short history of its early days.},
  langid = {english},
  keywords = {lisp,sz}
}

@article{stoneAAAI86ConferenceExhibits1987,
  title = {The AAAI-86 Conference Exhibits: New Directions for Commercial Artificial Intelligence},
  shorttitle = {The AAAI-86 Conference Exhibits},
  author = {Stone, Jeffrey},
  year = {1987},
  journal = {The AI Magazine},
  url = {https://scholar.archive.org/work/sbbswzyqmbgwlpxikdxm7pfife},
  urldate = {2022-09-29},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\7BTXM35M\\Stone - 1987 - The AAAI-86 Conference Exhibits New Directions fo.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\LPT38DX2\\sbbswzyqmbgwlpxikdxm7pfife.html}
}

@inproceedings{stoyanEarlyLISPHistory1984,
  title = {Early LISP History (1956 - 1959)},
  booktitle = {Proceedings of the 1984 ACM Symposium on LISP and Functional Programming},
  author = {Stoyan, Herbert},
  year = {1984},
  month = aug,
  series = {LFP '84},
  pages = {299--310},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800055.802047},
  url = {https://doi.org/10.1145/800055.802047},
  urldate = {2021-05-29},
  abstract = {This paper describes the development of LISP from McCarthy's first research in the topic of programming languages for AI until the stage when the LISP1 implementation had developed into a serious program (May 1959). We show the steps that led to LISP and the various proposals for LISP interpreters (between November 1958 and May 1959). The paper contains some correcting details to our book (32).},
  isbn = {978-0-89791-142-3},
  keywords = {sz}
}

@incollection{stoyanInfluenceDesignerDesign1991,
  title = {The Influence of the Designer on the Design—J. McCarthy and LISP},
  booktitle = {Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy},
  author = {Stoyan, Herbert},
  year = {1991},
  month = sep,
  pages = {409--426},
  publisher = {Academic Press Professional, Inc.},
  address = {USA},
  url = {https://dl.acm.org/doi/abs/10.5555/132218.132242},
  urldate = {2021-06-02},
  isbn = {978-0-12-450010-5},
  keywords = {sz}
}

@inproceedings{stoyanLisp50Years2008,
  title = {Lisp 50 Years Ago},
  booktitle = {Celebrating the 50th Anniversary of Lisp},
  author = {Stoyan, Herbert},
  year = {2008},
  month = oct,
  series = {LISP50},
  pages = {1--2},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1529966.1529969},
  url = {https://doi.org/10.1145/1529966.1529969},
  urldate = {2021-06-02},
  abstract = {I acknowledge the help of David Elsweiler to get this paper more readable.},
  isbn = {978-1-60558-383-9},
  keywords = {sz}
}

@article{stoyanLISPHistory1979,
  title = {LISP History},
  author = {Stoyan, Herbert},
  year = {1979},
  month = dec,
  journal = {ACM Lisp Bulletin},
  number = {3},
  pages = {42--53},
  doi = {10.1145/1411829.1411837},
  url = {https://dl.acm.org/doi/10.1145/1411829.1411837},
  urldate = {2021-04-23},
  abstract = {For the SIGPLAN conference on history of programming languages held in Los Angeles in this June, J. McCarthy had to write a paper about LISP-history (1). He was very able to do this because he has given a talk on LISP history in summer 1974 at M.I.T. (2) and has contributed since then a lot of remarks and comments to my work on compiling a complete history of our language. His paper corresponds to the state of our knowledge in May of this year (1978) before D. Park found the original LISP 1 manual (3).},
  langid = {english},
  keywords = {sz}
}

@inproceedings{stoyanLispThemesHistory2007,
  title = {Lisp: Themes and History},
  shorttitle = {Lisp},
  booktitle = {Proceedings of the 2007 International Lisp Conference},
  author = {Stoyan, Herbert},
  year = {2007},
  month = apr,
  series = {ILC '07},
  pages = {1},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1622123.1622132},
  url = {https://doi.org/10.1145/1622123.1622132},
  urldate = {2021-04-25},
  abstract = {This presentation will cover several themes connected with Lisp. There will be some part about history, some part about semantical equivalences of code pieces in Lisp, etc.},
  isbn = {978-1-59593-618-9},
  keywords = {sz}
}

@inproceedings{strandhFastGenericDispatch2014,
  title = {Fast Generic Dispatch for Common Lisp},
  booktitle = {Proceedings of ILC 2014 on 8th International Lisp Conference},
  author = {Strandh, Robert},
  year = {2014},
  month = aug,
  series = {ILC '14},
  pages = {89--96},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2635648.2635654},
  url = {https://doi.org/10.1145/2635648.2635654},
  urldate = {2021-04-25},
  abstract = {We describe a technique for generic dispatch that is adapted to modern computers where accessing memory is potentially quite expensive. Instead of the traditional hashing scheme used by PCL [6], we assign a unique number to each class, and the dispatch consists of comparisons of the number assigned to an instance with a certain number of (usually small) constant integers. While our implementation (SICL) is not yet in a state where we are able to get exact performance figures, a conservative simulation suggests that our technique is significantly faster than the one used in SBCL, which uses PCL, and indeed faster than the technique used by most high-performance Common Lisp implementations. Furthermore, existing work [7] using a similar technique in the context of static languages suggests that perfomance can improve significantly compared to table-based techniques.},
  isbn = {978-1-4503-2931-6},
  keywords = {CLOS,Common Lisp,Generic dispatch,Method dispatch,sz}
}

@inproceedings{strandhImprovementSlidingGarbage2014,
  title = {An Improvement to Sliding Garbage Collection},
  booktitle = {Proceedings of ILC 2014 on 8th International Lisp Conference},
  author = {Strandh, Robert},
  year = {2014},
  month = aug,
  series = {ILC '14},
  pages = {97--102},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2635648.2635655},
  url = {https://doi.org/10.1145/2635648.2635655},
  urldate = {2021-04-25},
  abstract = {Garbage collection algorithms are divided into three main categories, namely mark-and-sweep, mark-and-compact, and copying collectors. The collectors in the mark-and-compact category are frequently overlooked, perhaps because they have traditionally been associated with greater cost than collectors in the other categories. Among the compacting collectors, the sliding collector has some advantages in that it preserves the relative age of objects. The main problem with the traditional sliding collector by Haddon and Waite [4] is that building address-forwarding tables is costly. We suggest an improvement to the existing algorithm that reverses the order between building the forwarding table and moving the objects. Our method improves performance of building the table, making the sliding collector a better contestant for young generations of objects (nurseries).},
  isbn = {978-1-4503-2931-6},
  keywords = {Compaction,Sliding garbage collection,sz}
}

@incollection{stroustrupHistory197919911996,
  title = {A History of C++: 1979--1991},
  shorttitle = {A History of C++},
  booktitle = {History of Programming Languages---II},
  author = {Stroustrup, Bjarne},
  year = {1996},
  month = jan,
  pages = {699--769},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/234286.1057836},
  urldate = {2021-04-15},
  abstract = {This paper outlines the history of the C++ programming language. The emphasis is on the ideas, constraints, and people that shaped the language, rather than the minutiae of language features. Key design decisions relating to language features are discussed, but the focus is one the overall design goals and practical constraints. The evolution of C++ is traced from C with Classes to the current ANSI and ISO standards work and the explosion of use, interest, commercial activity, compilers, tools, environments, and libraries.},
  isbn = {978-0-201-89502-5},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\ARDPCKUY\\Stroustrup - 1996 - A history of C++ 1979--1991.pdf}
}

@inproceedings{swansonImplementationPortableStandard1988,
  title = {An Implementation of Portable Standard LISP on the BBN Butterfly},
  booktitle = {Proceedings of the 1988 ACM Conference on LISP and Functional Programming  - LFP '88},
  author = {Swanson, Mark and Kessler, Robert and Lindstrom, Gary},
  year = {1988},
  pages = {132--142},
  publisher = {ACM Press},
  address = {Snowbird, Utah, United States},
  doi = {10.1145/62678.62694},
  url = {http://portal.acm.org/citation.cfm?doid=62678.62694},
  urldate = {2021-04-23},
  abstract = {An implementation of the Portable Standard Lisp (PSL) on the BBN Butterfly is described. Butterfly PSL is identical, syntactically and semantically, to implementations of PSL currently available on the VAX, Gould, and many 68000-based machines, except for the differences discussed in this paper. The differences include the addition of the future and touch constructs for explicit parallelism and an extension of the fluid binding mechanism to support the multiple environments required by concurrent tasks. As with all other PSL implementations, full compilation to machine code of the basic system and application source code is the normal mode, in contrast to the previous byte-code interpreter efforts. Also discussed are other required changes to the PSL system not visible in the syntax or semantics, e.g., compiler support for the future construct. Finally, the underlying hardware is described, and timings for basic operations and speedup results for two examples are given.},
  isbn = {978-0-89791-273-X},
  langid = {english},
  keywords = {sz}
}

@misc{SymbolicsFileSystems1981,
  title = {Symbolics File Systems},
  year = {1981},
  month = aug,
  publisher = {Symbolics Corporaiton},
  langid = {english}
}

@misc{SymbolicsOverviewBriefing1986,
  title = {Symbolics Overview (Briefing)},
  year = {1986},
  publisher = {Symbolics Corporaiton},
  langid = {english}
}

@misc{SymbolicsSoftware1981,
  title = {Symbolics Software},
  year = {1981},
  publisher = {Symbolics Corporaiton},
  langid = {english}
}

@misc{tannirNextHOPE20102014,
  title = {The Next HOPE (2010): Lisp, The Oldest Language of the Future},
  shorttitle = {The Next HOPE (2010)},
  author = {Tannir, Adam},
  year = {2014},
  month = jan,
  publisher = {Channel2600},
  url = {https://www.youtube.com/watch?v=YwDpjDZOxF0},
  urldate = {2021-05-02},
  abstract = {Being the second oldest high-level language still in widespread use (after Fortran), Lisp is often considered solely as an academic language well-suited for artificial intelligence. It is sometimes accused of having a (very (strange syntax)), only using lists as data types, being difficult to learn, using lots of memory, being inefficient and slow, as well as being dead, an ex-language. This talk, focusing on Common Lisp, aims to show that it is actually an elegant, unique, expressive, fast, extensible language for symbolic computation that is not difficult to learn and may even change the way you think about programming. Lisp is primarily a functional paradigm language, but supports object-oriented, imperative, and other programming models natively. Rapid prototyping, iterative development, multiprocessor development, and creation of domain-specific languages are all facilitated by Lisp. There will be a discussion of the origins and history of Lisp, followed by a demonstration of the language, features that migrated to and from other languages, and concluding with a look to what may be in store for the future. Hosted by Adam Tannir},
  keywords = {sz}
}

@article{tatarProgrammerGuideCommon1987,
  title = {A Programmer's Guide to Common Lisp},
  author = {Tatar, Deborah G. and Weinreb, Daniel},
  year = {1987},
  month = apr,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {1},
  number = {1},
  pages = {5--55},
  issn = {1045-3563},
  doi = {10.1145/1862396.1862402},
  url = {https://doi.org/10.1145/1862396.1862402},
  urldate = {2021-04-25},
  abstract = {Lisp has been around for more than twenty-five years. But for most of Lisp's lifetime, there haven't been any good books that teach the language. Only a few books were available, ranging from mediocre to awful.},
  keywords = {sz}
}

@article{tavaniCyberethicsFutureComputing1996,
  title = {Cyberethics and the Future of Computing},
  author = {Tavani, Herman T.},
  year = {1996},
  month = may,
  journal = {ACM SIGCAS Computers and Society},
  volume = {26},
  number = {2},
  pages = {22--29},
  issn = {0095-2737},
  doi = {10.1145/236394.236396},
  url = {https://doi.org/10.1145/236394.236396},
  urldate = {2021-04-25},
  keywords = {sz}
}

@inproceedings{teitelmanAutomatedProgrammeringProgrammer1972,
  title = {Automated Programmering: The Programmer's Assistant},
  shorttitle = {Automated Programmering},
  booktitle = {Proceedings of the December 5-7, 1972, Fall Joint Computer Conference, Part II},
  author = {Teitelman, Warren},
  year = {1972},
  month = dec,
  series = {AFIPS '72 (Fall, Part II)},
  pages = {917--921},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1480083.1480119},
  url = {https://doi.org/10.1145/1480083.1480119},
  urldate = {2021-05-31},
  abstract = {This paper describes a research effort and programming system designed to facilitate the production of programs. Unlike automated programming, which focuses on developing systems that write programs, automated programmering involves developing systems which automate (or at least greatly facilitate) those tasks that a programmer performs other than writing programs: e.g., repairing syntactical errors to get programs to run in the first place, generating test cases, making tentative changes, retesting, undoing changes, reconfiguring, massive edits, et al., plus repairing and recovering from mistakes made during the above. When the system in which the programmer is operating is cooperative and helpful with respect to these activities, the programmer can devote more time and energy to the task of programming itself, i.e., to conceptualizing, designing and implementing. Consequently, he can be more ambitious, and more productive.},
  isbn = {978-1-4503-7913-7},
  keywords = {interlisp,s2z}
}

@misc{teitelmanBBNLISPTENEX1971,
  title = {BBN - LISP, TENEX Reference Manual},
  author = {Teitelman, W. and Bobrow, D. G. and Hartley, A. K. and Murphy, D. L.},
  year = {1971},
  month = jul,
  publisher = {Bolt, Beranek and Newman, Inc. (BBN)},
  url = {http://www.softwarepreservation.org/projects/LISP/bbnlisp/TenexLispRef_Jul71.pdf},
  urldate = {2021-06-01},
  keywords = {BBN-LISP,s2z}
}

@misc{teitelmanBBNLISPTENEX1972,
  title = {BBN - LISP, TENEX Reference Manual, Revised},
  author = {Teitelman, W. and Bobrow, D. G. and Hartley, A. K. and Murphy, D. L.},
  year = {1972},
  month = aug,
  publisher = {Bolt, Beranek and Newman, Inc. (BBN)},
  url = {http://www.bitsavers.org/pdf/bbn/tenex/TenexLispRef_Aug72.pdf},
  urldate = {2021-06-01},
  keywords = {BBN-LISP,s2z}
}

@article{teitelmanClispConversationalLisp1976,
  title = {Clisp: Conversational Lisp},
  shorttitle = {Clisp},
  author = {Teitelman, Warren},
  year = {1976},
  month = apr,
  journal = {IEEE Transactions on Computers},
  volume = {C-25},
  number = {4},
  pages = {354--357},
  issn = {0018-9340},
  doi = {10.1109/TC.1976.1674617},
  url = {http://www.softwarepreservation.org/projects/LISP/interlisp/Teitelman-3IJCAI.pdf/view},
  abstract = {Clisp is an attempt to make Lisp programs easier to read and write by extending the syntax of Lisp to include infix operators, IF-THEN statements, FOR-DO-WHILE statements, and similar Algol-like constructs, without changing the structure or representation of the language. Clisp is implemented through Lisp's error handling machinery, rather than by modifying the interpreter. When an expression is encountered whose evaluation causes an error, the expression is scanned for possible Clisp constructs, which are then converted to the equivalent Lisp expressions. Thus, users can freely intermix Lisp and Clisp without ut having to distinguish which is which. Emphasis in the design and development of Clisp has been on the system aspects of such a facility, with the goal of producing a useful tool, not just another language. To this end, Clisp includes interactive error correction and many "do-what-I-mean" features.},
  keywords = {{Automatic error correction, extensible languages, interactive systems, Lisp, list processing, programming, programming languages.},interlisp,s2z}
}

@techreport{teitelmanDESIGNIMPLEMENTATIONFLIP1967,
  title = {DESIGN AND IMPLEMENTATION OF FLIP, A LISP FORMAT DIRECTED LIST PROCESSOR},
  author = {Teitelman, Warren},
  year = {1967},
  month = jul,
  institution = {BOLT BERANEK AND NEWMAN INC CAMBRIDGE MA},
  url = {https://apps.dtic.mil/sti/citations/AD0660548},
  urldate = {2021-06-01},
  abstract = {The paper discusses some of the considerations involved in designing and implementing a pattern matching or COMIT feature inside of LISP. The programming language FLIP is presented here as a paradigm for such a feature. The design and implementation of FLIP discussed below emphasizes compact notation and efficiency of operation. In addition, FLIP is a modular language and can be readily extended and generalized to include features found in other pattern driven languages such as CONVERT and SNOBOL. This makes it extremely versatile. The development of this paper proceeds from abstract considerations to specific details. The syntax and semantics of FLIP are presented first, followed by a discussion of the implementation with especial attention devoted to techniques used for reducing the number of conses required as well as improving search strategy. Finally FLIP is treated as a working system and viewed from the users standpoint. Here we present some of the additions and extensions to FLIP that have evolved out of almost two years of experimentation. These transform it from a notational system into a practical and useful programming system.},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {BBN-LISP,s2z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\X58MN7JK\\Teitelman - 1967 - DESIGN AND IMPLEMENTATION OF FLIP, A LISP FORMAT D.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\ZKKC8SC3\\AD0660548.html}
}

@inproceedings{teitelmanDisplayOrientedProgrammer1977,
  title = {A Display Oriented Programmer's Assistant},
  booktitle = {Proceedings of the 5th International Joint Conference on Artificial Intelligence - Volume 2},
  author = {Teitelman, Warren},
  year = {1977},
  month = aug,
  series = {IJCAI'77},
  pages = {905--915},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  url = {https://dl.acm.org/doi/10.5555/1622943.1623025},
  urldate = {2021-05-31},
  abstract = {This paper continues and extends previous work by the author in developing systems which provide the user with various forms of explicit and implicit assistance, and in general cooperate with the user in the development of his programs. The system described in this paper makes extensive use of a bit map display and pointing device (a mouse) to significantly enrich the user's interactions with the system, and to provide capabilities not possible with terminals that essentially emulate hard copy devices. For example, any text that is displayed on the screen can be pointed at and treated as input, exactly as though it were typed, i.e., the user can say use this expression or that value, and then simply point. The user views his programming environment through a collection of display windows, each of which corresponds to a different task or context. The user can manipulate the windows, or the contents of a particular window, by a combination of keyboard inputs or pointing operations. The technique of using different windows for different tasks makes it easy for the user to manage several simultaneous tasks and contexts, e.g., defining programs, testing programs, editing, asking the system for assistance, sending and receiving messages, etc and to switch back and forth between these tasks at his convenience.},
  keywords = {interlisp,s2z}
}

@article{teitelmanDisplayOrientedProgrammer1979,
  title = {A Display Oriented Programmer's Assistant},
  author = {Teitelman, Warren},
  year = {1979},
  month = mar,
  journal = {International Journal of Man-Machine Studies},
  volume = {11},
  number = {2},
  pages = {157--187},
  issn = {0020-7373},
  doi = {10.1016/S0020-7373(79)80015-2},
  url = {https://www.sciencedirect.com/science/article/pii/S0020737379800152},
  urldate = {2021-05-31},
  abstract = {This paper continues and extends previous work by the author in developing systems which provide the user with various forms of explicit and implicit assistance, and in general co-operate with the user in the development of his programs. The system described in this paper makes extensive use of a bit map display and pointing device (a mouse) to significantly enrich the user's interactions with the system, and to provide capabilities not possible with terminals that essentially emulate hard copy devices. For example, any text that is displayed on the screen can be pointed at and treated as input, exactly as though it were typed, i.e. the user can say use this expression or that value, and then simply point. The user views his programming environment through a collection of display windows, each of which corresponds to a different task or context. The user can manipulate the windows, or the contents of a particular window, by a combination of keyboard inputs or pointing operations. The technique of using different windows for different tasks makes it easy for the user to manage several simultaneous tasks and contexts, e.g. defining programs, testing programs, editing, asking the system for assistance, sending and receiving messages, etc. and to switch back and forth between these tasks at his convenience.},
  langid = {english},
  keywords = {interlisp,s2z}
}

@techreport{teitelmanDisplayOrientedProgrammers1977,
  title = {A Display Oriented Programmers Assistant},
  author = {Teitelman, Warren},
  year = {1977},
  month = mar,
  pages = {34},
  url = {http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/CSL-77-3_A_Display_Oriented_Programmers_Assistant.pdf},
  abstract = {This paper continues and extends previous work by the author in developing systems which provide the user with various forms of explicit and implicit assistance, and in general co-operate with the user in the development of his programs. The system described in this paper makes extensive use of a bit map display and pointing device (a mouse) to significantly enrich the user's interactions with the system, and to provide capabilities not possible with terminals that essentially emulate hard copy devices. For example, any text that is displayed on the screen can be pointed at and treated as input, exactly as though it were typed, i.e. the user can say use this expression or that value, and then simply point. The user views his programming environment through a collection of display windows, each of which corresponds to a different task or context. The user can manipulate the windows, or the contents of a particular window, by a combination of keyboard inputs or pointing operations. The technique of using different windows for different tasks makes it easy for the user to manage several simultaneous tasks and contexts, e.g. defining programs, testing programs, editing, asking the system for assistance, sending and receiving messages, etc. and to switch back and forth between these tasks at his convenience.},
  langid = {english},
  keywords = {DLISP,human computer interaction,interlisp,Interlisp,Reviewed by SHFT - CSUCI (Ron Vincent A.),s2z}
}

@inproceedings{teitelmanHistoryInterlisp2008,
  title = {History of Interlisp},
  booktitle = {Celebrating the 50th Anniversary of Lisp},
  author = {Teitelman, Warren},
  year = {2008},
  month = oct,
  series = {LISP50},
  pages = {1--5},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1529966.1529971},
  url = {https://doi.org/10.1145/1529966.1529971},
  urldate = {2021-04-15},
  abstract = {I was first introduced to Lisp in 1962 as a first year graduate student at M.I.T. in a class taught by James Slagle. Having programmed in Fortran and assembly, I was impressed with Lisp's elegance. In particular, Lisp enabled expressing recursion in a manner that was so simple that many first time observers would ask the question, "Where does the program do the work?" (Answer - between the parentheses!) Lisp also provided the ability to manipulate programs, since Lisp programs were themselves data (S-expressions) the same as other list structures used to represent program data. This made Lisp an ideal language for writing programs that themselves constructed programs or proved things about programs. Since I was at M.I.T. to study Artificial Intelligence, program writing programs was something that interested me greatly.},
  isbn = {978-1-60558-383-9},
  keywords = {Interlisp-D,s2z}
}

@article{teitelmanINTERLISP1973,
  title = {INTERLISP},
  author = {Teitelman, Warren},
  year = {1973},
  month = dec,
  journal = {ACM SIGART Bulletin},
  number = {43},
  pages = {8--9},
  issn = {0163-5719},
  doi = {10.1145/1056786.1056787},
  url = {https://doi.org/10.1145/1056786.1056787},
  urldate = {2021-04-15},
  abstract = {INTERLISP (INTERactive LISP) is a LISP system currently implemented on the DEC PDP-10 under the BBN TENEX time sharing system{$<$}*R1{$>$}. INTERLISP is designed to provide the user access to the large virtual memory allowed by TENEX, with a relatively small penalty in speed (using special paging techniques described in {$<$}*R2{$>$}). Additional data types have been added, including strings, arrays, and hash association tables (hash links). The system includes a compatible compiler and interpreter. Machine code can be intermixed with INTERLISP expressions via the assemble directive of the compiler. The compiler also contains a facility for "block compilation" which allows a group of functions to be compiled as a unit, suppressing internal names. Each successive level of computation, from interpreted through compiled, to block-compiled provides greater speed at a cost of debugging ease.},
  keywords = {interlisp,s2z}
}

@article{teitelmanINTERLISPDocumentation1974,
  title = {INTERLISP Documentation},
  author = {Teitelman, Warren},
  year = {1974},
  month = feb,
  journal = {ACM SIGART Bulletin},
  number = {44},
  pages = {5--22},
  issn = {0163-5719},
  doi = {10.1145/1045183.1045186},
  url = {https://doi.org/10.1145/1045183.1045186},
  urldate = {2021-04-15},
  abstract = {Documentation for INTERSLIP in the form of the INTERSLIP Reference Manual is now available and may be obtained from Warren Teitelman, Xerox Palo Alto Research Center. The new manual replaces all existing documentation, and is completely up to date (as to January, 1974). The manual is available in either loose-leaf or bound form. The lose-leaf version (binders not supplied) comes with printed separator tabs between the chapters. The bound version also includes colored divider pages between chapters, and is printed on somewhat thinner paper than the loose-leaf version, in an effort to make it 'portable' (the manual being approximately 700 pages long). Both versions contain a complete master index (approximately 1600 entries), as well as a separate index for each chapter. Although the manual is intended primarily to be used for reference, many chapters, e.g., the programmer's assistant, do-what-I-mean, CLISP, etc., include introductory and tutorial material. The manual is available in machine-readable form, and an on-line question-answering system using the manual as a data base is currently being implemented.},
  keywords = {interlisp,s2z}
}

@article{teitelmanInterlispProgrammingEnvironment1981,
  title = {The Interlisp Programming Environment},
  author = {Teitelman, W. and Masinter, L.},
  year = {1981},
  month = apr,
  journal = {Computer},
  volume = {14},
  number = {04},
  pages = {25--33},
  publisher = {IEEE Computer Society},
  issn = {0018-9162},
  doi = {10.1109/C-M.1981.220410},
  url = {https://www.computer.org/csdl/magazine/co/1981/04/01667317/13rRUyv53Ic},
  urldate = {2021-05-05},
  abstract = {Integration, extensibility, and ease of modification made Interlisp unique and powerful. Its adaptations will enhance the power of the coming world of personal computing and advanced displays.},
  langid = {english},
  keywords = {interlisp},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\3T48W2JU\\Teitelman and Masinter - 1981 - The Interlisp Programming Environment.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\I6XGDDTQ\\13rRUyv53Ic.html}
}

@misc{teitelmanNewlispmessagesTxt1979,
  title = {New-Lisp-Messages.Txt.1.},
  author = {Teitelman, Warren and Kaplan, Ron},
  year = {1979},
  journal = {Software Preservation Group},
  url = {http://www.softwarepreservation.org/projects/LISP/interlisp/tenex/sumex-aim/new-lisp-messages.txt.1/view},
  urldate = {2021-04-23},
  keywords = {sz}
}

@article{teitelmanPILOTStepManComputer1966,
  title = {PILOT: A Step Toward Man-Computer Symbiosis},
  shorttitle = {PILOT},
  author = {Teitelman, Warren},
  year = {1966},
  month = sep,
  pages = {199},
  url = {https://dspace.mit.edu/handle/1721.1/6905},
  urldate = {2021-05-31},
  abstract = {PILOT is a programming system constructed  in LISP. It is designed to facilitate the  development of programs by easing the  familiar sequence: write some code, run the  program, make some changes, write some  more code, run the program again, etc. As a  program becomes more complex, making  these changes becomes harder and harder  because the implications of changes are  harder to anticipate. In the PILOT system, the  computer plays an active role in this  evolutionary process by providing the means  whereby changes can be effected  immediately, and in ways that seem natural to  the user. The user of PILOT feels that he is  giving advice, or making suggestions, to the  computer about the operation of his  programs, and that the system then performs  the work necessary. The PILOT system is  thus an interface between the user and his  program, monitoring both in the requests of  the user and operation of his program. The  user may easily modify the PILOT system  itself by giving it advice about its own  operation. This allows him to develop his own  language and to shift gradually onto PILOT the  burden of performing routine but increasingly  complicated tasks. In this way, he can  concentrate on the conceptual difficulties in  the original problem, rather than on the  niggling tasks of editing, rewriting, or adding  to his programs. Two detailed examples are  presented. PILOT is a first step toward  computer systems that will help man to  formulate problems in the same way they now  help him to solve them. Experience with it  supports the claim that such "symbiotic  systems" allow the programmer to attack and  solve more difficult problems.},
  langid = {american},
  keywords = {interlisp,s2z},
  annotation = {Accepted: 2004-10-20T20:06:03Z},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\AQ3Z7DEC\\Teitelman - 1966 - PILOT A Step Toward Man-Computer Symbiosis.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\CAMSS4LV\\6905.html}
}

@techreport{teitelmanProposalResearchInterlisp1976,
  title = {Proposal for Research on Interlisp and Network-Based Systems},
  author = {Teitelman, W.},
  year = {1976},
  month = oct,
  institution = {XEROX CORP PALO ALTO RESEARCH CENTER CA},
  url = {https://apps.dtic.mil/sti/citations/ADA033633},
  urldate = {2021-06-02},
  abstract = {The contract covered by this annual report includes a variety of activities and services centering around the continued growth and well-being of INTERLISP, a large, interactive system widely used in the ARPA community for developing advanced and sophisticated computer-based systems.},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {sz},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\5349MQI7\\Teitelman - 1976 - Proposal for Research on Interlisp and Network-Bas.pdf;C\:\\Users\\wstumbo\\Zotero\\storage\\TSTKXLLD\\ADA033633.html}
}

@misc{teitelmanRecentImprovements9401967,
  title = {Recent Improvements to 940 LISP Library},
  author = {Teitelman, Warren},
  year = {1967},
  month = apr,
  url = {http://bitsavers.org/pdf/sds/9xx/940/ucbProjectGenie/940_LISP_Memo_2_Apr67.pdf},
  urldate = {2021-04-21},
  keywords = {BBN-LISP,s2z}
}

@inproceedings{teitelmanTenYearsWindow1986,
  title = {Ten Years of Window Systems - A Retrospective View},
  booktitle = {Methodology of Window Management},
  author = {Teitelman, Warren},
  editor = {Hopgood, F. Robert A. and Duce, David A. and Fielding, Elizabeth V. C. and Robinson, Ken and Williams, Antony S.},
  year = {1986},
  series = {EurographicSeminars},
  pages = {35--46},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-70919-7_4},
  abstract = {Both James Gosling and I currently work for SUN and the reason for my wanting to talk before he does is that I am talking about the past and James is talking about the future. I have been connected with eight window systems as a user, or as an implementor, or by being in the same building! I have been asked to give a historical view and my talk looks at window systems over ten years and features: the Smalltalk, DLisp (Interlisp), Interlisp-D, Tajo (Mesa Development Environment), Docs (Cedar), Viewers (Cedar), SunWindows and SunDew systems.},
  isbn = {978-3-642-70919-7},
  langid = {english}
}

@misc{TexasInstrumentsExpert1984,
  title = {Texas Instruments Expert System Development Tools, DNJS058},
  year = {1984},
  publisher = {Texas Instruments},
  annotation = {Austin, TX 78792}
}

@misc{TexasInstrumentsExplorer1984,
  title = {Texas Instruments Explorer Technical Summary, DDYB022},
  year = {1984},
  publisher = {Texas Imstruments},
  langid = {english},
  annotation = {Austin, TX 7879}
}

@misc{TexasInstrumentsNew1984,
  title = {Texas Instruments New Developments in Artificial Intelligence, DEEB024 (Brochure)},
  year = {1984},
  publisher = {Texas Instruments},
  annotation = {Austin, TX 78792}
}

@misc{TIExplorerSymbolic1984,
  title = {TI Explorer Symbolic Processing System, DEES055 (Brochure)},
  year = {1984},
  publisher = {Texas Instruments},
  annotation = {Austin, TX 78792}
}

@article{tomoyukiFuturesMultipleValues1995,
  title = {Futures and Multiple Values in Parallel Lisp},
  author = {Tomoyuki, Tanaka and Shigeru, Uzuhara},
  year = {1995},
  month = may,
  journal = {ACM SIGPLAN Lisp Pointers},
  volume = {VIII},
  number = {2},
  pages = {15--24},
  issn = {1045-3563},
  doi = {10.1145/224133.224135},
  url = {https://dl.acm.org/doi/10.1145/224133.224135},
  urldate = {2021-04-25},
  abstract = {We consider the impact of introducing the future construct to the multiple value facility in Lisp (Common Lisp and Scheme). A natural way to accommodate this problem is by modifying the implementation of futures so that one future object returns (or resolves to) multiple values instead of one. We first show how a such straightforward modification fails to maintain the crucial characteristic of futures, namely that inserting futures in a functional program does not alter the the result of the computation. A straightforward modification may result in wrong number of values. We then present two methods which we call the mv-context method and the mv-p flag method to overcome this problem. Both of these methods have been tested in TOP-1 Common Lisp, an implementation of a parallel Common Lisp on the TOP-1 multiprocessor workstation. To our knowledge, this problem has never been analyzed nor solved in an implementation of parallel Lisp. We also present the technique of future chain elimination which avoids creation of unnecessary futures and processes at run-time, which was inspired by this solution.},
  langid = {english},
  keywords = {sz}
}

@inproceedings{tranconywidemannReferencecountingGarbageCollection2008,
  title = {A Reference-Counting Garbage Collection Algorithmfor Cyclical Functional Programming},
  booktitle = {Proceedings of the 7th International Symposium on Memory Management},
  author = {{Trancón y Widemann}, Baltasar},
  year = {2008},
  month = jun,
  series = {ISMM '08},
  pages = {71--80},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1375634.1375645},
  url = {https://doi.org/10.1145/1375634.1375645},
  urldate = {2021-04-25},
  abstract = {Reference-counting garbage collection is known to have problems with the collection of cyclically connected data. There are two historically significant styles of cycle-aware algorithms: The style of Brownbridge that maintains a subset of marked edges and the invariant that every cycle contains at least one marked edge, and the style of Martinez-Lins-Wachenchauzer (MLW) that involves local mark-and-scan procedures to detect cycles. The former is known to be difficult to design and implement correctly, and the latter to have pathological efficiency for a number of very typical situations. We present a novel algorithm that combines both approaches to obtain reasonably efficient local mark-and-scan phases with a marking invariant that is rather cheap to maintain. We demonstrate that the assumptions of this algorithm about mutator activity patterns make it well-suited, but not limited, to a functional programming technique for cyclic data. We evaluate the approach in comparison with simple and more sophisticated MLW algorithms using a simple benchmark based on that functional paradigm.},
  isbn = {978-1-60558-134-7},
  keywords = {cycles,functional programming,garbage collection,memory management,reference counting,sz}
}

@misc{trhawesFreeBSDT36002022,
  type = {Reddit Post},
  title = {FreeBSD on Dell T3600},
  author = {{trhawes}},
  year = {2022},
  month = jul,
  journal = {r/freebsd},
  url = {www.reddit.com/r/freebsd/comments/vrjqa4/freebsd_on_dell_t3600/},
  urldate = {2023-02-25},
  abstract = {I'm a retro enthusiast who loves Lisp, so natually, I'd want to show off my Medley Interlisp virtual machine (emulating a Xerox Lisp Machine). Someone had included FreeBSD support for the project. I contributed makefiles for amd64 and aarch64 architectures. The project isn't in ports, it resides on github. Super-easy to get running on FreeBSD.},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\W7N7MVXZ\\freebsd_on_dell_t3600.html}
}

@inproceedings{triggHypertextHabitatsExperiences1987,
  title = {Hypertext Habitats: Experiences of Writers in NoteCards},
  shorttitle = {Hypertext Habitats},
  booktitle = {Proceedings of the ACM Conference on Hypertext},
  author = {Trigg, Randall H. and Irish, Peggy M.},
  year = {1987},
  month = nov,
  series = {HYPERTEXT '87},
  pages = {89--108},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/317426.317435},
  url = {https://doi.org/10.1145/317426.317435},
  urldate = {2023-03-03},
  abstract = {This paper reports on an investigation into the use of the NoteCards hypertext system for writing. We describe a wide variety of personal styles adopted by 20 researchers at Xerox as they “inhabit” NoteCards. This variety is displayed in each of their writing activities: notetaking, organizing and reorganizing their work, maintaining references and bibliographies, and preparing documents. In addition, we discuss the distinctive personal decisions made as to which activities are appropriate for NoteCards in the first place. Finally, we conclude with a list of recommendations for system designers arising from this work.},
  isbn = {978-0-89791-340-9},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\Q9Q924EC\\Trigg and Irish - 1987 - Hypertext habitats experiences of writers in Note.pdf}
}

@inproceedings{triggSupportingCollaborationNotecards1986,
  title = {Supporting Collaboration in Notecards},
  booktitle = {Proceedings of the 1986 ACM Conference on Computer-Supported Cooperative Work},
  author = {Trigg, Randall H. and Suchman, Lucy A. and Halasz, Frank G.},
  year = {1986},
  month = dec,
  series = {CSCW '86},
  pages = {153--162},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/637069.637089},
  url = {https://doi.org/10.1145/637069.637089},
  urldate = {2023-03-03},
  abstract = {This paper describes a project underway to investigate computer support for collaboration. In particular, we focus on experience with and extensions to NoteCards, a hypertext-based idea structuring system. The forms of collaboration discussed include draft-passing, simultaneous sharing and online presentations. The requirement that mutual intelligibility be maintained between collaborators leads to the need for support of annotative and procedural as well as substantive activities.},
  isbn = {978-1-4503-7365-4},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\TJF5PCRW\\Trigg et al. - 1986 - Supporting collaboration in notecards.pdf}
}

@misc{TruckinKnowledgeCompetitions,
  title = {Truckin’ and the Knowledge Competitions | MJSBlog},
  url = {https://www.markstefik.com/?page_id=359},
  urldate = {2022-07-17},
  abstract = {MJSBlog - Workin on it},
  langid = {american},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\832HGPCC\\www.markstefik.com.html}
}

@inproceedings{turnerLPLISPLiterate2010,
  title = {LP/LISP: Literate Programming for Lisp},
  shorttitle = {LP/LISP},
  booktitle = {Proceedings of the 2010 International Conference on Lisp},
  author = {Turner, Roy M.},
  year = {2010},
  month = oct,
  series = {ILC '10},
  pages = {21--28},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1869643.1869647},
  url = {https://doi.org/10.1145/1869643.1869647},
  urldate = {2021-04-25},
  abstract = {Writing a program and writing its documentation are often considered two separate tasks, leading to several problems: the documentation may never be written; when it is, it may be an afterthought; and when the program is modified, the needed changes to the documentation may be overlooked. Literate programming (LP), introduced by Donald Knuth, views a program and its documentation as an integrated whole: they are written together to inform both the computer and human readers. LP tools then extract the code for the computer and the documentation for further document processing. Unfortunately, existing LP tools are much more suited for compiled languages, where there is already a step between coding and executing and debugging the code. Lisp programming typically involved incremental development and testing, often highly interleaving coding with running portions of the code. Thus LP tools inject an artificial impediment into this process. LP/Lisp is a new LP tool designed specifically for Lisp and the usual style of programming using Lisp. The literate programming file is the Lisp file; LP markup and text resides in Lisp comments, where it does not interfere with running the code. LP/Lisp provided the usual literate programming services, such as code typesetting, syntactic sugaring, and the ability to split the code for expository purposes (a "chunk" mechanism). LP/Lisp, itself written in Lisp, is run on the code to produce the documentation.},
  isbn = {978-1-4503-0470-2},
  keywords = {latex,lisp,literate programming,sz}
}

@misc{tvontaroComputerAssistedInstructionBits2012,
  title = {Computer-Assisted Instruction (Bits and Bytes, Episode 7)},
  year = {2012},
  month = may,
  url = {https://www.youtube.com/watch?v=eURtTV_qKw8&t=147s},
  urldate = {2021-05-02},
  abstract = {This clip looks at two examples of larger tutorial--CAI systems that were developed by the Ontario Institute for Studies and Education, and Xerox's PARC. It is from Episode 7 of the classic 1983 television series, Bits and Bytes, which starred Luba Goy and Billy Van.  It was produced by TVOntario, but is no longer available for purchase.},
  collaborator = {{TVontaro}},
  keywords = {sz}
}

@inproceedings{ungarAnnotatingObjectsTransport1995,
  title = {Annotating Objects for Transport to Other Worlds},
  booktitle = {Proceedings of the Tenth Annual Conference on Object-Oriented Programming Systems, Languages, and Applications},
  author = {Ungar, David},
  year = {1995},
  month = oct,
  series = {OOPSLA '95},
  volume = {30},
  pages = {73--87},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/217838.217845},
  url = {https://doi.org/10.1145/217838.217845},
  urldate = {2021-04-15},
  abstract = {In Self 4.0, people write programs by directly constructing webs of objects in a larger world of objects. But in order to save or share these programs, the objects must be moved to other worlds. However, a concrete, directly constructed program is incomplete, in particular missing five items of information: which module to use, whether to transport an actual value or a counterfactuaI initial value, whether to create a new object in the new world or to refer to an existing one, whether an object is immutable with respect to transportation, and whether an object should be created by a low-level, concrete expression or an abstract, type-specific expression. In Self 4.0, the programmer records this extra information in annotations and attributes. Any system that saves directly constructed programs will have to supply this missing information somehow.},
  isbn = {978-0-89791-703-0},
  keywords = {sz}
}

@article{ungarDebuggingExperienceImmediacy1997,
  title = {Debugging and the Experience of Immediacy},
  author = {Ungar, David and Lieberman, Henry and Fry, Christopher},
  year = {1997},
  month = apr,
  journal = {Communications of the ACM},
  volume = {40},
  number = {4},
  pages = {38--43},
  issn = {0001-0782},
  doi = {10.1145/248448.248457},
  url = {https://doi.org/10.1145/248448.248457},
  urldate = {2021-04-15},
  keywords = {sz}
}

@inproceedings{viriyakattiyapornImprovingProgramNavigation2010,
  title = {Improving Program Navigation with an Active Help System},
  booktitle = {Proceedings of the 2010 Conference of the Center for Advanced Studies on Collaborative Research},
  author = {Viriyakattiyaporn, Petcharat and Murphy, Gail C.},
  year = {2010},
  month = nov,
  series = {CASCON '10},
  pages = {27--41},
  publisher = {IBM Corp.},
  address = {USA},
  doi = {10.1145/1923947.1923951},
  url = {https://doi.org/10.1145/1923947.1923951},
  urldate = {2021-04-15},
  abstract = {When performing software change tasks, software developers spend a substantial amount of their time navigating dependencies in the code. Despite the availability of numerous tools to aid such navigation, there is evidence to suggest that developers are not using these tools. In this paper, we introduce an active help system, called Spyglass, that suggests tools to aid program navigation as a developer works. We report on the results of a laboratory study that investigated two questions: will developers act upon suggestions from an active help system and will those suggestions improve developer behaviour? We found that with Spyglass we could make developers as aware of navigational tools as they are when requested to read a tutorial about such tools, with less up-front effort. We also found that we could improve developer behaviour as developers in the Spyglass group, after being given recommendations in the context of their work, navigated programming artifacts more efficiently than those in the tutorial group.},
  keywords = {sz}
}

@inproceedings{waguespackWorkbenchProjectOriented1984,
  title = {A Workbench for Project Oriented Software Engineering Courses},
  booktitle = {Proceedings of the Fifteenth SIGCSE Technical Symposium on Computer Science Education},
  author = {Waguespack, Leslie J. and Hass, David F.},
  year = {1984},
  month = jan,
  series = {SIGCSE '84},
  pages = {137--145},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/800039.808638},
  url = {https://doi.org/10.1145/800039.808638},
  urldate = {2021-04-25},
  abstract = {We present the Computer Science Scholar's Workbench, a tool kit written in Pascal suitable for research and teaching. It has advantages over contemporary workbenches, UNIX and INTERLISP: a host to support the tool kit costs less than \$3,000, the tools are free-available in source from publications, and the tools are written in Pascal which is widely used in academic environments. We discuss a) course requirements and problems unique to project oriented software engineering classes, b) the tools we've chosen for the workbench, and c) how they may be used to ameliorate or solve many of the problems. We report our experience using the workbench and evaluate it in terms of cost, performance, portability, extensibility, and effectiveness.},
  isbn = {978-0-89791-126-1},
  keywords = {sz}
}

@article{weizenbaumELIZAComputerProgram1966,
  title = {ELIZA, a Computer Program for the Study of Natural Language Communication between Man and Machine},
  author = {Weizenbaum, Joseph},
  year = {1966},
  month = jan,
  journal = {Communications of the ACM},
  volume = {9},
  number = {1},
  pages = {36--45},
  issn = {0001-0782},
  doi = {10.1145/365153.365168},
  url = {https://doi.org/10.1145/365153.365168},
  urldate = {2021-05-31},
  abstract = {Eliza is a program operating within the MAC time-sharing systemm at MIT which makes certain kinds of natural language conversation between man and computer possible. Input sentences are analyzed on the basis of decomposition rules which are triggered by key words appearing in the input text. Responsesare generated by reassembly rules associated with selected decomposition rules. The fundamental technical problems with which ELIZA is concerned are: (1) the identification of key words, (2) the discovery of minimal context, (3) the choice of appropriate transformations, (4) generation of reponses in the abscence of key words, and (5) the provision of an editing capability for ELIZA "scripts". A discussion of some pyschological issues relevant to the ELIZA approach as well as of future developments concludes the paper.},
  keywords = {Basic PDP-1 LISP,s2z}
}

@article{wertzSystemUnderstandIncorrect1978,
  title = {A System to Understand Incorrect Programs},
  author = {Wertz, Harald},
  year = {1978},
  month = jul,
  journal = {ACM Lisp Bulletin},
  number = {2},
  pages = {2--46},
  doi = {10.1145/1411798.1411808},
  url = {https://doi.org/10.1145/1411798.1411808},
  urldate = {2021-04-25},
  abstract = {This paper presents a systems (PHENARETE) which understands and improves incompletely defined LISP programs, such as those written by students beginning to program in LISP. This system takes, as input, the program without any additional information. In order to understand the program, the system meta-evaluates it, using a library of "pragmatic rules", describing the construction and correction of general program constructs, and a set of "specialists", describing the syntax and semantics of the standard LISP functions. The system can use its understanding of the program to detect errors in it, to debug them and, eventually, to justify its proposed modification. This paper gives a brief survey of the working of the system, emphasizing on some commented examples.},
  keywords = {sz}
}

@article{westfoldHIstoricalOverviewArtifiicial1979,
  title = {An HIstorical Overview of Artifiicial Intellligence Programming Languages},
  author = {Westfold, Stephen},
  year = {1979},
  month = may,
  url = {https://stacks.stanford.edu/file/druid:vg077ps3762/vg077ps3762.pdf},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\3647X8C6\\Westfold - Name Stephen Westfold Project I Programmer SJW .pdf}
}

@techreport{weylInterlispRelationalData1975,
  title = {An Interlisp Relational Data Base System.},
  author = {Weyl, Stephen},
  year = {1975},
  month = nov,
  institution = {STANFORD RESEARCH INST MENLO PARK CALIF},
  url = {https://apps.dtic.mil/sti/citations/ADA018962},
  urldate = {2021-05-29},
  abstract = {This report describes the file system for the experimental large file management support system currently being implemented at SRI. INTERLISP, an interactive, development-oriented computer programming system, has been augmented to support applications requiring large data bases maintained on secondary store.  The data base support programs are separated into two levels  an advanced file system and relational data base management procedures. The file system allows programmers to make full use of the capabilities of on-line random access devices using problem related symbolic primitives rather than page and word numbers.  It also performs several useful data storage functions such as data compression, sequencing, and generation of symbols which are unique for a file.},
  chapter = {Technical Reports},
  langid = {english},
  keywords = {sz}
}

@inproceedings{whiteMassivelyMonsterMachines2008,
  title = {From Massively Monster Machines to Microchips: Forces Affecting Lisp Language Design for Five Decades},
  shorttitle = {From Massively Monster Machines to Microchips},
  booktitle = {Celebrating the 50th Anniversary of Lisp},
  author = {White, Jon L. and Bourbaki, Nickieben},
  year = {2008},
  month = oct,
  series = {LISP50},
  pages = {1--2},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1529966.1529968},
  url = {https://doi.org/10.1145/1529966.1529968},
  urldate = {2021-04-15},
  abstract = {I worked on Lisp design and implementation from the late 1960s almost until I retired about 5 years ago---and since then I've remained in the community by helping organize Lisp conferences. This means I've been in the thick of Lisp for most of its lifetime. In my talk there were a couple of points I wanted to make. First, computer hardware over the years has imposed constraints on the design of Lisp, ranging from gigantic machines in the early days---gigantic in size but miniscule in computing power---to tiny ones today (whose computing power was once considered "super".) Second, it was certain mindsets of the people involved in the design and implementation of Lisp that most strongly influenced its design---in particular, it was their educational background, driven by interests and talents, that had a great impact on the language.},
  isbn = {978-1-60558-383-9},
  keywords = {sz}
}

@incollection{wiederholdIntegrationKnowledgeData1986,
  title = {An Integration of Knowledge and Data Representation},
  booktitle = {On Knowledge Base Management Systems: Integrating Artificial Intelligence and Database Technologies},
  author = {Wiederhold, Gio and Blum, Robert L. and Walker, Michael},
  editor = {Brodie, Micheal L. and Mylopoulos, John},
  year = {1986},
  series = {Topics in Information Systems},
  pages = {431--444},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-4980-1_33},
  url = {https://doi.org/10.1007/978-1-4612-4980-1_33},
  urldate = {2021-05-29},
  abstract = {A variety of types of linkages from knowledge bases to databases have been proposed, and a few have been implemented [MW84]. In this research note, we summarize a technique which was employed in a specific context: knowledge extraction from a copy of an existing clinical database. The knowledge base is also used to drive the extracting process. RX builds causal models in its domain to generate input for statistical hypothesis verification. We distinguish two information types: knowledge and data, and recognize four types of knowledge: categorical, definitional, causal (represented in frames), and operational, represented by rules. Based on our experience, we speculate about the generalization of the approach.},
  isbn = {978-1-4612-4980-1},
  langid = {english},
  keywords = {Causal Knowledge,Data Representation,Defense Advance Research Project Agency,Medical Knowledge,Statistical Knowledge,sz}
}

@inproceedings{wiilHyperformUsingExtensibility1993,
  title = {Hyperform: Using Extensibility to Develop Dynamic, Open, and Distributed Hypertext Systems},
  shorttitle = {Hyperform},
  booktitle = {Proceedings of the ACM Conference on Hypertext},
  author = {Wiil, Uffe K. and Leggett, John J.},
  year = {1993},
  month = dec,
  series = {ECHT '92},
  pages = {251--261},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/168466.171510},
  url = {https://doi.org/10.1145/168466.171510},
  urldate = {2021-04-15},
  abstract = {An approach to flexible hyperbase (hypertext database) support predicated on the notion of ex-tensibility is presented. The extensible hypertext platform (Hyperform) implements basic hyperbase services that can be tailored to provide specialised hyperbase support. Hypeeform is based on an inter-nal computational engine that provides an object-oriented extension language which allows new data model objects and operations to be added at run-time. Hyperform has a number of built-in classes to pro-vide basic hyperbase features such as concurrency control, notification control (events), access control, version control and search and query. Each of these classes can be specialised using multiple inheritance to form virtually any type of hyperbase support needed in next-generation hypertext systems. This approach greatly reduces the effort required to provide high-quality customized hyperbase support for distributed hypertext applications. Hyper-form is implemented and operational in Unix environments. This paper describes the Hyperform approach, discusses its advantages and disadvantages, and gives examples of simulating the 11AM and the Danish Hyperlime in Hyperform. Hyper-form is compared with related work from the HAM generation of hyperbase systems and the current status of the project is reviewed.},
  isbn = {978-0-89791-547-X},
  keywords = {sz}
}

@article{woodBookReviewPractical1995,
  title = {Book Review: Practical User Interface Design by Larry Wood},
  shorttitle = {Book Review},
  author = {Wood, Larry},
  year = {1995},
  month = oct,
  journal = {ACM SIGCHI Bulletin},
  volume = {27},
  number = {4},
  pages = {79--80},
  issn = {0736-6906},
  doi = {10.1145/214132.570139},
  url = {https://doi.org/10.1145/214132.570139},
  urldate = {2021-04-25},
  keywords = {sz}
}

@article{woodLJInterviewsLarry1996,
  title = {LJ Interviews Larry Gritz},
  author = {Wood, Amy},
  year = {1996},
  month = nov,
  journal = {Linux Journal},
  volume = {1996},
  number = {31es},
  pages = {6-es},
  issn = {1075-3583},
  url = {https://dl.acm.org/doi/abs/10.5555/326464.326470},
  keywords = {sz}
}

@techreport{Xerox1108Artifical,
  title = {Xerox 1108 Artifical Intelligence Workstations},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\SUB44YL9\\xerox1108.pdf}
}

@misc{xerox1985HarmonyIntermezzo1985,
  title = {1985 Harmony and Intermezzo Releases Koto Release (for Xerox 1186), Some Bits of Common Lisp},
  author = {{XEROX}},
  year = {1985},
  month = dec,
  url = {https://www.google.com/search?client=firefox-b-d&q=1985+Harmony+and+Intermezzo+releases+Koto+release+%28for+Xerox+1186%29%2C+some+bits+of+Common+Lisp},
  urldate = {2021-04-21},
  langid = {english},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\47GPP9MP\\198512_3101312_Koto_Release_Notes.pdf}
}

@misc{XeroxAltoEmulator,
  title = {Xerox Alto Emulator},
  url = {https://archives.loomcom.com/contraltojs/},
  urldate = {2021-08-20},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\M7AT3AFN\\contraltojs.html}
}

@misc{xeroxArtificialIntelligenceSystems1986,
  title = {Artificial Intelligence Systems, Interlisp-D: A Friendly Primer},
  author = {{Xerox}},
  year = {1986},
  month = nov,
  publisher = {Xerox Corporation},
  url = {http://www.bitsavers.org/pdf/xerox/interlisp-d/198510_Koto/3102300_Interlisp-D_A_Friendly_Primer_Nov86.pdf},
  urldate = {2021-04-23},
  langid = {english},
  keywords = {Interlisp-D,s2z}
}

@book{XeroxGlobalviewDocument,
  title = {Xerox\_Globalview\_Document\_Services\_for\_Sun\_Technical\_Reference\_Manual\_Jun92.Pdf},
  url = {http://www.bitsavers.org/pdf/xerox/xns_services/services_sparc/Xerox_Globalview_Document_Services_for_Sun_Technical_Reference_Manual_Jun92.pdf},
  urldate = {2022-07-26},
  file = {C\:\\Users\\wstumbo\\Zotero\\storage\\ZB2TAD4S\\Xerox_Globalview_Document_Services_for_Sun_Technical_Reference_Manual_Jun92.pdf}
}

@misc{xeroxInterlispReferenceManual1983,
  title = {Interlisp Reference Manual},
  shorttitle = {Interlisp Reference Manual},
  author = {{Xerox}},
  year = {Octuber 1983},
  publisher = {Xerox Corporation},
  url = {https://larrymasinter.net/86-interlisp-manual-opt.pdf},
  abstract = {Interlisp began with an implementation of the Lisp programming language for the PDP-1 at Bolt. Beranek and Newman in 1966. It was followed in 1967 by 940 Lisp, an upward compatible implementation for the SDS-940 computer. 940 Lisp was the first Lisp system to demonstrate the feasibility of using software paging techniques and a large vinual memory in conjunction with a list-processing system [Bobrow \& ( -----\textbackslash{} ) Murphy, 1967]. 940 Lisp was patterned after the Lisp 1.5 \textasciitilde plementation for CTSS at MIT, with several' ) 1ew facilities added to take advantage of its timeshared. on-line environment. DWIM, the Do-What+ Mean error correction facility, was introduced into this system in 1968 by Warren Teitelman [Teitelman. 1969].},
  langid = {english},
  keywords = {sz},
  annotation = {OCLC: 802551877}
}

@preamble{ "\providecommand{\noopsort}[1]{} " }
